{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVLRMczx3WZBkXFo0GyIjy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Credit Card Approval Prediction"
      ],
      "metadata": {
        "id": "AeTsGu5_t67K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"2\"></a>\n",
        "## Data Content\n",
        "There're two tables could be merged by ID:\n",
        "\n",
        "\n",
        "**application_record.csv**\t:\n",
        "- ID\tClient: number\n",
        "- CODE_GENDER:\tGender\n",
        "- FLAG_OWN_CAR:\tIs there a car\n",
        "- FLAG_OWN_REALTY:\tIs there a property\n",
        "- CNT_CHILDREN:\tNumber of children\n",
        "- AMT_INCOME_TOTAL:\tAnnual income\n",
        "- NAME_INCOME_TYPE:\tIncome category\n",
        "- NAME_EDUCATION_TYPE:\tEducation level\n",
        "- NAME_FAMILY_STATUS:\tMarital status\n",
        "- NAME_HOUSING_TYPE:\tWay of living\n",
        "- DAYS_BIRTH:\tBirthday\tCount backwards from current day (0), -1 means yesterday\n",
        "- DAYS_EMPLOYED:\tStart date of employment. Count backwards from current day(0). If positive, it means the person currently unemployed.\n",
        "- FLAG_MOBIL:\tIs there a mobile phone\n",
        "- FLAG_WORK_PHONE:\tIs there a work phone\n",
        "- FLAG_PHONE:\tIs there a phone\n",
        "- FLAG_EMAIL:\tIs there an email\n",
        "- OCCUPATION_TYPE:\tOccupation\n",
        "- CNT_FAM_MEMBERS:\tFamily size\n",
        "\n",
        "\n",
        "**credit_record.csv** :\n",
        "- ID:\tClient number\n",
        "- MONTHS_BALANCE:\tRecord month. The month of the extracted data is the starting point, backwards, 0 is the current month, -1 is the previous month, and so on\n",
        "- STATUS\tStatus\t0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month"
      ],
      "metadata": {
        "id": "r7om4gKzFWOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What topics are covered in this project?\n",
        "* Preprocessing: missing value, train-test split and normalization\n",
        "* Feature Engineering\n",
        "* Feature Importance and Selection\n",
        "* Modelling: Ensemble Model :LightGBM-Gradient Boosting\n",
        "* LightGBM and Gradient Boosting Hyperparameter Tuning and Optimization\n",
        "* Ensemble Methods\n",
        "* Handling Class Imbalance\n",
        "* Model Training and Evaluation"
      ],
      "metadata": {
        "id": "LDaw2jI_N9rw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "1. [Python Libraries](#1)\n",
        "1. [Data Loading and Initial Exploration](#2)\n",
        "1. [Handling Duplicates and Missing Values](#3)\n",
        "1. [Feature Analysis and Manupulation](#4)\n",
        "1. [Credit Scoring Calculation](#5)\n",
        "1. [Merging and Preprocessing Datasets](#6)\n",
        "1. [Data Visualization](#7)\n",
        "1. [Data Splitting and Preprocessing](#8)\n",
        "1. [Model Training and Evaluation](#9)\n",
        "1. [Feature Importance and Selection](#10)\n",
        "1. [Hyperparameter Tuning and Optimization](#11)\n",
        "1. [Ensemble Methods](#12)\n",
        "1. [Handling Class Imbalance](#13)\n",
        "1. [Final Model Training and Evaluation](#14)"
      ],
      "metadata": {
        "id": "sTAWNaSVOszx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"1\"></a>\n",
        "## 1. Python Libraries"
      ],
      "metadata": {
        "id": "og2g-oQnwBoV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V00y89m1QUXc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce6a945-00f4-4382-826b-e1896b73447f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# Data Manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Typing and Pretty Printing\n",
        "from typing import List, Dict, Any\n",
        "from pprint import pprint\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Model Selection\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "\n",
        "# Pipelines and Column Transformation\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Machine Learning Models\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Decision Trees\n",
        "from sklearn.tree import DecisionTreeRegressor, export_text\n",
        "\n",
        "# Model Evaluation\n",
        "from sklearn.metrics import make_scorer, accuracy_score, classification_report, f1_score, roc_auc_score, precision_recall_curve, average_precision_score, matthews_corrcoef, balanced_accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Class Weight Computation\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Model Calibration\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Oversampling Techniques\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"2\"></a>\n",
        "## 2. Data Loading and Initial Exploration"
      ],
      "metadata": {
        "id": "lnENmwRHEck8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app = pd.read_csv('application_record.csv')"
      ],
      "metadata": {
        "id": "oOFhs1GmRoOz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_cre = pd.read_csv('credit_record.csv')"
      ],
      "metadata": {
        "id": "psio8uc2wgxL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "0ChMc-QNRtM0",
        "outputId": "5cd3981e-1db6-4ea0-f50b-f312c081b94d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
              "0  5008804           M            Y               Y             0   \n",
              "1  5008805           M            Y               Y             0   \n",
              "2  5008806           M            Y               Y             0   \n",
              "3  5008808           F            N               Y             0   \n",
              "4  5008809           F            N               Y             0   \n",
              "\n",
              "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
              "0          427500.0               Working               Higher education   \n",
              "1          427500.0               Working               Higher education   \n",
              "2          112500.0               Working  Secondary / secondary special   \n",
              "3          270000.0  Commercial associate  Secondary / secondary special   \n",
              "4          270000.0  Commercial associate  Secondary / secondary special   \n",
              "\n",
              "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
              "0        Civil marriage   Rented apartment      -12005          -4542   \n",
              "1        Civil marriage   Rented apartment      -12005          -4542   \n",
              "2               Married  House / apartment      -21474          -1134   \n",
              "3  Single / not married  House / apartment      -19110          -3051   \n",
              "4  Single / not married  House / apartment      -19110          -3051   \n",
              "\n",
              "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
              "0           1                1           0           0             NaN   \n",
              "1           1                1           0           0             NaN   \n",
              "2           1                0           0           0  Security staff   \n",
              "3           1                0           1           1     Sales staff   \n",
              "4           1                0           1           1     Sales staff   \n",
              "\n",
              "   CNT_FAM_MEMBERS  \n",
              "0              2.0  \n",
              "1              2.0  \n",
              "2              2.0  \n",
              "3              1.0  \n",
              "4              1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51789c2f-0fcf-46a7-8b55-0d666717457c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <th>CNT_FAM_MEMBERS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008804</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>-12005</td>\n",
              "      <td>-4542</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008805</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>-12005</td>\n",
              "      <td>-4542</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5008806</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>112500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-21474</td>\n",
              "      <td>-1134</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Security staff</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5008808</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19110</td>\n",
              "      <td>-3051</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5008809</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19110</td>\n",
              "      <td>-3051</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51789c2f-0fcf-46a7-8b55-0d666717457c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51789c2f-0fcf-46a7-8b55-0d666717457c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51789c2f-0fcf-46a7-8b55-0d666717457c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcaae217-384c-4d87-9d30-1843677eb616\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcaae217-384c-4d87-9d30-1843677eb616')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcaae217-384c-4d87-9d30-1843677eb616 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_app"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cre.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7XK-3ZxXEvPN",
        "outputId": "31a5fa65-6cd9-4acc-efca-917f8da84be5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  MONTHS_BALANCE STATUS\n",
              "0  5001711               0      X\n",
              "1  5001711              -1      0\n",
              "2  5001711              -2      0\n",
              "3  5001711              -3      0\n",
              "4  5001712               0      C"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31415c21-0938-4750-8ca2-9b073b64096d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>MONTHS_BALANCE</th>\n",
              "      <th>STATUS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5001711</td>\n",
              "      <td>0</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5001711</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5001711</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5001711</td>\n",
              "      <td>-3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5001712</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31415c21-0938-4750-8ca2-9b073b64096d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31415c21-0938-4750-8ca2-9b073b64096d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31415c21-0938-4750-8ca2-9b073b64096d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff28f4c5-16e1-4d98-810c-65ebc6ccb07b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff28f4c5-16e1-4d98-810c-65ebc6ccb07b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff28f4c5-16e1-4d98-810c-65ebc6ccb07b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_cre"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkNwvktqxxjE",
        "outputId": "b7bbaab6-902a-42b9-b08b-becd7813ff78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 438557 entries, 0 to 438556\n",
            "Data columns (total 18 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   ID                   438557 non-null  int64  \n",
            " 1   CODE_GENDER          438557 non-null  object \n",
            " 2   FLAG_OWN_CAR         438557 non-null  object \n",
            " 3   FLAG_OWN_REALTY      438557 non-null  object \n",
            " 4   CNT_CHILDREN         438557 non-null  int64  \n",
            " 5   AMT_INCOME_TOTAL     438557 non-null  float64\n",
            " 6   NAME_INCOME_TYPE     438557 non-null  object \n",
            " 7   NAME_EDUCATION_TYPE  438557 non-null  object \n",
            " 8   NAME_FAMILY_STATUS   438557 non-null  object \n",
            " 9   NAME_HOUSING_TYPE    438557 non-null  object \n",
            " 10  DAYS_BIRTH           438557 non-null  int64  \n",
            " 11  DAYS_EMPLOYED        438557 non-null  int64  \n",
            " 12  FLAG_MOBIL           438557 non-null  int64  \n",
            " 13  FLAG_WORK_PHONE      438557 non-null  int64  \n",
            " 14  FLAG_PHONE           438557 non-null  int64  \n",
            " 15  FLAG_EMAIL           438557 non-null  int64  \n",
            " 16  OCCUPATION_TYPE      304354 non-null  object \n",
            " 17  CNT_FAM_MEMBERS      438557 non-null  float64\n",
            "dtypes: float64(2), int64(8), object(8)\n",
            "memory usage: 60.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cre.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W70pEKzFE0-k",
        "outputId": "529e85ba-9a96-4acb-cc3d-5001c5731636"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count    Dtype \n",
            "---  ------          --------------    ----- \n",
            " 0   ID              1048575 non-null  int64 \n",
            " 1   MONTHS_BALANCE  1048575 non-null  int64 \n",
            " 2   STATUS          1048575 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 24.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"3\"></a>\n",
        "## 3. Handling Duplicates and Missing Values"
      ],
      "metadata": {
        "id": "OvnBM-jXE_jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.ID.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR-qNwPc6Hv3",
        "outputId": "43ab4e36-dcf1-4a51-9a93-fdd69204b4d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "438510"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_ids = data_app[data_app.duplicated(subset=['ID'], keep=False)].sort_values('ID')\n",
        "duplicate_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "e67UFHs_87sx",
        "outputId": "eb2cc456-e3fd-4ce6-8935-9e719f5dbe07"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
              "426818  7022197           M            Y               Y             3   \n",
              "425023  7022197           F            N               Y             0   \n",
              "431545  7022327           F            N               Y             0   \n",
              "431911  7022327           M            Y               Y             0   \n",
              "425486  7023108           M            Y               Y             1   \n",
              "...         ...         ...          ...             ...           ...   \n",
              "426563  7836711           F            N               Y             2   \n",
              "421464  7836971           M            Y               N             1   \n",
              "428620  7836971           F            N               Y             0   \n",
              "422068  7838075           M            N               Y             0   \n",
              "423702  7838075           F            Y               Y             0   \n",
              "\n",
              "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
              "426818          135000.0               Working  Secondary / secondary special   \n",
              "425023          450000.0  Commercial associate               Higher education   \n",
              "431545          135000.0  Commercial associate  Secondary / secondary special   \n",
              "431911          256500.0  Commercial associate               Higher education   \n",
              "425486           67500.0               Working  Secondary / secondary special   \n",
              "...                  ...                   ...                            ...   \n",
              "426563          292500.0               Working               Higher education   \n",
              "421464          157500.0               Working  Secondary / secondary special   \n",
              "428620          103500.0               Working  Secondary / secondary special   \n",
              "422068          337500.0  Commercial associate  Secondary / secondary special   \n",
              "423702          315000.0  Commercial associate               Higher education   \n",
              "\n",
              "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
              "426818               Married  House / apartment      -11945           -735   \n",
              "425023             Separated  House / apartment      -19813          -1799   \n",
              "431545  Single / not married  House / apartment      -14771          -5298   \n",
              "431911               Married  House / apartment      -21503          -1674   \n",
              "425486               Married  House / apartment      -15156          -1696   \n",
              "...                      ...                ...         ...            ...   \n",
              "426563               Married  House / apartment      -13747          -4386   \n",
              "421464               Married  House / apartment      -13771          -5520   \n",
              "428620        Civil marriage  House / apartment      -13383          -2798   \n",
              "422068               Married  House / apartment      -18198          -1275   \n",
              "423702  Single / not married  House / apartment      -10698          -1659   \n",
              "\n",
              "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL  \\\n",
              "426818           1                0           0           1   \n",
              "425023           1                0           0           1   \n",
              "431545           1                0           0           0   \n",
              "431911           1                0           0           1   \n",
              "425486           1                1           0           0   \n",
              "...            ...              ...         ...         ...   \n",
              "426563           1                0           1           0   \n",
              "421464           1                0           0           0   \n",
              "428620           1                0           1           0   \n",
              "422068           1                0           0           1   \n",
              "423702           1                0           0           1   \n",
              "\n",
              "              OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
              "426818               Laborers              5.0  \n",
              "425023                    NaN              1.0  \n",
              "431545  High skill tech staff              1.0  \n",
              "431911             Core staff              2.0  \n",
              "425486             Core staff              3.0  \n",
              "...                       ...              ...  \n",
              "426563            Accountants              4.0  \n",
              "421464                    NaN              3.0  \n",
              "428620            Sales staff              2.0  \n",
              "422068                Drivers              2.0  \n",
              "423702                    NaN              1.0  \n",
              "\n",
              "[94 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de3f1f7-fed3-4df4-b78a-fa3dd73eb425\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <th>CNT_FAM_MEMBERS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>426818</th>\n",
              "      <td>7022197</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>3</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-11945</td>\n",
              "      <td>-735</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425023</th>\n",
              "      <td>7022197</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>450000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-19813</td>\n",
              "      <td>-1799</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431545</th>\n",
              "      <td>7022327</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-14771</td>\n",
              "      <td>-5298</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>High skill tech staff</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431911</th>\n",
              "      <td>7022327</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>256500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-21503</td>\n",
              "      <td>-1674</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425486</th>\n",
              "      <td>7023108</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>1</td>\n",
              "      <td>67500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-15156</td>\n",
              "      <td>-1696</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Core staff</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426563</th>\n",
              "      <td>7836711</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>2</td>\n",
              "      <td>292500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13747</td>\n",
              "      <td>-4386</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Accountants</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421464</th>\n",
              "      <td>7836971</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>157500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13771</td>\n",
              "      <td>-5520</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428620</th>\n",
              "      <td>7836971</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-13383</td>\n",
              "      <td>-2798</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422068</th>\n",
              "      <td>7838075</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>337500.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-18198</td>\n",
              "      <td>-1275</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Drivers</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423702</th>\n",
              "      <td>7838075</td>\n",
              "      <td>F</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>315000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-10698</td>\n",
              "      <td>-1659</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>94 rows  18 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de3f1f7-fed3-4df4-b78a-fa3dd73eb425')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8de3f1f7-fed3-4df4-b78a-fa3dd73eb425 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8de3f1f7-fed3-4df4-b78a-fa3dd73eb425');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9f60eda9-70b0-4643-8141-58434e56bf4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f60eda9-70b0-4643-8141-58434e56bf4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9f60eda9-70b0-4643-8141-58434e56bf4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_54759724-e169-44aa-a6ec-641dad9279d1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('duplicate_ids')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_54759724-e169-44aa-a6ec-641dad9279d1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('duplicate_ids');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "duplicate_ids",
              "summary": "{\n  \"name\": \"duplicate_ids\",\n  \"rows\": 94,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 301530,\n        \"min\": 7022197,\n        \"max\": 7838075,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          7317997,\n          7742853,\n          7282535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CODE_GENDER\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"F\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_OWN_CAR\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_OWN_REALTY\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"N\",\n          \"Y\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CNT_CHILDREN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMT_INCOME_TOTAL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 126393.74330209651,\n        \"min\": 47250.0,\n        \"max\": 900000.0,\n        \"num_unique_values\": 36,\n        \"samples\": [\n          337500.0,\n          117000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME_INCOME_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Commercial associate\",\n          \"State servant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME_EDUCATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Secondary / secondary special\",\n          \"Higher education\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME_FAMILY_STATUS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Separated\",\n          \"Widow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME_HOUSING_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Municipal apartment\",\n          \"Office apartment\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAYS_BIRTH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4137,\n        \"min\": -24708,\n        \"max\": -8246,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          -10518,\n          -17189\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DAYS_EMPLOYED\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 135240,\n        \"min\": -9433,\n        \"max\": 365243,\n        \"num_unique_values\": 79,\n        \"samples\": [\n          -279,\n          -735\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_MOBIL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_WORK_PHONE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_PHONE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLAG_EMAIL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OCCUPATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Drivers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CNT_FAM_MEMBERS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.960200924600074,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Understanding duplication"
      ],
      "metadata": {
        "id": "lWZ81-zlFjYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping duplicate IDs\n",
        "grouped_duplicates = duplicate_ids.groupby('ID')\n",
        "\n",
        "# Finding columns that differ\n",
        "differences = {}\n",
        "\n",
        "for client_id, group in grouped_duplicates:\n",
        "    # Find the columns that differ for each group\n",
        "    diff = group.loc[:, group.nunique() > 1]\n",
        "    differences[client_id] = diff\n",
        "\n",
        "# Printing the differences on the screen\n",
        "for client_id, diff in differences.items():\n",
        "    print(f\"ID: {client_id}\")\n",
        "    print(diff)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CpnlT3kU9dzI",
        "outputId": "05db1a4f-d4b2-4727-fb3d-6b559a544fb3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 7022197\n",
            "       CODE_GENDER FLAG_OWN_CAR  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "426818           M            Y             3          135000.0   \n",
            "425023           F            N             0          450000.0   \n",
            "\n",
            "            NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
            "426818               Working  Secondary / secondary special   \n",
            "425023  Commercial associate               Higher education   \n",
            "\n",
            "       NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "426818            Married      -11945           -735              5.0  \n",
            "425023          Separated      -19813          -1799              1.0  \n",
            "\n",
            "\n",
            "ID: 7022327\n",
            "       CODE_GENDER FLAG_OWN_CAR  AMT_INCOME_TOTAL  \\\n",
            "431545           F            N          135000.0   \n",
            "431911           M            Y          256500.0   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "431545  Secondary / secondary special  Single / not married      -14771   \n",
            "431911               Higher education               Married      -21503   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_EMAIL        OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "431545          -5298           0  High skill tech staff              1.0  \n",
            "431911          -1674           1             Core staff              2.0  \n",
            "\n",
            "\n",
            "ID: 7023108\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "425486           M            Y               Y             1   \n",
            "426488           F            N               N             0   \n",
            "\n",
            "        AMT_INCOME_TOTAL  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "425486           67500.0      -15156          -1696                1   \n",
            "426488          135000.0      -17590          -1273                0   \n",
            "\n",
            "       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "425486      Core staff              3.0  \n",
            "426488  Cleaning staff              2.0  \n",
            "\n",
            "\n",
            "ID: 7023651\n",
            "       CODE_GENDER FLAG_OWN_CAR  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "425306           F            N             0          225000.0   \n",
            "421907           M            Y             1          157500.0   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED OCCUPATION_TYPE  \\\n",
            "425306  Single / not married      -10229          -1209     Accountants   \n",
            "421907               Married      -10521          -1457         Drivers   \n",
            "\n",
            "        CNT_FAM_MEMBERS  \n",
            "425306              1.0  \n",
            "421907              3.0  \n",
            "\n",
            "\n",
            "ID: 7024111\n",
            "       CODE_GENDER FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "427778           M               N             2          157500.0   \n",
            "432643           F               Y             0          180000.0   \n",
            "\n",
            "            NAME_INCOME_TYPE NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "427778  Commercial associate     Civil marriage      -15270           -117   \n",
            "432643               Working            Married      -22041          -1524   \n",
            "\n",
            "        FLAG_PHONE OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "427778           0         Drivers              4.0  \n",
            "432643           1     Accountants              2.0  \n",
            "\n",
            "\n",
            "ID: 7036518\n",
            "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "424708               Y             0          360000.0   \n",
            "429078               N             1          180000.0   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "424708               Higher education      -15875          -1965   \n",
            "429078  Secondary / secondary special      -13858          -2612   \n",
            "\n",
            "        FLAG_WORK_PHONE OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "424708                1      Core staff              2.0  \n",
            "429078                0        Laborers              3.0  \n",
            "\n",
            "\n",
            "ID: 7045794\n",
            "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "427007               N             0          414000.0   \n",
            "428048               Y             2          225000.0   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "427007               Higher education          Separated      -20786   \n",
            "428048  Secondary / secondary special            Married      -14431   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_PHONE  CNT_FAM_MEMBERS  \n",
            "427007          -1447           0              1.0  \n",
            "428048           -507           1              4.0  \n",
            "\n",
            "\n",
            "ID: 7045885\n",
            "       CODE_GENDER FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "432271           F               N             2          247500.0   \n",
            "426022           M               Y             0           67500.0   \n",
            "\n",
            "            NAME_INCOME_TYPE NAME_FAMILY_STATUS    NAME_HOUSING_TYPE  \\\n",
            "432271  Commercial associate     Civil marriage  Municipal apartment   \n",
            "426022             Pensioner            Married    House / apartment   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  FLAG_PHONE  \\\n",
            "432271      -14452          -1624                1           1   \n",
            "426022      -20851         365243                0           0   \n",
            "\n",
            "        CNT_FAM_MEMBERS  \n",
            "432271              4.0  \n",
            "426022              2.0  \n",
            "\n",
            "\n",
            "ID: 7046068\n",
            "        AMT_INCOME_TOTAL NAME_INCOME_TYPE    NAME_FAMILY_STATUS  \\\n",
            "432134          112500.0          Working  Single / not married   \n",
            "424618          135000.0        Pensioner               Married   \n",
            "\n",
            "        NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_PHONE  \\\n",
            "432134   Rented apartment      -11888          -2781           0   \n",
            "424618  House / apartment      -22744         365243           1   \n",
            "\n",
            "        CNT_FAM_MEMBERS  \n",
            "432134              1.0  \n",
            "424618              2.0  \n",
            "\n",
            "\n",
            "ID: 7050948\n",
            "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "428171               N             0          135000.0  Commercial associate   \n",
            "430746               Y             1           81000.0               Working   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "428171               Married      -12256          -4031                1   \n",
            "430746  Single / not married      -13977           -148                0   \n",
            "\n",
            "        FLAG_PHONE  FLAG_EMAIL  \n",
            "428171           1           1  \n",
            "430746           0           0  \n",
            "\n",
            "\n",
            "ID: 7052783\n",
            "        CNT_CHILDREN  AMT_INCOME_TOTAL            NAME_EDUCATION_TYPE  \\\n",
            "422660             2          166500.0  Secondary / secondary special   \n",
            "421726             0          157500.0               Higher education   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL  \\\n",
            "422660      -15883          -2697                1           0           1   \n",
            "421726      -13428          -2589                0           1           0   \n",
            "\n",
            "       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "422660        Managers              4.0  \n",
            "421726        Laborers              2.0  \n",
            "\n",
            "\n",
            "ID: 7052812\n",
            "        AMT_INCOME_TOTAL    NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "431414          117000.0               Married      -17189          -4523   \n",
            "422119          135000.0  Single / not married      -15002           -123   \n",
            "\n",
            "       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "431414        Managers              2.0  \n",
            "422119     Accountants              1.0  \n",
            "\n",
            "\n",
            "ID: 7053557\n",
            "       FLAG_OWN_CAR  AMT_INCOME_TOTAL            NAME_EDUCATION_TYPE  \\\n",
            "423852            N          315000.0              Incomplete higher   \n",
            "424480            Y          193500.0  Secondary / secondary special   \n",
            "\n",
            "        NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "423852       With parents      -12417           -245                0   \n",
            "424480  House / apartment      -10439          -2250                1   \n",
            "\n",
            "        FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \n",
            "423852           1           1        Managers  \n",
            "424480           0           0      Core staff  \n",
            "\n",
            "\n",
            "ID: 7089090\n",
            "       FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "425539               N          180000.0               Working   \n",
            "426198               Y          189000.0  Commercial associate   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_PHONE  \\\n",
            "425539  Secondary / secondary special      -14167           -735           1   \n",
            "426198              Incomplete higher      -10045          -1730           0   \n",
            "\n",
            "       OCCUPATION_TYPE  \n",
            "425539        Laborers  \n",
            "426198      Core staff  \n",
            "\n",
            "\n",
            "ID: 7090931\n",
            "       FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
            "429834            N               Y          157500.0   \n",
            "423076            Y               N          202500.0   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "429834               Higher education            Married       -8246   \n",
            "423076  Secondary / secondary special     Civil marriage      -14228   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_PHONE  FLAG_EMAIL  \n",
            "429834          -1490           0           1  \n",
            "423076          -5330           1           0  \n",
            "\n",
            "\n",
            "ID: 7091721\n",
            "       CODE_GENDER  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "433666           F           90000.0  Commercial associate   \n",
            "423143           M          441000.0         State servant   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "433666  Secondary / secondary special      -14116          -2269   \n",
            "423143               Higher education      -18766          -8883   \n",
            "\n",
            "        FLAG_WORK_PHONE  FLAG_EMAIL  \n",
            "433666                0           0  \n",
            "423143                1           1  \n",
            "\n",
            "\n",
            "ID: 7099881\n",
            "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
            "432426          112500.0  Commercial associate              Incomplete higher   \n",
            "424224          157500.0             Pensioner  Secondary / secondary special   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_EMAIL  \n",
            "432426  Single / not married      -10244           -279           1  \n",
            "424224                 Widow      -23066         365243           0  \n",
            "\n",
            "\n",
            "ID: 7135270\n",
            "        CNT_CHILDREN  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  DAYS_BIRTH  \\\n",
            "433217             0          216000.0             Pensioner      -23113   \n",
            "431201             2          405000.0  Commercial associate      -13662   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_EMAIL  CNT_FAM_MEMBERS  \n",
            "433217         365243           0              2.0  \n",
            "431201          -2730           1              4.0  \n",
            "\n",
            "\n",
            "ID: 7137299\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "423160           M            Y               N             1   \n",
            "426665           F            N               Y             0   \n",
            "\n",
            "        AMT_INCOME_TOTAL    NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  \\\n",
            "423160          225000.0               Married  House / apartment      -15243   \n",
            "426665          292500.0  Single / not married   Office apartment      -19679   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_WORK_PHONE  FLAG_PHONE        OCCUPATION_TYPE  \\\n",
            "423160          -7260                1           1  High skill tech staff   \n",
            "426665          -2074                0           0         Cleaning staff   \n",
            "\n",
            "        CNT_FAM_MEMBERS  \n",
            "423160              3.0  \n",
            "426665              1.0  \n",
            "\n",
            "\n",
            "ID: 7154598\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
            "427164           M            Y               N          135000.0   \n",
            "432088           F            N               Y          157500.0   \n",
            "\n",
            "            NAME_INCOME_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "427164               Working      -16101           -430                1   \n",
            "432088  Commercial associate      -17711          -3108                0   \n",
            "\n",
            "              OCCUPATION_TYPE  \n",
            "427164                Drivers  \n",
            "432088  High skill tech staff  \n",
            "\n",
            "\n",
            "ID: 7154819\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "428168           M            Y               Y             1   \n",
            "427287           F            N               N             0   \n",
            "\n",
            "        AMT_INCOME_TOTAL NAME_INCOME_TYPE    NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "428168          225000.0          Working               Married      -10518   \n",
            "427287           58500.0        Pensioner  Single / not married      -21971   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_WORK_PHONE  CNT_FAM_MEMBERS  \n",
            "428168          -3716                1              3.0  \n",
            "427287         365243                0              1.0  \n",
            "\n",
            "\n",
            "ID: 7155150\n",
            "       FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  \\\n",
            "429029            N               Y             2           90000.0   \n",
            "422747            Y               N             0          157500.0   \n",
            "\n",
            "       NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "429029            Married  House / apartment      -10404          -2073   \n",
            "422747     Civil marriage       With parents      -12918          -1411   \n",
            "\n",
            "        FLAG_WORK_PHONE  FLAG_PHONE  CNT_FAM_MEMBERS  \n",
            "429029                1           1              4.0  \n",
            "422747                0           0              2.0  \n",
            "\n",
            "\n",
            "ID: 7174719\n",
            "       FLAG_OWN_CAR  AMT_INCOME_TOTAL NAME_INCOME_TYPE  DAYS_BIRTH  \\\n",
            "430756            Y          112500.0          Working      -17835   \n",
            "428911            N           92250.0        Pensioner      -20275   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_WORK_PHONE  FLAG_PHONE  \n",
            "430756          -1742                1           1  \n",
            "428911         365243                0           0  \n",
            "\n",
            "\n",
            "ID: 7207977\n",
            "       FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "427114               Y          315000.0             Pensioner   \n",
            "427883               N          270000.0  Commercial associate   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "427114               Higher education               Married      -23688   \n",
            "427883  Secondary / secondary special  Single / not married      -16860   \n",
            "\n",
            "        DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "427114         365243              2.0  \n",
            "427883          -1002              1.0  \n",
            "\n",
            "\n",
            "ID: 7213374\n",
            "       FLAG_OWN_CAR  CNT_CHILDREN  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "421698            Y             0          148500.0               Working   \n",
            "425724            N             1          270000.0  Commercial associate   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "421698  Secondary / secondary special       -9950           -961   \n",
            "425724               Higher education      -14317          -1052   \n",
            "\n",
            "       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "421698        Laborers              2.0  \n",
            "425724        Managers              3.0  \n",
            "\n",
            "\n",
            "ID: 7243768\n",
            "       CODE_GENDER  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "429121           F          157500.0               Working   \n",
            "426018           M          135000.0  Commercial associate   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "429121               Higher education      -16794          -9433   \n",
            "426018  Secondary / secondary special      -19238          -1789   \n",
            "\n",
            "              OCCUPATION_TYPE  \n",
            "429121  High skill tech staff  \n",
            "426018             Core staff  \n",
            "\n",
            "\n",
            "ID: 7282535\n",
            "       FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "428166               N             1          202500.0  Commercial associate   \n",
            "433158               Y             0           63000.0             Pensioner   \n",
            "\n",
            "       NAME_FAMILY_STATUS    NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "428166     Civil marriage  Municipal apartment      -16819           -521   \n",
            "433158            Married    House / apartment      -21124         365243   \n",
            "\n",
            "        FLAG_PHONE  CNT_FAM_MEMBERS  \n",
            "428166           0              3.0  \n",
            "433158           1              2.0  \n",
            "\n",
            "\n",
            "ID: 7317997\n",
            "       CODE_GENDER  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  NAME_HOUSING_TYPE  \\\n",
            "429053           F          135000.0               Working       With parents   \n",
            "423794           M          900000.0  Commercial associate  House / apartment   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_EMAIL OCCUPATION_TYPE  \n",
            "429053      -12107           -150           1      Core staff  \n",
            "423794      -15962           -941           0        Managers  \n",
            "\n",
            "\n",
            "ID: 7372589\n",
            "       FLAG_OWN_CAR  AMT_INCOME_TOTAL NAME_INCOME_TYPE    NAME_FAMILY_STATUS  \\\n",
            "422326            N          112500.0        Pensioner                 Widow   \n",
            "432562            Y           94500.0          Working  Single / not married   \n",
            "\n",
            "          NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \n",
            "422326    House / apartment      -22334         365243  \n",
            "432562  Municipal apartment      -10666          -1093  \n",
            "\n",
            "\n",
            "ID: 7416167\n",
            "       CODE_GENDER FLAG_OWN_CAR  AMT_INCOME_TOTAL NAME_INCOME_TYPE  \\\n",
            "428802           M            Y          135000.0          Working   \n",
            "428632           F            N          315000.0        Pensioner   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "428802  Single / not married      -10083           -523              1.0  \n",
            "428632        Civil marriage      -23092         365243              2.0  \n",
            "\n",
            "\n",
            "ID: 7576316\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "424151           M            Y               Y             0   \n",
            "426325           F            N               N             1   \n",
            "\n",
            "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE    NAME_FAMILY_STATUS  \\\n",
            "424151           94500.0             Pensioner               Married   \n",
            "426325          405000.0  Commercial associate  Single / not married   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  FLAG_PHONE  \n",
            "424151      -22407         365243                0           0  \n",
            "426325      -11994           -170                1           1  \n",
            "\n",
            "\n",
            "ID: 7602432\n",
            "       CODE_GENDER FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "421268           M               Y          315000.0  Commercial associate   \n",
            "421349           F               N          117000.0             Pensioner   \n",
            "\n",
            "       NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_PHONE  \n",
            "421268     Civil marriage      -16627          -1304           1  \n",
            "421349            Married      -24708         365243           0  \n",
            "\n",
            "\n",
            "ID: 7603224\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
            "430187           F            N               N           47250.0   \n",
            "425235           M            Y               Y          540000.0   \n",
            "\n",
            "            NAME_INCOME_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_EMAIL  \n",
            "430187             Pensioner      -21889         365243           0  \n",
            "425235  Commercial associate      -15971          -3050           1  \n",
            "\n",
            "\n",
            "ID: 7618285\n",
            "       CODE_GENDER FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "433789           F               Y          157500.0               Working   \n",
            "427016           M               N          135000.0  Commercial associate   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "433789  Single / not married      -10113          -1007              1.0  \n",
            "427016               Married      -19726          -2788              2.0  \n",
            "\n",
            "\n",
            "ID: 7636389\n",
            "       CODE_GENDER FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "422077           M               N          135000.0  Commercial associate   \n",
            "427167           F               Y          112500.0               Working   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_EMAIL  \n",
            "422077               Higher education       -9624           -666           0  \n",
            "427167  Secondary / secondary special      -11367           -513           1  \n",
            "\n",
            "\n",
            "ID: 7636756\n",
            "        AMT_INCOME_TOTAL NAME_INCOME_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "432355           76500.0          Working      -16930           -301   \n",
            "423592          103500.0    State servant      -15205           -455   \n",
            "\n",
            "        FLAG_PHONE OCCUPATION_TYPE  \n",
            "432355           0        Laborers  \n",
            "423592           1      Core staff  \n",
            "\n",
            "\n",
            "ID: 7702238\n",
            "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "428986          202500.0               Working            Married      -11979   \n",
            "425624          135000.0  Commercial associate     Civil marriage      -17871   \n",
            "\n",
            "        DAYS_EMPLOYED OCCUPATION_TYPE  \n",
            "428986          -2959     Sales staff  \n",
            "425624          -1743      Core staff  \n",
            "\n",
            "\n",
            "ID: 7702516\n",
            "        CNT_CHILDREN  AMT_INCOME_TOTAL  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "432379             1          117000.0      -11575          -4270   \n",
            "421211             2          180000.0      -11753          -1256   \n",
            "\n",
            "        FLAG_WORK_PHONE  FLAG_PHONE OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "432379                0           0  Medicine staff              3.0  \n",
            "421211                1           1     Sales staff              4.0  \n",
            "\n",
            "\n",
            "ID: 7742298\n",
            "       CODE_GENDER FLAG_OWN_REALTY  AMT_INCOME_TOTAL NAME_FAMILY_STATUS  \\\n",
            "424819           F               Y          144000.0              Widow   \n",
            "430436           M               N          112500.0            Married   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  CNT_FAM_MEMBERS  \n",
            "424819      -20626          -1455                0              1.0  \n",
            "430436      -18239          -5428                1              2.0  \n",
            "\n",
            "\n",
            "ID: 7742853\n",
            "       CODE_GENDER  CNT_CHILDREN  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "433159           M             0          157500.0               Working   \n",
            "423874           F             1          360000.0  Commercial associate   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "433159  Secondary / secondary special  Single / not married      -15052   \n",
            "423874               Higher education               Married      -11816   \n",
            "\n",
            "        DAYS_EMPLOYED  FLAG_PHONE OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "433159          -1695           0        Laborers              1.0  \n",
            "423874           -683           1     Accountants              3.0  \n",
            "\n",
            "\n",
            "ID: 7743418\n",
            "       CODE_GENDER FLAG_OWN_CAR  AMT_INCOME_TOTAL NAME_FAMILY_STATUS  \\\n",
            "426845           F            N          112500.0            Married   \n",
            "429337           M            Y          405000.0     Civil marriage   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  FLAG_PHONE  \n",
            "426845      -17389          -2108           0  \n",
            "429337      -17750          -1573           1  \n",
            "\n",
            "\n",
            "ID: 7744386\n",
            "       CODE_GENDER  AMT_INCOME_TOTAL            NAME_EDUCATION_TYPE  \\\n",
            "431391           M          315000.0              Incomplete higher   \n",
            "423327           F           81000.0  Secondary / secondary special   \n",
            "\n",
            "          NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "431391  Single / not married      -15392           -494                1   \n",
            "423327        Civil marriage      -18835           -389                0   \n",
            "\n",
            "       OCCUPATION_TYPE  CNT_FAM_MEMBERS  \n",
            "431391        Managers              1.0  \n",
            "423327   Cooking staff              2.0  \n",
            "\n",
            "\n",
            "ID: 7772847\n",
            "       FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL      NAME_INCOME_TYPE  \\\n",
            "429104            N               N          180000.0             Pensioner   \n",
            "423416            Y               Y          225000.0  Commercial associate   \n",
            "\n",
            "       NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "429104              Widow   Office apartment      -22039         365243   \n",
            "423416            Married  House / apartment      -15121          -1642   \n",
            "\n",
            "        FLAG_PHONE  CNT_FAM_MEMBERS  \n",
            "429104           0              1.0  \n",
            "423416           1              2.0  \n",
            "\n",
            "\n",
            "ID: 7833087\n",
            "       CODE_GENDER  AMT_INCOME_TOTAL      NAME_INCOME_TYPE NAME_FAMILY_STATUS  \\\n",
            "429228           F           90000.0             Pensioner              Widow   \n",
            "430284           M          157500.0  Commercial associate            Married   \n",
            "\n",
            "        DAYS_BIRTH  DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "429228      -21725         365243              1.0  \n",
            "430284      -15961          -2216              2.0  \n",
            "\n",
            "\n",
            "ID: 7836711\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
            "426714           M            Y               N          315000.0   \n",
            "426563           F            N               Y          292500.0   \n",
            "\n",
            "       NAME_INCOME_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  FLAG_WORK_PHONE  \\\n",
            "426714    State servant      -11649          -1517                1   \n",
            "426563          Working      -13747          -4386                0   \n",
            "\n",
            "       OCCUPATION_TYPE  \n",
            "426714        Managers  \n",
            "426563     Accountants  \n",
            "\n",
            "\n",
            "ID: 7836971\n",
            "       CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "421464           M            Y               N             1   \n",
            "428620           F            N               Y             0   \n",
            "\n",
            "        AMT_INCOME_TOTAL NAME_FAMILY_STATUS  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "421464          157500.0            Married      -13771          -5520   \n",
            "428620          103500.0     Civil marriage      -13383          -2798   \n",
            "\n",
            "        FLAG_PHONE  CNT_FAM_MEMBERS  \n",
            "421464           0              3.0  \n",
            "428620           1              2.0  \n",
            "\n",
            "\n",
            "ID: 7838075\n",
            "       CODE_GENDER FLAG_OWN_CAR  AMT_INCOME_TOTAL  \\\n",
            "422068           M            N          337500.0   \n",
            "423702           F            Y          315000.0   \n",
            "\n",
            "                  NAME_EDUCATION_TYPE    NAME_FAMILY_STATUS  DAYS_BIRTH  \\\n",
            "422068  Secondary / secondary special               Married      -18198   \n",
            "423702               Higher education  Single / not married      -10698   \n",
            "\n",
            "        DAYS_EMPLOYED  CNT_FAM_MEMBERS  \n",
            "422068          -1275              2.0  \n",
            "423702          -1659              1.0  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "Since we cannot make a clear assumption about the reason for the changing data, we will generalize and assume that there are repeated data due to incorrect data entries or changes depending on time, and choose the last one."
      ],
      "metadata": {
        "id": "9SDel01y_Cdp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Drop duplicate IDs"
      ],
      "metadata": {
        "id": "mcoWFxxOGIJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app = data_app.drop_duplicates(subset=['ID'], keep='last')"
      ],
      "metadata": {
        "id": "l-LFT2k55433"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Check Null values"
      ],
      "metadata": {
        "id": "THj0CqyBGaQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "XjH6wBYV6AN3",
        "outputId": "1244516b-a2be-4f46-efc7-661f4144cf09"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                          0\n",
              "CODE_GENDER                 0\n",
              "FLAG_OWN_CAR                0\n",
              "FLAG_OWN_REALTY             0\n",
              "CNT_CHILDREN                0\n",
              "AMT_INCOME_TOTAL            0\n",
              "NAME_INCOME_TYPE            0\n",
              "NAME_EDUCATION_TYPE         0\n",
              "NAME_FAMILY_STATUS          0\n",
              "NAME_HOUSING_TYPE           0\n",
              "DAYS_BIRTH                  0\n",
              "DAYS_EMPLOYED               0\n",
              "FLAG_MOBIL                  0\n",
              "FLAG_WORK_PHONE             0\n",
              "FLAG_PHONE                  0\n",
              "FLAG_EMAIL                  0\n",
              "OCCUPATION_TYPE        134187\n",
              "CNT_FAM_MEMBERS             0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNT_CHILDREN</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_MOBIL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <td>134187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNT_FAM_MEMBERS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_cre.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "aX9kcd3piUu2",
        "outputId": "697d15ce-46c5-43cb-cffd-b1be36838fdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                0\n",
              "MONTHS_BALANCE    0\n",
              "STATUS            0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MONTHS_BALANCE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>STATUS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Take action for Nulls"
      ],
      "metadata": {
        "id": "KXN9kyvFGoRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app['OCCUPATION_TYPE'].fillna('Unknown', inplace=True)"
      ],
      "metadata": {
        "id": "dOvlpdgZEpMr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"4\"></a>\n",
        "## 4. Feature Analysis and Manupulation"
      ],
      "metadata": {
        "id": "YwDvkNAtANRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_values_sorted(df: pd.DataFrame, columns: List[str]) -> Dict[str, List[Any]]:\n",
        "    valid_columns = df.columns.intersection(columns)\n",
        "\n",
        "    def safe_sort(values):\n",
        "        try:\n",
        "            return sorted(values)\n",
        "        except TypeError:\n",
        "            return sorted(map(str, values))\n",
        "\n",
        "    return {col: safe_sort(df[col].unique()) for col in valid_columns}"
      ],
      "metadata": {
        "id": "W-TBQhfrHyEL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Application Record Data"
      ],
      "metadata": {
        "id": "gsD4RPEaHGlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['CODE_GENDER', 'FLAG_OWN_CAR ', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
        "                    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
        "                    'NAME_HOUSING_TYPE', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
        "                    'FLAG_EMAIL', 'OCCUPATION_TYPE ', 'CNT_FAM_MEMBERS']"
      ],
      "metadata": {
        "id": "3PatyxDCIJrj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = unique_values_sorted(data_app, selected_columns)\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNxLaYBWEOr3",
        "outputId": "e436c325-de59-467c-f1e6-b97eafa9214c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CNT_CHILDREN': [0, 1, 2, 3, 4, 5, 6, 7, 9, 12, 14, 19],\n",
            " 'CNT_FAM_MEMBERS': [1.0,\n",
            "                     2.0,\n",
            "                     3.0,\n",
            "                     4.0,\n",
            "                     5.0,\n",
            "                     6.0,\n",
            "                     7.0,\n",
            "                     8.0,\n",
            "                     9.0,\n",
            "                     11.0,\n",
            "                     14.0,\n",
            "                     15.0,\n",
            "                     20.0],\n",
            " 'CODE_GENDER': ['F', 'M'],\n",
            " 'FLAG_EMAIL': [0, 1],\n",
            " 'FLAG_MOBIL': [1],\n",
            " 'FLAG_OWN_REALTY': ['N', 'Y'],\n",
            " 'FLAG_PHONE': [0, 1],\n",
            " 'FLAG_WORK_PHONE': [0, 1],\n",
            " 'NAME_EDUCATION_TYPE': ['Academic degree',\n",
            "                         'Higher education',\n",
            "                         'Incomplete higher',\n",
            "                         'Lower secondary',\n",
            "                         'Secondary / secondary special'],\n",
            " 'NAME_FAMILY_STATUS': ['Civil marriage',\n",
            "                        'Married',\n",
            "                        'Separated',\n",
            "                        'Single / not married',\n",
            "                        'Widow'],\n",
            " 'NAME_HOUSING_TYPE': ['Co-op apartment',\n",
            "                       'House / apartment',\n",
            "                       'Municipal apartment',\n",
            "                       'Office apartment',\n",
            "                       'Rented apartment',\n",
            "                       'With parents'],\n",
            " 'NAME_INCOME_TYPE': ['Commercial associate',\n",
            "                      'Pensioner',\n",
            "                      'State servant',\n",
            "                      'Student',\n",
            "                      'Working']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n"
      ],
      "metadata": {
        "id": "9sygVhtPKT_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The FLAG_MOBIL column contains only a single unique value (1), which means it does not carry any information for your model and will be removed from the dataset."
      ],
      "metadata": {
        "id": "phHedNEuLDbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can start creating the **scenario** at this step: Part-1\n",
        "\n",
        "Let's begin by manipulating the CNT_CHILDREN and CNT_FAM_MEMBERS data.\n",
        "\n",
        "First, calculate the number of adults in the family and add this information to our dataset. Then, drop the columns we have worked on."
      ],
      "metadata": {
        "id": "HzsxWZ0CMzz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.drop('FLAG_MOBIL', inplace=True, axis = 1)"
      ],
      "metadata": {
        "id": "bpjfolzGQiXu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_app['CNT_ADLT_FAM_MEMBERS'] = data_app['CNT_FAM_MEMBERS'] - data_app['CNT_CHILDREN']\n",
        "data_app.loc[data_app['CNT_ADLT_FAM_MEMBERS'] <= 0, 'CNT_ADLT_FAM_MEMBERS'] = data_app['CNT_FAM_MEMBERS']"
      ],
      "metadata": {
        "id": "5UrGNYm-Rx7R"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_app.drop(columns=['CNT_CHILDREN', 'CNT_FAM_MEMBERS'], inplace=True)"
      ],
      "metadata": {
        "id": "sxipbn7PQWXe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns.append('CNT_ADLT_FAM_MEMBERS')"
      ],
      "metadata": {
        "id": "253EmYoqNcgB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = unique_values_sorted(data_app, selected_columns)\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsIUWnuJNVmg",
        "outputId": "c223b029-304d-49e6-cac7-0157414c3f7d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'CNT_ADLT_FAM_MEMBERS': [1.0, 2.0],\n",
            " 'CODE_GENDER': ['F', 'M'],\n",
            " 'FLAG_EMAIL': [0, 1],\n",
            " 'FLAG_OWN_REALTY': ['N', 'Y'],\n",
            " 'FLAG_PHONE': [0, 1],\n",
            " 'FLAG_WORK_PHONE': [0, 1],\n",
            " 'NAME_EDUCATION_TYPE': ['Academic degree',\n",
            "                         'Higher education',\n",
            "                         'Incomplete higher',\n",
            "                         'Lower secondary',\n",
            "                         'Secondary / secondary special'],\n",
            " 'NAME_FAMILY_STATUS': ['Civil marriage',\n",
            "                        'Married',\n",
            "                        'Separated',\n",
            "                        'Single / not married',\n",
            "                        'Widow'],\n",
            " 'NAME_HOUSING_TYPE': ['Co-op apartment',\n",
            "                       'House / apartment',\n",
            "                       'Municipal apartment',\n",
            "                       'Office apartment',\n",
            "                       'Rented apartment',\n",
            "                       'With parents'],\n",
            " 'NAME_INCOME_TYPE': ['Commercial associate',\n",
            "                      'Pensioner',\n",
            "                      'State servant',\n",
            "                      'Student',\n",
            "                      'Working']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario Evaluation**\n",
        "\n",
        "The newly created CNT_ADLT_FAM_MEMBERS data will show us whether there are adults around the person who can provide support.\n",
        "\n",
        "The underlying logic: As is well known, the foundation of banking is built on the payments it receives from its customers. Here, we focused more on the number of people who can assist the customer with their payments rather than the number of dependents the customer has, and we created a new feature for ourselves."
      ],
      "metadata": {
        "id": "5lBhCD5-SQzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Credit Record Data"
      ],
      "metadata": {
        "id": "womEY5TyWx3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "We need to understand the logic behind this dataset. In short, it contains payment information for customers who use credit cards."
      ],
      "metadata": {
        "id": "8kuFHa7ZZsAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['STATUS']"
      ],
      "metadata": {
        "id": "oqi3H4RudQov"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = unique_values_sorted(data_cre, selected_columns)\n",
        "pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx2MzjXxx0TD",
        "outputId": "08b06fff-ea81-42fd-cc8f-5d8aaefe28fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'STATUS': ['0', '1', '2', '3', '4', '5', 'C', 'X']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuing Our Scenario: Part-2**\n",
        "Let's continue the fun by gradually building our main story.\n",
        "At this stage, let's start approaching the logic of Turkish banking. Let's examine the main information that will help us get an idea:\n",
        "- Very good  1700-1900. (Credit card is given with eyes closed)\n",
        "- Good  1500-1699. (Credit card can be given with one eye closed)\n",
        "- Normal  1100-1499. (Credit card can be given with eyes open)\n",
        "- Medium risk  700-1099. (Credit card is not given with eyes open)\n",
        "- Risky  1-699. (Credit card is not given with one eye closed)\n",
        "- High risk  0. (Credit card is not given with eyes closed)"
      ],
      "metadata": {
        "id": "pYyL6n_kZsQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To keep up with our scenario, let's start scoring in this dataset.\n",
        "\n",
        "- 0: 1-29 days past due => -100 points\n",
        "- 1: 30-59 days past due => -300 points\n",
        "- 2: 60-89 days overdue => -500 points\n",
        "- 3: 90-119 days overdue => -700 points\n",
        "- 4: 120-149 days overdue => -900 points\n",
        "- 5: Overdue or bad debts, write-offs for more than 150 days => -1500 points\n",
        "- C: paid off that month => 1000 points\n",
        "- X: No loan for the month => 0 points\n",
        "\n",
        "The scoring might be a bit harsh or unrealistic, but let's remember that our goal is not to reach the truth but to get as close to it as possible."
      ],
      "metadata": {
        "id": "EcI98k4wcFFE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"5\"></a>\n",
        "## 5. Credit Scoring Calculation"
      ],
      "metadata": {
        "id": "KQWZKBahgfkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Score map\n",
        "status_score_map = {\n",
        "    '0': -100,\n",
        "    '1': -300,\n",
        "    '2': -500,\n",
        "    '3': -700,\n",
        "    '4': -900,\n",
        "    '5': -1500,\n",
        "    'C': 1000,\n",
        "    'X': 0\n",
        "}\n",
        "\n",
        "# Calculate points based on STATUS column\n",
        "data_cre['CREDIT_SCORE'] = data_cre['STATUS'].map(status_score_map)\n",
        "\n",
        "# Calculate total score for each customer\n",
        "result = data_cre.groupby('ID')['CREDIT_SCORE'].sum().reset_index()"
      ],
      "metadata": {
        "id": "8PWgLk920gOF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.describe()"
      ],
      "metadata": {
        "id": "4_PNWw8aFHik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "bbb6273a-16e9-4168-dda3-c78fdb5b4045"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 ID  CREDIT_SCORE\n",
              "count  4.598500e+04  45985.000000\n",
              "mean   5.070164e+06   8633.115146\n",
              "std    4.543364e+04  13788.124782\n",
              "min    5.001711e+06 -72100.000000\n",
              "25%    5.026147e+06   -700.000000\n",
              "50%    5.065737e+06      0.000000\n",
              "75%    5.114024e+06  15500.000000\n",
              "max    5.150487e+06  59900.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53a0078c-48d6-431d-9a8c-e2285c74484b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.598500e+04</td>\n",
              "      <td>45985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.070164e+06</td>\n",
              "      <td>8633.115146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.543364e+04</td>\n",
              "      <td>13788.124782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.001711e+06</td>\n",
              "      <td>-72100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.026147e+06</td>\n",
              "      <td>-700.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.065737e+06</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.114024e+06</td>\n",
              "      <td>15500.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.150487e+06</td>\n",
              "      <td>59900.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53a0078c-48d6-431d-9a8c-e2285c74484b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53a0078c-48d6-431d-9a8c-e2285c74484b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53a0078c-48d6-431d-9a8c-e2285c74484b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9bcd3c74-9db9-4a53-b0f9-4a301921476d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bcd3c74-9db9-4a53-b0f9-4a301921476d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9bcd3c74-9db9-4a53-b0f9-4a301921476d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2326893.485694246,\n        \"min\": 45433.63587058629,\n        \"max\": 5150487.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          5070163.913058606,\n          5065737.0,\n          45985.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CREDIT_SCORE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39235.89377732859,\n        \"min\": -72100.0,\n        \"max\": 59900.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8633.11514624334,\n          0.0,\n          45985.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"6\"></a>\n",
        "## 6. Merging and Preprocessing Datasets"
      ],
      "metadata": {
        "id": "YICfykYzis9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Join by ID column (outer join)\n",
        "merged_df = pd.merge(data_app, result, on='ID', how='left')"
      ],
      "metadata": {
        "id": "6eTaf4EajPYt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "9pdFVo-VkALM",
        "outputId": "ecb3c9e3-834d-4e36-e73f-26e394ba2732"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                           0\n",
              "CODE_GENDER                  0\n",
              "FLAG_OWN_CAR                 0\n",
              "FLAG_OWN_REALTY              0\n",
              "AMT_INCOME_TOTAL             0\n",
              "NAME_INCOME_TYPE             0\n",
              "NAME_EDUCATION_TYPE          0\n",
              "NAME_FAMILY_STATUS           0\n",
              "NAME_HOUSING_TYPE            0\n",
              "DAYS_BIRTH                   0\n",
              "DAYS_EMPLOYED                0\n",
              "FLAG_WORK_PHONE              0\n",
              "FLAG_PHONE                   0\n",
              "FLAG_EMAIL                   0\n",
              "OCCUPATION_TYPE              0\n",
              "CNT_ADLT_FAM_MEMBERS         0\n",
              "CREDIT_SCORE            402053\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAYS_BIRTH</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CNT_ADLT_FAM_MEMBERS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "      <td>402053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scenario continued: Part-3**\n",
        "\n",
        "Here we assign a value of 0 to those with no credit history"
      ],
      "metadata": {
        "id": "c2Wx9lCHh0SL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the value 0 to the CREDIT_SCORE column\n",
        "merged_df['CREDIT_SCORE'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "BTIjcec9pem4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulating"
      ],
      "metadata": {
        "id": "siLY0UTXxqky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working on DAYS_BIRTH**"
      ],
      "metadata": {
        "id": "-QphnqqMzIQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DAYS_BIRTH column to numeric type\n",
        "merged_df['DAYS_BIRTH'] = pd.to_numeric(merged_df['DAYS_BIRTH'], errors='coerce')\n",
        "\n",
        "# Convert DAYS_BIRTH column to age in days\n",
        "merged_df['AGE'] = (merged_df['DAYS_BIRTH'] / -365.25).astype(int)\n",
        "\n",
        "# Delete DAYS BIRTHDAY column\n",
        "merged_df.drop('DAYS_BIRTH', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "IwRdaFEDp5eK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working on DAYS_EMPLOYED**"
      ],
      "metadata": {
        "id": "GlZChcoh02Wa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this Feature, we will assign average DAYS_EMPLOYED to the existing unreal values according to the new AGE_GROUP and INCOME_GROUP Features that we will create. Then we will convert it to month."
      ],
      "metadata": {
        "id": "u_tbFpCYZzQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "n0lTVSgVyXm_",
        "outputId": "0e4fc32f-c877-4e45-d8d8-a1df3aa43252"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
              "0       5008804           M            Y               Y          427500.0   \n",
              "1       5008805           M            Y               Y          427500.0   \n",
              "2       5008806           M            Y               Y          112500.0   \n",
              "3       5008808           F            N               Y          270000.0   \n",
              "4       5008809           F            N               Y          270000.0   \n",
              "...         ...         ...          ...             ...               ...   \n",
              "438505  6840104           M            N               Y          135000.0   \n",
              "438506  6840222           F            N               N          103500.0   \n",
              "438507  6841878           F            N               N           54000.0   \n",
              "438508  6842765           F            N               Y           72000.0   \n",
              "438509  6842885           F            N               Y          121500.0   \n",
              "\n",
              "            NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
              "0                    Working               Higher education   \n",
              "1                    Working               Higher education   \n",
              "2                    Working  Secondary / secondary special   \n",
              "3       Commercial associate  Secondary / secondary special   \n",
              "4       Commercial associate  Secondary / secondary special   \n",
              "...                      ...                            ...   \n",
              "438505             Pensioner  Secondary / secondary special   \n",
              "438506               Working  Secondary / secondary special   \n",
              "438507  Commercial associate               Higher education   \n",
              "438508             Pensioner  Secondary / secondary special   \n",
              "438509               Working  Secondary / secondary special   \n",
              "\n",
              "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_EMPLOYED  \\\n",
              "0             Civil marriage   Rented apartment          -4542   \n",
              "1             Civil marriage   Rented apartment          -4542   \n",
              "2                    Married  House / apartment          -1134   \n",
              "3       Single / not married  House / apartment          -3051   \n",
              "4       Single / not married  House / apartment          -3051   \n",
              "...                      ...                ...            ...   \n",
              "438505             Separated  House / apartment         365243   \n",
              "438506  Single / not married  House / apartment          -3007   \n",
              "438507  Single / not married       With parents           -372   \n",
              "438508               Married  House / apartment         365243   \n",
              "438509               Married  House / apartment          -1201   \n",
              "\n",
              "        FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
              "0                     1           0           0         Unknown   \n",
              "1                     1           0           0         Unknown   \n",
              "2                     0           0           0  Security staff   \n",
              "3                     0           1           1     Sales staff   \n",
              "4                     0           1           1     Sales staff   \n",
              "...                 ...         ...         ...             ...   \n",
              "438505                0           0           0         Unknown   \n",
              "438506                0           0           0        Laborers   \n",
              "438507                1           0           0     Sales staff   \n",
              "438508                0           0           0         Unknown   \n",
              "438509                0           1           0     Sales staff   \n",
              "\n",
              "        CNT_ADLT_FAM_MEMBERS  CREDIT_SCORE  AGE  \n",
              "0                        2.0       12600.0   32  \n",
              "1                        2.0       11600.0   32  \n",
              "2                        2.0        6300.0   58  \n",
              "3                        1.0        -200.0   52  \n",
              "4                        1.0           0.0   52  \n",
              "...                      ...           ...  ...  \n",
              "438505                   1.0           0.0   62  \n",
              "438506                   1.0           0.0   43  \n",
              "438507                   1.0           0.0   22  \n",
              "438508                   2.0           0.0   59  \n",
              "438509                   2.0           0.0   51  \n",
              "\n",
              "[438510 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-453ffb9e-81a3-4766-864e-6cccebc42fe9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>DAYS_EMPLOYED</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <th>OCCUPATION_TYPE</th>\n",
              "      <th>CNT_ADLT_FAM_MEMBERS</th>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "      <th>AGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008804</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>-4542</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008805</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>-4542</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11600.0</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5008806</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>112500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-1134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Security staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5008808</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-3051</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-200.0</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5008809</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-3051</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438505</th>\n",
              "      <td>6840104</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>365243</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438506</th>\n",
              "      <td>6840222</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-3007</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Laborers</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438507</th>\n",
              "      <td>6841878</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>-372</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438508</th>\n",
              "      <td>6842765</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>365243</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Unknown</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438509</th>\n",
              "      <td>6842885</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>121500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>-1201</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Sales staff</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438510 rows  17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-453ffb9e-81a3-4766-864e-6cccebc42fe9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-453ffb9e-81a3-4766-864e-6cccebc42fe9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-453ffb9e-81a3-4766-864e-6cccebc42fe9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2953eb7a-8f5a-4ee1-8260-78b22f2edd07\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2953eb7a-8f5a-4ee1-8260-78b22f2edd07')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2953eb7a-8f5a-4ee1-8260-78b22f2edd07 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c01747c-8a6c-4445-82a2-0adf805c1648\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c01747c-8a6c-4445-82a2-0adf805c1648 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df_drop = merged_df.drop('ID', axis=1)"
      ],
      "metadata": {
        "id": "egeDqDr5uacc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables to numerical data\n",
        "merged_df_encoded = pd.get_dummies(merged_df_drop)\n",
        "\n",
        "# Specify the features and target variable\n",
        "X = merged_df_encoded.drop(columns=['CREDIT_SCORE'])\n",
        "y = merged_df_encoded['CREDIT_SCORE']\n",
        "\n",
        "# Create and train the Decision Tree model\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Learn the rules of splitting\n",
        "tree_rules = export_text(model, feature_names=list(X.columns))"
      ],
      "metadata": {
        "id": "yTZ8Kv2AIBBj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter AMT_INCOME_TOTAL breakdowns\n",
        "amt_income_total_splits = [line for line in tree_rules.split('\\n') if 'AMT_INCOME_TOTAL' in line]\n",
        "\n",
        "# Print results\n",
        "for line in amt_income_total_splits:\n",
        "    print(line)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z3H64KKrajSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d813cfc-14cc-46ba-dfcc-3c8ca3c778a6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 193500.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  193500.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 41625.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  41625.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 87750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 69750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  69750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  87750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 158400.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  158400.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 486000.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  486000.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 140625.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  140625.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 110250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  110250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 384750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  384750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 387675.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  387675.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 105750.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  105750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 146250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  146250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 294750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  294750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 189000.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  189000.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 363375.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  363375.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 585000.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 168750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  168750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  585000.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 130500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  130500.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 51750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  51750.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 308250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 74475.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 72675.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  72675.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  74475.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 120825.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  120825.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  308250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 184500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  184500.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 81675.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  81675.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 173250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  173250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 416250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  416250.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 112500.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  112500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 210375.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  210375.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 114750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  114750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 83925.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  83925.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 202500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  202500.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 123750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  123750.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 171000.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  171000.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 303750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  303750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 254250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  254250.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 68571.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 57600.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  57600.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  68571.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 200250.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  200250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 362250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  362250.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 153000.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  153000.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 82125.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  82125.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 101250.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  101250.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 137250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 98365.50\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 92844.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  92844.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  98365.50\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  137250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 141750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  141750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 148500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 137250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  137250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  148500.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 315000.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  315000.00\n",
            "|   |   |   |--- AMT_INCOME_TOTAL <= 126225.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL <= 118167.75\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 81218.25\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  81218.25\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 74250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  74250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 49500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  49500.00\n",
            "|   |   |   |   |   |--- AMT_INCOME_TOTAL >  118167.75\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 122150.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  122150.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 123750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  123750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 124875.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  124875.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 39953.25\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 36789.75\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  36789.75\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 36954.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  36954.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  39953.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 92250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  92250.00\n",
            "|   |   |   |--- AMT_INCOME_TOTAL >  126225.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 392926.50\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 384750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 130986.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  130986.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 131447.25\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  131447.25\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  384750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 389250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  389250.00\n",
            "|   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  392926.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 315000.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  315000.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 175500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  175500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 454500.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 139500.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  139500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  454500.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 236250.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  236250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 222750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  222750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 357750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  357750.00\n",
            "|   |   |--- AMT_INCOME_TOTAL <= 40950.00\n",
            "|   |   |   |   |--- AMT_INCOME_TOTAL <= 35325.00\n",
            "|   |   |   |   |--- AMT_INCOME_TOTAL >  35325.00\n",
            "|   |   |--- AMT_INCOME_TOTAL >  40950.00\n",
            "|   |   |   |--- AMT_INCOME_TOTAL <= 179550.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 51750.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  51750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 130500.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  130500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 137250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  137250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 89550.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 58950.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  58950.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  89550.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 105525.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  105525.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 101250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  101250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 69075.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  69075.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 50625.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 48375.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 46125.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  46125.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  48375.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  50625.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 75375.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  75375.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 87750.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  87750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 114750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  114750.00\n",
            "|   |   |   |--- AMT_INCOME_TOTAL >  179550.00\n",
            "|   |   |   |   |--- AMT_INCOME_TOTAL <= 200250.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 191925.00\n",
            "|   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  191925.00\n",
            "|   |   |   |   |--- AMT_INCOME_TOTAL >  200250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 236250.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  236250.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 230625.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  230625.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 241875.00\n",
            "|   |   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  241875.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 204750.00\n",
            "|   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  204750.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL <= 211500.00\n",
            "|   |   |   |   |   |   |   |   |   |--- AMT_INCOME_TOTAL >  211500.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used the DecisionTree model to find the most important breakpoints in the AMT_INCOME_TOTAL data. We continue on our way with the values we obtained from our first training.\n",
        "\n",
        "The values we found: 0, 56250, 261000, 411750, 450000 (These values may change when the model is retrained)"
      ],
      "metadata": {
        "id": "VHV6q2ysU2Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign average to DAYS_EMPLOYED values greater than zero\n",
        "def assign_mean_days_employed(row):\n",
        "    if row['DAYS_EMPLOYED'] > 0:\n",
        "        key = (row['AGE_GROUP'], row['INCOME_GROUP'])\n",
        "        if key in mean_days_employed_dict:\n",
        "            return mean_days_employed_dict[key]\n",
        "    return row['DAYS_EMPLOYED']\n",
        "\n",
        "def remove_unassigned_rows(df):\n",
        "    initial_row_count = df.shape[0]\n",
        "    df_cleaned = df.dropna(subset=['DAYS_EMPLOYED'])\n",
        "    final_row_count = df_cleaned.shape[0]\n",
        "    rows_removed = initial_row_count - final_row_count\n",
        "    print(f\"Number of deleted rows: {rows_removed}\")\n",
        "    return df_cleaned, rows_removed\n",
        "\n",
        "# Separate AGE and AMT_INCOME_TOTAL columns by category\n",
        "age_bins = [0, 30, 40, 50, 60, 70]\n",
        "income_bins = [0, 56250, 261000, 411750, 450000, 7000000]\n",
        "\n",
        "merged_df['AGE_GROUP'] = pd.cut(merged_df['AGE'], bins=age_bins, right=False)\n",
        "merged_df['INCOME_GROUP'] = pd.cut(merged_df['AMT_INCOME_TOTAL'], bins=income_bins, right=False)\n",
        "\n",
        "# Calculate average by grouping by DAYS_EMPLOYED values less than zero\n",
        "mean_days_employed = merged_df[merged_df['DAYS_EMPLOYED'] < 0].groupby(['AGE_GROUP', 'INCOME_GROUP'])['DAYS_EMPLOYED'].mean()\n",
        "\n",
        "# Create a dictionary\n",
        "mean_days_employed_dict = mean_days_employed.to_dict()\n",
        "\n",
        "# Assign average to DAYS_EMPLOYED values greater than zero\n",
        "merged_df['DAYS_EMPLOYED'] = merged_df.apply(assign_mean_days_employed, axis=1)\n",
        "\n",
        "# Delete data that cannot be assigned\n",
        "merged_df, rows_removed = remove_unassigned_rows(merged_df)\n",
        "\n",
        "# Convert DAYS_EMPLOYED column from days to months\n",
        "merged_df['MONTHS_EMPLOYED'] = (merged_df['DAYS_EMPLOYED'] / -30.44).astype(int)\n",
        "\n",
        "# Delete DAYS_EMPLOYED column\n",
        "merged_df.drop('DAYS_EMPLOYED', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "4p-qEVUGzz1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff51db2-3e4c-4e09-b71b-421973ce628d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deleted rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working on Evaluation Score**"
      ],
      "metadata": {
        "id": "35_2yGMBUad5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLAG_OWN_CAR :\n",
        "- Y : +5000\n",
        "- N : 0\n",
        "\n",
        "Evaluate owning a car positively.\n",
        "\n",
        "FLAG_OWN_REALTY :\n",
        "- Y : +10000\n",
        "- N : 0\n",
        "\n",
        "Consider being a homeowner positively.\n",
        "\n",
        "NAME_INCOME_TYPE :\n",
        "- Working : +1000\n",
        "- Commercial associate : +10000\n",
        "- Pensioner : +500\n",
        "- State Servant : +5000\n",
        "- Student : +500\n",
        "\n",
        "Provide special scoring for income types.\n",
        "\n",
        "NAME_HOUSING_TYPE :\n",
        "- Rented Apartment : -1000\n",
        "- House/Apartment : +500\n",
        "- Municipal apartment : +500\n",
        "- with parents : +500\n",
        "- Co-op apartment : +500\n",
        "- Office apartment : +500\n",
        "\n",
        "Give special scores for house types.\n",
        "\n",
        "FLAG_WORK_PHONE :\n",
        "- Y : +1000\n",
        "- N : 0\n",
        "\n",
        "We consider having a work phone as a positive thing, considering it as a corporate thing.\n",
        "\n",
        "FLAG_PHONE :\n",
        "- Y : +100\n",
        "- N : -100\n",
        "\n",
        "Accessibility scoring.\n",
        "\n",
        "FLAG_EMAIL :\n",
        "- Y : +100\n",
        "- N : -100\n",
        "\n",
        "Accessibility scoring.\n",
        "\n",
        "CNT_ADLT_FAM_MEMBERS :\n",
        "- 1< : +500\n",
        "\n",
        "Evaluating possible support."
      ],
      "metadata": {
        "id": "2JKG9kM9Vh81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring dictionaries\n",
        "income_type_scores = {\n",
        "    'Working': 5000,\n",
        "    'Commercial associate': 10000,\n",
        "    'Pensioner': 500,\n",
        "    'State Servant': 10000,\n",
        "    'Student': 500\n",
        "}\n",
        "\n",
        "housing_type_scores = {\n",
        "    'Rented Apartment': -1000,\n",
        "    'House/Apartment': 500,\n",
        "    'Municipal apartment': 500,\n",
        "    'with parents': 500,\n",
        "    'Co-op apartment': 500,\n",
        "    'Office apartment': 500\n",
        "}\n",
        "\n",
        "# Scoring function\n",
        "def calculate_evaluation_score(row):\n",
        "    score = 0\n",
        "\n",
        "    score += 5000 if row['FLAG_OWN_CAR'] == 'Y' else 0\n",
        "    score += 10000 if row['FLAG_OWN_REALTY'] == 'Y' else 0\n",
        "    score += income_type_scores.get(row['NAME_INCOME_TYPE'], 0)\n",
        "    score += housing_type_scores.get(row['NAME_HOUSING_TYPE'], 0)\n",
        "    score += 1000 if row['FLAG_WORK_PHONE'] == 'Y' else 0\n",
        "    score += 100 if row['FLAG_PHONE'] == 'Y' else -100\n",
        "    score += 100 if row['FLAG_EMAIL'] == 'Y' else -100\n",
        "    score += 500 if row['CNT_ADLT_FAM_MEMBERS'] > 1 else 0\n",
        "\n",
        "    return score\n",
        "\n",
        "# Adding the Evaluation_Score feature\n",
        "merged_df['Evaluation_Score'] = merged_df.apply(calculate_evaluation_score, axis=1)"
      ],
      "metadata": {
        "id": "oXqzcCPMfwcl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.CREDIT_SCORE.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "hH47Hy0Cf3Ht",
        "outputId": "304348b2-f5e0-440d-d50b-e6b96f54350b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    438510.000000\n",
              "mean        672.191512\n",
              "std        4408.079124\n",
              "min      -72100.000000\n",
              "25%           0.000000\n",
              "50%           0.000000\n",
              "75%           0.000000\n",
              "max       59000.000000\n",
              "Name: CREDIT_SCORE, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>438510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>672.191512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4408.079124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-72100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>59000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.Evaluation_Score.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "FTMnj0O_gMwt",
        "outputId": "25624964-cb35-4d82-d028-6e34ebfbe1ea"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    438510.000000\n",
              "mean      13960.471825\n",
              "std        6327.170202\n",
              "min        -200.000000\n",
              "25%       10300.000000\n",
              "50%       15300.000000\n",
              "75%       20300.000000\n",
              "max       25800.000000\n",
              "Name: Evaluation_Score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Evaluation_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>438510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13960.471825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6327.170202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10300.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>15300.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>20300.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>25800.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working on Total_Score**\n",
        "\n",
        "Evaluation_Score'u CREDIT_SCORE'a ekliyoruz."
      ],
      "metadata": {
        "id": "NZuw7MVhk-68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Evaluation_Score to CREDIT_SCORE\n",
        "merged_df['Total_Score'] = merged_df['CREDIT_SCORE']*0.7 + merged_df['Evaluation_Score']*0.3"
      ],
      "metadata": {
        "id": "GH_neMzhk-fg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.Total_Score.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Az6pPSfGlV3o",
        "outputId": "fb056e2c-44b5-4d47-ebcf-1ed5c4b2b5b3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    438510.000000\n",
              "mean       4658.675606\n",
              "std        3613.347694\n",
              "min      -44380.000000\n",
              "25%        3090.000000\n",
              "50%        4590.000000\n",
              "75%        6090.000000\n",
              "max       47490.000000\n",
              "Name: Total_Score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>438510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4658.675606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3613.347694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-44380.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3090.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4590.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6090.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>47490.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Continuing Our Scenario: Part-3\n",
        "\n",
        "Let's try to adapt our data to the scoring system we mentioned in Part-2."
      ],
      "metadata": {
        "id": "qguQango_oIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(merged_df['Total_Score'], bins=30, kde=True)\n",
        "plt.title('Total_Score Dalm')\n",
        "plt.xlabel('Total_Score')\n",
        "plt.ylabel('Frekans')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "ZNF4c0XnDASj",
        "outputId": "e4391a0f-f531-42d9-bd34-1f6e5c02f293"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale CREDIT_SCORE values between 0 and 1900 using MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1900))\n",
        "merged_df['Total_Score_SCALED'] = (scaler.fit_transform(merged_df[['Total_Score']])).astype(int)"
      ],
      "metadata": {
        "id": "x1iCRFon6gyz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['Total_Score_SCALED'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "HluP6d5oAzbP",
        "outputId": "da241693-525e-4e95-e136-8547268a011c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    438510.000000\n",
              "mean       1013.447370\n",
              "std          74.751366\n",
              "min           0.000000\n",
              "25%         981.000000\n",
              "50%        1012.000000\n",
              "75%        1043.000000\n",
              "max        1900.000000\n",
              "Name: Total_Score_SCALED, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total_Score_SCALED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>438510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1013.447370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>74.751366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>981.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1012.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1043.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1900.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categories\n",
        "bins = [-1, 1, 699, 1099, 1499, 1699, 1900]\n",
        "labels = ['High risk', 'Risky', 'Medium risk', 'Normal', 'Good', 'Very good']\n",
        "\n",
        "# Apply categories\n",
        "merged_df['Total_Score_CATEGORY'] = pd.cut(merged_df['Total_Score_SCALED'], bins=bins, labels=labels)\n",
        "\n",
        "# Check the results\n",
        "print(merged_df[['Total_Score', 'Total_Score_SCALED', 'Total_Score_CATEGORY']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB0HjX6dBAxB",
        "outputId": "eb091714-75d1-4c85-c095-b7fcc98bfa61"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Total_Score  Total_Score_SCALED Total_Score_CATEGORY\n",
            "0      14910.0                1226               Normal\n",
            "1      14210.0                1211               Normal\n",
            "2      10500.0                1134               Normal\n",
            "3       5800.0                1037          Medium risk\n",
            "4       5940.0                1040          Medium risk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Last manupulation for Target_Label**\n",
        "\n",
        "We are fine-tuning the Medium Risks to ensure an even distribution of the Target Label."
      ],
      "metadata": {
        "id": "RTBlWhxiprNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "income_labels = ['Low', 'Lower Middle', 'Middle', 'Upper Middle', 'High']\n",
        "\n",
        "# Classifying the Medium risk category\n",
        "merged_df['Income_Bin'] = pd.cut(merged_df['AMT_INCOME_TOTAL'], bins=income_bins, labels=income_labels, right=False)\n",
        "\n",
        "# Assign Income_Bin for Medium risk category\n",
        "def assign_income_bin(row):\n",
        "    if row['Total_Score_CATEGORY'] == 'Medium risk':\n",
        "        return row['Income_Bin']\n",
        "    return np.nan\n",
        "\n",
        "merged_df['Income_Bin'] = merged_df.apply(assign_income_bin, axis=1)"
      ],
      "metadata": {
        "id": "o7bhpmyz6WGh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "o6uoerwO7zJ8",
        "outputId": "0da9a1f7-2a00-472d-8812-218f37c2c64d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
              "0       5008804           M            Y               Y          427500.0   \n",
              "1       5008805           M            Y               Y          427500.0   \n",
              "2       5008806           M            Y               Y          112500.0   \n",
              "3       5008808           F            N               Y          270000.0   \n",
              "4       5008809           F            N               Y          270000.0   \n",
              "...         ...         ...          ...             ...               ...   \n",
              "438505  6840104           M            N               Y          135000.0   \n",
              "438506  6840222           F            N               N          103500.0   \n",
              "438507  6841878           F            N               N           54000.0   \n",
              "438508  6842765           F            N               Y           72000.0   \n",
              "438509  6842885           F            N               Y          121500.0   \n",
              "\n",
              "            NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
              "0                    Working               Higher education   \n",
              "1                    Working               Higher education   \n",
              "2                    Working  Secondary / secondary special   \n",
              "3       Commercial associate  Secondary / secondary special   \n",
              "4       Commercial associate  Secondary / secondary special   \n",
              "...                      ...                            ...   \n",
              "438505             Pensioner  Secondary / secondary special   \n",
              "438506               Working  Secondary / secondary special   \n",
              "438507  Commercial associate               Higher education   \n",
              "438508             Pensioner  Secondary / secondary special   \n",
              "438509               Working  Secondary / secondary special   \n",
              "\n",
              "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  FLAG_WORK_PHONE  ...  \\\n",
              "0             Civil marriage   Rented apartment                1  ...   \n",
              "1             Civil marriage   Rented apartment                1  ...   \n",
              "2                    Married  House / apartment                0  ...   \n",
              "3       Single / not married  House / apartment                0  ...   \n",
              "4       Single / not married  House / apartment                0  ...   \n",
              "...                      ...                ...              ...  ...   \n",
              "438505             Separated  House / apartment                0  ...   \n",
              "438506  Single / not married  House / apartment                0  ...   \n",
              "438507  Single / not married       With parents                1  ...   \n",
              "438508               Married  House / apartment                0  ...   \n",
              "438509               Married  House / apartment                0  ...   \n",
              "\n",
              "        CREDIT_SCORE  AGE AGE_GROUP      INCOME_GROUP  MONTHS_EMPLOYED  \\\n",
              "0            12600.0   32  [30, 40)  [411750, 450000)              149   \n",
              "1            11600.0   32  [30, 40)  [411750, 450000)              149   \n",
              "2             6300.0   58  [50, 60)   [56250, 261000)               37   \n",
              "3             -200.0   52  [50, 60)  [261000, 411750)              100   \n",
              "4                0.0   52  [50, 60)  [261000, 411750)              100   \n",
              "...              ...  ...       ...               ...              ...   \n",
              "438505           0.0   62  [60, 70)   [56250, 261000)              137   \n",
              "438506           0.0   43  [40, 50)   [56250, 261000)               98   \n",
              "438507           0.0   22   [0, 30)        [0, 56250)               12   \n",
              "438508           0.0   59  [50, 60)   [56250, 261000)              122   \n",
              "438509           0.0   51  [50, 60)   [56250, 261000)               39   \n",
              "\n",
              "        Evaluation_Score Total_Score Total_Score_SCALED  Total_Score_CATEGORY  \\\n",
              "0                  20300     14910.0               1226                Normal   \n",
              "1                  20300     14210.0               1211                Normal   \n",
              "2                  20300     10500.0               1134                Normal   \n",
              "3                  19800      5800.0               1037           Medium risk   \n",
              "4                  19800      5940.0               1040           Medium risk   \n",
              "...                  ...         ...                ...                   ...   \n",
              "438505             10300      3090.0                981           Medium risk   \n",
              "438506              4800      1440.0                947           Medium risk   \n",
              "438507              9800      2940.0                978           Medium risk   \n",
              "438508             10800      3240.0                984           Medium risk   \n",
              "438509             15300      4590.0               1012           Medium risk   \n",
              "\n",
              "          Income_Bin  \n",
              "0                NaN  \n",
              "1                NaN  \n",
              "2                NaN  \n",
              "3             Middle  \n",
              "4             Middle  \n",
              "...              ...  \n",
              "438505  Lower Middle  \n",
              "438506  Lower Middle  \n",
              "438507           Low  \n",
              "438508  Lower Middle  \n",
              "438509  Lower Middle  \n",
              "\n",
              "[438510 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ce6bc2f-da30-40fd-a222-60f6ae1d3310\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>...</th>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>INCOME_GROUP</th>\n",
              "      <th>MONTHS_EMPLOYED</th>\n",
              "      <th>Evaluation_Score</th>\n",
              "      <th>Total_Score</th>\n",
              "      <th>Total_Score_SCALED</th>\n",
              "      <th>Total_Score_CATEGORY</th>\n",
              "      <th>Income_Bin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008804</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>12600.0</td>\n",
              "      <td>32</td>\n",
              "      <td>[30, 40)</td>\n",
              "      <td>[411750, 450000)</td>\n",
              "      <td>149</td>\n",
              "      <td>20300</td>\n",
              "      <td>14910.0</td>\n",
              "      <td>1226</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008805</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>11600.0</td>\n",
              "      <td>32</td>\n",
              "      <td>[30, 40)</td>\n",
              "      <td>[411750, 450000)</td>\n",
              "      <td>149</td>\n",
              "      <td>20300</td>\n",
              "      <td>14210.0</td>\n",
              "      <td>1211</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5008806</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>112500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>58</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>37</td>\n",
              "      <td>20300</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>1134</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5008808</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-200.0</td>\n",
              "      <td>52</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[261000, 411750)</td>\n",
              "      <td>100</td>\n",
              "      <td>19800</td>\n",
              "      <td>5800.0</td>\n",
              "      <td>1037</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Middle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5008809</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>52</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[261000, 411750)</td>\n",
              "      <td>100</td>\n",
              "      <td>19800</td>\n",
              "      <td>5940.0</td>\n",
              "      <td>1040</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Middle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438505</th>\n",
              "      <td>6840104</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>62</td>\n",
              "      <td>[60, 70)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>137</td>\n",
              "      <td>10300</td>\n",
              "      <td>3090.0</td>\n",
              "      <td>981</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438506</th>\n",
              "      <td>6840222</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>43</td>\n",
              "      <td>[40, 50)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>98</td>\n",
              "      <td>4800</td>\n",
              "      <td>1440.0</td>\n",
              "      <td>947</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438507</th>\n",
              "      <td>6841878</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22</td>\n",
              "      <td>[0, 30)</td>\n",
              "      <td>[0, 56250)</td>\n",
              "      <td>12</td>\n",
              "      <td>9800</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>978</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438508</th>\n",
              "      <td>6842765</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>122</td>\n",
              "      <td>10800</td>\n",
              "      <td>3240.0</td>\n",
              "      <td>984</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438509</th>\n",
              "      <td>6842885</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>121500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>39</td>\n",
              "      <td>15300</td>\n",
              "      <td>4590.0</td>\n",
              "      <td>1012</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438510 rows  24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ce6bc2f-da30-40fd-a222-60f6ae1d3310')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ce6bc2f-da30-40fd-a222-60f6ae1d3310 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ce6bc2f-da30-40fd-a222-60f6ae1d3310');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e5f810e-8983-44db-9580-9a225deebf6d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e5f810e-8983-44db-9580-9a225deebf6d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e5f810e-8983-44db-9580-9a225deebf6d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9fa136c3-9c54-4009-bc8b-2603d34a3957\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9fa136c3-9c54-4009-bc8b-2603d34a3957 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the probabilities\n",
        "medium_risk_probabilities = {\n",
        "    'Low': 0,\n",
        "    'Lower Middle': [0.35, 0.65],\n",
        "    'Middle': [0.5, 0.5],  # Assuming equal probability for 1 and 0\n",
        "    'Upper Middle': [0.5, 0.5],  # Assuming equal probability for 1 and 0\n",
        "    'High': 1\n",
        "}\n",
        "\n",
        "probabilities = {\n",
        "    'Very good': 1,\n",
        "    'Good': 1,\n",
        "    'Normal': [0.6, 0.4],\n",
        "    'Risky': 0,\n",
        "    'High risk': 0\n",
        "}\n",
        "\n",
        "# Function to handle Medium risk probabilities\n",
        "def get_medium_risk_label(income_bin):\n",
        "    if income_bin in medium_risk_probabilities:\n",
        "        prob = medium_risk_probabilities[income_bin]\n",
        "        if isinstance(prob, list):\n",
        "            return np.random.choice([1, 0], p=prob)\n",
        "        return prob\n",
        "    return np.nan\n",
        "\n",
        "# Function to handle other probabilities\n",
        "def get_other_label(category):\n",
        "    if category in probabilities:\n",
        "        prob = probabilities[category]\n",
        "        if isinstance(prob, list):\n",
        "            return np.random.choice([1, 0], p=prob)\n",
        "        return prob\n",
        "    return np.nan\n",
        "\n",
        "# Apply the vectorized operations\n",
        "merged_df['TARGET_LABEL'] = np.where(\n",
        "    merged_df['Total_Score_CATEGORY'] == 'Medium risk',\n",
        "    merged_df['Income_Bin'].apply(get_medium_risk_label),\n",
        "    merged_df['Total_Score_CATEGORY'].apply(get_other_label)\n",
        ")"
      ],
      "metadata": {
        "id": "EkHaXKtCv2ul"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize TARGET_LABEL distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.countplot(x='TARGET_LABEL', data=merged_df)\n",
        "plt.title('TARGET_LABEL Frequency Distribution')\n",
        "plt.xlabel('TARGET_LABEL')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "sPs70uE_xuse",
        "outputId": "5523a6b1-318d-475e-c7c9-8be5bd2fb060"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the graph, we have obtained a distribution close to what we wanted.\n",
        "\n",
        "Now we will visualize and interpret our data."
      ],
      "metadata": {
        "id": "c87NCDraqPSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"7\"></a>\n",
        "## 7. Data Visualization"
      ],
      "metadata": {
        "id": "1TCB231Nupvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='AGE_GROUP', y='Total_Score', hue='NAME_EDUCATION_TYPE', palette='viridis')\n",
        "plt.title('Total_Score by Age Group and Education Type')\n",
        "plt.xlabel('AGE_GROUP')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='NAME_EDUCATION_TYPE', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d6B3C450wzKZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "d9bcdd4d-b2e2-48e5-9128-2e67d1f4da64"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observation"
      ],
      "metadata": {
        "id": "hAytjAT6zULN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='INCOME_GROUP', y='Total_Score', hue='NAME_EDUCATION_TYPE', palette='viridis')\n",
        "plt.title('Total_Score by INCOME GROUP and Education Type')\n",
        "plt.xlabel('INCOME_GROUP')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='NAME_EDUCATION_TYPE', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SCIM29OL30l6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "5340c739-35b7-43f9-ce08-d13c02094d0f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABd0AAAJwCAYAAAB8jshBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC16ElEQVR4nOzdd3yN5//H8feRPSQRI8OMHRqjVkmtSom9WrVnUKWorfbeW1FKYnaqUavFl9pbKFLUqA6rFdHETu7fHx45P8cJEg4xXs/H4zwe7uv63Pf9ua9zcuNzrly3yTAMQwAAAAAAAAAA4KmlSe0EAAAAAAAAAAB4VVB0BwAAAAAAAADARii6AwAAAAAAAABgIxTdAQAAAAAAAACwEYruAAAAAAAAAADYCEV3AAAAAAAAAABshKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICNUHQHALy2Nm/eLJPJpM2bN6d2KqmmZcuWcnd3T+00gOcmIiJCJpNJZ8+efabneRnuL89rLAAAAIDXDUV3AMBzZTKZkvVKTqFq5MiRWr58+TPP+UFnz55Vq1atlCtXLjk7O8vX11flypXToEGDnnsuL4scOXKoRo0aFm2J7/WECROs4hOLgfv27bPqi4yMVNOmTZU1a1Y5OTnJ29tbISEhCg8PV3x8vEVsXFychg0bpkKFCsnV1VWenp4qW7asFixYIMMwrI6dmFNYWFiS19GvXz9zzD///GNub9my5UM/y87Ozskao1u3bmnatGl6++23lS5dOjk6Osrf31+1atXSl19+aXFtZ8+etThHmjRp5O3trapVq2rnzp0PPcf27dtVt25d+fj4yMnJSTly5FD79u117tw5q9jHfSHj7u6uli1bmrcTi8yJLwcHB+XMmVPNmzfX6dOnkzUGL5LBgwc/8h514cKF1E4x2VLrXpmUx41r4qtChQqpnSoAAADwxOxTOwEAwOtl4cKFFtsLFizQ+vXrrdoDAwMfe6yRI0fqvffeU506dWyZ4iP99ttvKlGihFxcXNS6dWvlyJFD58+f14EDBzRmzBgNGTLkueXyqhg3bpw6dOggV1fXx8Z+8cUX+vDDD+Xj46NmzZopT548+u+//7Rx40a1adNG58+f16effipJunjxoipVqqSoqCg1bNhQnTp10s2bN7V06VK1aNFCa9as0eLFi2VnZ2dxDmdnZy1dulQzZsyQo6OjRd+XX34pZ2dn3bx50yo3JycnffHFF1btDx4/KZcvX1bVqlW1f/9+ValSRf3795e3t7cuXLigDRs2qHHjxvrtt980YMAAi/0aNWqkatWqKT4+XidOnNCMGTNUsWJF7d27V0FBQRax06ZNU5cuXZQzZ059/PHH8vPzU1RUlL744gt9/fXXWrNmjcqUKfPYXB+nc+fOKlGihO7cuaMDBw5o9uzZWr16tX755Rf5+/s/9fGft5kzZyb55YOXl9fzT+YJPexe2axZMzVs2FBOTk7PLZd69eopd+7c5u3Y2Fh16NBBdevWVb169cztPj4+zy0nAAAAwNYougMAnqumTZtabO/atUvr16+3an9RTZo0SbGxsYqMjFT27Nkt+i5duvRcc4mLi5Obm9tzPaetFSlSRJGRkZo1a5a6dev2yNhdu3bpww8/VOnSpbVmzRqlTZvW3Ne1a1ft27dPR44cMbe1aNFCUVFRWrZsmWrVqmVu79y5s3r27Knx48eraNGi6t27t8V5QkNDtXLlSq1du1a1a9c2t+/YsUNnzpxR/fr1tXTpUqv87O3tn/hz3KxZMx08eFBLly61KDxKUt++fbVv3z4dP37car8333zT4pxly5ZV1apVNXPmTM2YMcPcvn37dnXt2lVvv/221q1bZ/EFR4cOHRQcHKz33ntPR48eVbp06Z7oGu7P4b333pMktWrVSnnz5lXnzp01f/589e3b96mOnRree+89ZciQIbXTeCbs7OyS9aWQLRUqVEiFChUyb//zzz/q0KGDChUq9NL8PQAAAAA8DsvLAABeOHFxcerevbt5+ZB8+fJp/PjxFsuBmEwmxcXFaf78+eblCBKXuvj999/10UcfKV++fHJxcVH69On1/vvv22Td4lOnTilLlixWBXdJypQpk1Xb2rVrVb58eaVNm1YeHh4qUaKElixZYhHz7bffqlixYnJxcVGGDBnUtGlT/fXXXxYxiUt9nDp1StWqVVPatGnVpEkTSVJCQoImT56sggULytnZWT4+Pmrfvr2io6OTfV2nT59WlSpV5ObmJn9/fw0dOtQ83oZhKEeOHBYF6EQ3b96Up6en2rdvn+xz3S84OFjvvPOOxo4dqxs3bjwydsiQITKZTFq8eLFFwT1R8eLFzZ+BXbt26ccff1TLli0tCu6JRo0apTx58mjMmDFW582cObPKlStn9T4tXrxYQUFBeuONN1J4lY+2c+dO/fjjj2rXrp1VwT1R8eLFze/3o5QtW1bSvc/p/YYNGyaTyaT58+db/UZBrly5NHbsWJ0/f16ff/75E17Fw73zzjuSpDNnzjwyLjw8XO+8844yZcokJycnFShQQDNnzrSKS1yqaNu2bSpZsqScnZ2VM2dOLViwwCr26NGjeuedd+Ti4qIsWbJo+PDhSkhIsM2F3efPP/9UnTp15ObmpkyZMumTTz7RrVu3ksz9/iV5ElWoUMFqOZWbN29q8ODByps3r5ydneXn56d69epZvLfjx49XmTJllD59erm4uKhYsWL67rvvLI7zqHvlw9Z0nzFjhgoWLCgnJyf5+/urY8eOunr1qlXOb7zxho4dO6aKFSvK1dVVmTNn1tixY5M9bkk5ffq0TCaTJk2aZNW3Y8cOmUwmffnll5L+f6maX3/9VQ0aNJCHh4fSp0+vLl26JPnbKIsWLTLfa729vdWwYUP98ccfT5UvAAAAkBSK7gCAF4phGKpVq5YmTZqk0NBQTZw4Ufny5VPPnj0tZkIvXLhQTk5OKlu2rBYuXKiFCxeaC7979+7Vjh071LBhQ02dOlUffvihNm7cqAoVKuj69etPlV/27Nn1xx9/6H//+99jYyMiIlS9enVduXJFffv21ejRo1WkSBGtW7fOIqZBgways7PTqFGj1LZtW33//fd6++23rYpcd+/eVZUqVZQpUyaNHz9e9evXlyS1b99ePXv2VHBwsKZMmaJWrVpp8eLFqlKliu7cufPYPOPj4xUaGiofHx+NHTtWxYoV06BBg8xr1JtMJjVt2lRr167VlStXLPb94YcfdO3ataeaoTp48GBdvHgxyQJrouvXr2vjxo0qV66csmXL9thj/vDDD5Kk5s2bJ9lvb2+vxo0bKzo6Wtu3b7fqb9y4sX744QfFxsZKujf23377rRo3bvzI8/7zzz9Wr2vXriUrV1vM8k0snt4/Wz1x7MqWLauAgIAk9/vggw/k5OSkVatWPXUOD0osEqdPn/6RcTNnzlT27Nn16aefasKECcqaNas++ugjffbZZ1axv/32m9577z29++67mjBhgtKlS6eWLVvq6NGj5pgLFy6oYsWKioyMVJ8+fdS1a1ctWLBAU6ZMSVH+V65csXpP7//ZvHHjhipVqqQff/xRnTp1Ur9+/bR161b16tUrRee5X3x8vGrUqKEhQ4aoWLFimjBhgrp06aKYmBiL3+aYMmWKihYtqqFDh2rkyJGyt7fX+++/r9WrV5tjHnWvTMrgwYPVsWNH+fv7a8KECapfv74+//xzVa5c2ep+Eh0drdDQUBUuXFgTJkxQ/vz51bt3b61du/aJrz1nzpwKDg7W4sWLrfoSv3B78AvABg0a6ObNmxo1apSqVaumqVOnql27dhYxI0aMUPPmzZUnTx5NnDhRXbt2Nd9THrzXAgAAAE/NAAAgFXXs2NG4/6+j5cuXG5KM4cOHW8S99957hslkMn777Tdzm5ubm9GiRQurY16/ft2qbefOnYYkY8GCBea2TZs2GZKMTZs2JTvfI0eOGC4uLoYko0iRIkaXLl2M5cuXG3FxcRZxV69eNdKmTWuUKlXKuHHjhkVfQkKCYRiGcfv2bSNTpkzGG2+8YRGzatUqQ5IxcOBAc1uLFi0MSUafPn0sjrV161ZDkrF48WKL9nXr1iXZ/qDE43788ccW+VWvXt1wdHQ0Ll++bBiGYRw/ftyQZMycOdNi/1q1ahk5cuQwX9PDZM+e3ahevbpFmySjY8eOhmEYRsWKFQ1fX1/zexceHm5IMvbu3WsYhmEcOnTIkGR06dLlkedJVKdOHUOSER0d/dCY77//3pBkTJ061SqnK1euGI6OjsbChQsNwzCM1atXGyaTyTh79qwxaNAgQ5J5bAzj/8cxqVeVKlUemWvdunUNScbVq1ct2m/cuGFcvnzZ/Lr/Ws6cOWNIMoYMGWJcvnzZuHDhgrF161ajRIkShiTj22+/NcdGRkYma+wKFSpkeHt7W1yTm5vbQ+Mf/PlL/HmaN2+ecfnyZePvv/82Vq9ebeTIkcMwmUzm9/Jhkvq5rVKlipEzZ06LtuzZsxuSjC1btpjbLl26ZDg5ORndu3c3t3Xt2tWQZOzevdsiztPT05BknDlz5pH5JL7PSb3y5ctnjps8ebIhyfjmm2/MbXFxcUbu3Lmt7i/Zs2dP8p5Vvnx5o3z58ubtefPmGZKMiRMnWsXe/7P24Jjdvn3beOONN4x33nnHov1h98rEn7PEsbh06ZLh6OhoVK5c2YiPjzfHTZ8+3fze3p/zg/fUW7duGb6+vkb9+vWtzvUwly9fNiQZgwYNMrd9/vnnhiQjKirK4toyZMhgcR2J71GtWrUsjvnRRx8ZkoxDhw4ZhmEYZ8+eNezs7IwRI0ZYxP3yyy+Gvb29VTsAAADwtJjpDgB4oaxZs0Z2dnbq3LmzRXv37t1lGEayZlC6uLiY/3znzh39+++/yp07t7y8vHTgwIGnyq9gwYKKjIxU06ZNdfbsWU2ZMkV16tSRj4+P5syZY45bv369/vvvP/Xp00fOzs4WxzCZTJKkffv26dKlS/roo48sYqpXr678+fNbzFZN1KFDB4vtb7/9Vp6ennr33XctZuIWK1ZM7u7u2rRpU7Kuq1OnThb5derUSbdv39aGDRskSXnz5lWpUqUsZp9euXJFa9euVZMmTczX9KQGDx6sCxcuaNasWUn2J84WT2pZmaT8999/j41P7EtqJnq6dOkUGhpqXsZiyZIlKlOmTJLLCiVydnbW+vXrrV6jR49+ZK6J53/wYZ2zZs1SxowZza+3337bat9BgwYpY8aM8vX1VdmyZRUVFaUJEyaY11SXkjcWif2Pm5WfHK1bt1bGjBnl7++v6tWrm5c2KV68+CP3u//nNiYmRv/884/Kly+v06dPKyYmxiK2QIEC5qV0JCljxozKly+fTp8+bW5bs2aN3nrrLZUsWdIiLjnL9Nxv6dKlVu9peHi4xXn8/PwsxtzV1dVqpnVKz5khQwZ9/PHHVn33/6zdP2bR0dGKiYlR2bJln/g+t2HDBt2+fVtdu3ZVmjT//9+Etm3bysPDw+qe5O7ubvEbGo6OjipZsqTF+/AkGjRoIGdnZ4v7zY8//qh//vknyd8I6dixo8V24ritWbNGkvT9998rISFBDRo0sLhP+vr6Kk+ePMm+TwIAAADJxYNUAQAvlN9//13+/v5WBcLAwEBz/+PcuHFDo0aNUnh4uP766y+LteAfLN49ibx582rhwoWKj4/XsWPHtGrVKo0dO1bt2rVTQECAQkJCzEtqPGr978RryZcvn1Vf/vz5tW3bNos2e3t7ZcmSxaLt5MmTiomJSXI9eSl5D3dNkyaNcubMaXWNkizWem7evLk6deqk33//XdmzZ9e3336rO3fuqFmzZo89x+OUK1dOFStW1NixY/Xhhx9a9Xt4eEj6/wLy4yR+fv777z95eXklGfO4YnTjxo3VrFkznTt3TsuXL3/sWtV2dnYKCQlJVn5J5RobGytPT09ze/369c2fn+7duys+Pt5q33bt2un999/XzZs39b///U9Tp061irt/LB7lv//+S/aXGomS+rJl4MCBKlu2rOzs7JQhQwYFBgbK3v7x/+Tcvn27Bg0apJ07d1otAxUTE2MxNkktMZQuXTqL5xj8/vvvKlWqlFVcUj9vj1KuXLlHPkj1999/V+7cua3GIqXnud+pU6eUL1++x47bqlWrNHz4cEVGRlqsIf+kX4I97J7k6OionDlzWt1/s2TJYnWudOnS6fDhw090/kReXl6qWbOmlixZomHDhkm6t7RM5syZzc8IuF+ePHkstnPlyqU0adKY718nT56UYRhWcYkcHByeKl8AAADgQRTdAQCvnI8//ljh4eHq2rWrSpcuLU9PT5lMJjVs2NCmD1G0s7NTUFCQgoKCVLp0aVWsWFGLFy9+osJrcjg5OVnMPpXuPUQ1U6ZMSa5/LN2b2WsrDRs21CeffKLFixfr008/1aJFi1S8ePGnKi7eb9CgQapQoYI+//xzq0J57ty5ZW9vr19++SVZxwoMDNTy5ct1+PBhlStXLsmYxMJggQIFkuyvVauWnJyc1KJFC926dUsNGjRI/sWkQP78+SVJR44cUXBwsLk9a9asypo1q6R7hcx//vnHat88efKYP281atSQnZ2d+vTpo4oVK5pnlieO3aMKobdu3dLx48ctZqM7Ozvr1q1bMgzDqrBqGIZu3rxp9VsckhQUFJTin4FTp06pUqVKyp8/vyZOnKisWbPK0dFRa9as0aRJk6x+bu3s7JI8zv1fsL2IHlYMj4+Pf+g1PczWrVtVq1YtlStXTjNmzJCfn58cHBwUHh5u9RDgZ+VZvg/NmzfXt99+qx07digoKEgrV67URx99ZHUPTMqD45yQkCCTyaS1a9cmmfODv2UCAAAAPC2WlwEAvFCyZ8+uv//+22pW7q+//mruT/SwAtZ3332nFi1amJfZePfdd5N8MKktJRYrz58/L+neTEtJFg89fFDitRw/ftyq7/jx449cyiRRrly59O+//yo4OFghISFWr8KFCz/2GAkJCVbLQZw4cUKSlCNHDnObt7e3qlevrsWLF+v333/X9u3bbTLLPVH58uVVoUIFjRkzRjdu3LDoc3V11TvvvKMtW7bojz/+eOyxatSoIUlasGBBkv3x8fFasmSJ0qVLZ1Hovp+Li4vq1KmjzZs36913333kbOenkZjrw744SYl+/fopbdq06t+/v7nNzc1NFStW1JYtWx76myLffPONbt26Zc5Fuvf5vHv3rvm3Nu7322+/KT4+Plmf0eT44YcfdOvWLa1cuVLt27dXtWrVFBISYrF8Skplz55dJ0+etGpP6uftaWTPnl2nTp2yKjQndZ506dIleR968H3JlSuXjh8//sgHIS9dulTOzs768ccf1bp1a1WtWvWhX3Ykd+b7w+5Jt2/f1pkzZ2z2fidHaGioMmbMqMWLF2vZsmW6fv36Q+83D77Pv/32mxISEsz3r1y5cskwDPNvIj34euutt5715QAAAOA1Q9EdAPBCqVatmuLj4zV9+nSL9kmTJslkMqlq1armNjc3tyQLWHZ2dlYFsGnTpiW5PEdKbd26NclCWOLawYmzvitXrqy0adNq1KhRunnzpkVsYm7FixdXpkyZNGvWLIulIdauXauoqChVr179sfk0aNBA8fHx5iUY7nf37t1kf9Fw/3gbhqHp06fLwcFBlSpVsohr1qyZjh07pp49e8rOzk4NGzZM1vGTK3Ft99mzZ1v1DRo0SIZhqFmzZoqNjbXq379/v+bPny9JKlOmjEJCQhQeHq5Vq1ZZxfbr108nTpxQr169HlnY7dGjhwYNGqQBAwY8xVU9WnBwsN59913Nnj1bK1asSDImuTOHvby81L59e/3444+KjIw0t/fv31+GYahly5ZWX2icOXNGvXr1kp+fn9q3b29uT/xZe/BnUZI+++wzi5inlTj7+MGloO5fOz2lqlWrpl27dmnPnj3mtsuXL9vky40Hz/P333/ru+++M7ddv349yc9wrly5tGvXLt2+fdvctmrVKqsvkurXr69//vknybFPHCM7OzuZTCaL+9rZs2e1fPlyq30edq98UEhIiBwdHTV16lSL92Lu3LmKiYlJ1j3JVuzt7dWoUSN98803ioiIUFBQkAoVKpRkbOLnMdG0adMk/f/ns169erKzs9OQIUOsfpYMw9C///77DK4AAAAArzOWlwEAvFBq1qypihUrql+/fjp79qwKFy6sn376SStWrFDXrl3NM8glqVixYtqwYYMmTpwof39/BQQEqFSpUqpRo4YWLlwoT09PFShQQDt37tSGDRuUPn36p85vzJgx2r9/v+rVq2cuAB04cEALFiyQt7e3unbtKuneGuSTJk1SWFiYSpQoocaNGytdunQ6dOiQrl+/rvnz58vBwUFjxoxRq1atVL58eTVq1EgXL17UlClTlCNHDn3yySePzad8+fJq3769Ro0apcjISFWuXFkODg46efKkvv32W02ZMsXiAY9JcXZ21rp169SiRQuVKlVKa9eu1erVq/Xpp59aLU9TvXp1pU+fXt9++62qVq360LXkn1T58uVVvnx5/fzzz1Z9ZcqU0WeffaaPPvpI+fPnV7NmzZQnTx79999/2rx5s1auXKnhw4eb4xcsWKBKlSqpdu3aaty4scqWLatbt27p+++/1+bNm/XBBx+oZ8+ej8yncOHCyfptAenelxyLFi1Ksq9u3bpyc3N76L6LFi1SaGio6tSpY56xnC5dOl24cEEbNmzQli1bkl3g7tKliyZPnqzRo0frq6++knRvXfLx48erW7duKlSokFq2bCk/Pz/9+uuvmjNnjhISErRmzRqlS5fOfJwiRYooLCxMU6ZM0cmTJ/Xuu+9KuveQ4DVr1igsLCzZY/M4lStXlqOjo2rWrKn27dsrNjZWc+bMUaZMmcy/PZJSvXr10sKFCxUaGqouXbrIzc1Ns2fPVvbs2VO05vh3332X5PIj7777rnx8fNS2bVtNnz5dzZs31/79++Xn56eFCxfK1dXVap+wsDB99913Cg0NVYMGDXTq1CktWrTI4r4m3VtaZcGCBerWrZv27NmjsmXLKi4uThs2bNBHH32k2rVrq3r16po4caJCQ0PVuHFjXbp0SZ999ply585tdX0Pu1c+KGPGjOrbt6+GDBmi0NBQ1apVS8ePH9eMGTNUokSJJB9i+iw1b95cU6dO1aZNmzRmzJiHxp05c0a1atVSaGiodu7cqUWLFqlx48bmz2euXLk0fPhw9e3bV2fPnlWdOnWUNm1anTlzRsuWLVO7du3Uo0eP53VZAAAAeB0YAACkoo4dOxoP/nX033//GZ988onh7+9vODg4GHny5DHGjRtnJCQkWMT9+uuvRrly5QwXFxdDktGiRQvDMAwjOjraaNWqlZEhQwbD3d3dqFKlivHrr78a2bNnN8cYhmFs2rTJkGRs2rQp2flu377d6Nixo/HGG28Ynp6ehoODg5EtWzajZcuWxqlTp6ziV65caZQpU8ZwcXExPDw8jJIlSxpffvmlRczXX39tFC1a1HBycjK8vb2NJk2aGH/++adFTIsWLQw3N7eH5jV79myjWLFihouLi5E2bVojKCjI6NWrl/H3338/8noSj3vq1CmjcuXKhqurq+Hj42MMGjTIiI+PT3Kfjz76yJBkLFmy5JHHvl/27NmN6tWrW7RJMjp27GgVm/i+SDL27t1r1b9//36jcePG5s9HunTpjEqVKhnz58+3yvm///4zBg8ebBQsWNA8NsHBwUZERITV5+lROd1v0KBBhiTj8uXL5rYWLVqYc07qdebMmUce0zAM48aNG8bkyZON0qVLGx4eHoa9vb3h6+tr1KhRw1i8eLFx9+5dc+yZM2cMSca4ceOSPFbLli0NOzs747fffrNo37Jli1G7dm0jQ4YM5s9u27ZtjbNnzyZ5nPj4eGPKlClG4cKFDWdnZ8PZ2dkoXLiwMXXqVKuxTnzfvv3228dea1JWrlxpFCpUyHB2djZy5MhhjBkzxpg3b57V+CX1WTIMwyhfvrxRvnx5i7bDhw8b5cuXN5ydnY3MmTMbw4YNM+bOnZus9yTxfX7Y6/77xu+//27UqlXLcHV1NTJkyGB06dLFWLduXZL3lwkTJhiZM2c2nJycjODgYGPfvn1J5n79+nWjX79+RkBAgOHg4GD4+voa7733nsV9Zu7cuUaePHkMJycnI3/+/EZ4eLg57/s97F4ZHh6e5FhMnz7dyJ8/v+Hg4GD4+PgYHTp0MKKjo63Gu2DBglbj1qJFCyN79uyPHNv7Xb582ZBkDBo0KMn+ggULGmnSpLG6JxrG/79Hx44dM9577z0jbdq0Rrp06YxOnToZN27csIpfunSp8fbbbxtubm6Gm5ubkT9/fqNjx47G8ePHk50vAAAAkBwmw3jBnzgFAABeKJ988onmzp2rCxcuJDmbFwBspWjRovL29tbGjRut+gYPHqwhQ4bo8uXLz+yZCwAAAMCTYE13AACQbDdv3tSiRYtUv359Cu4Anql9+/YpMjJSzZs3T+1UAAAAgBRhTXcAACTduHFDMTExj4zx9vaWo6Pjc8roxXLp0iVt2LBB3333nf7991916dIltVMC8Io6cuSI9u/frwkTJsjPz08ffPBBaqcEAAAApAhFdwAAJH399ddq1arVI2M2bdqkChUqPJ+EXjDHjh1TkyZNlClTJk2dOlVFihRJ7ZQAvKK+++47DR06VPny5dOXX34pZ2fn1E4JAAAASBHWdAcAQNL58+d19OjRR8YUK1ZM6dKle04ZAQAAAACAlxFFdwAAAAAAAAAAbIQHqQIAAAAAAAAAYCOs6W4jCQkJ+vvvv5U2bVqZTKbUTgcAAAAAAMAmDMPQf//9J39/f6VJw/xNAHgciu428vfffytr1qypnQYAAAAAAMAz8ccffyhLliypnQYAvPAouttI2rRpJd37C8jDwyOVswEAAAAAALCNa9euKWvWrObaBwDg0Si620jikjIeHh4U3QEAAAAAwCuH5XQBIHlYiAsAAAAAAAAAABuh6A4AAAAAAAAAgI1QdAcAAAAAAAAAwEZY0x0AAAAAAABIgmEYunv3ruLj41M7FQCpzMHBQXZ2dsmKpegOAAAAAAAAPOD27ds6f/68rl+/ntqpAHgBmEwmZcmSRe7u7o+NpegOAAAAAAAA3CchIUFnzpyRnZ2d/P395ejoKJPJlNppAUglhmHo8uXL+vPPP5UnT57Hznin6A4AAAAAAADc5/bt20pISFDWrFnl6uqa2ukAeAFkzJhRZ8+e1Z07dx5bdOdBqgAAAAAAAEAS0qShdAbgnpT8tgt3DgAAAAAAAAAAbISiOwAAAAAAAAAANkLRHQAAAAAAAAAAG6HoDgAAAAAAALxiWrZsKZPJpNGjR1u0L1++PMm1qfPnzy8nJydduHDBqq9ChQpJHkuSqlevLpPJpMGDB1vFP/j68MMPk5V7UvuaTCZ99dVXkqTNmzeb29KkSSNPT08VLVpUvXr10vnz563GoU6dOlbnSDzG1atXzW23b9/W2LFjVbhwYbm6uipDhgwKDg5WeHi47ty5Y7H/zp07ZWdnp+rVq1uc62G5m0wm5ciRwzw+Xbt2tTje0aNH1aBBA2XMmFFOTk7KmzevBg4cqOvXr1vE5ciRQyaTSbt27bJo79q1qypUqPDYsU3c/2Gvxo0by9XVVUuWLLHYLyEhQWXKlNF7771nda2Ojo7KnTu3hg4dqrt371qMb1KvpD5jrxqK7gAAAAAAAMAryNnZWWPGjFF0dPQj47Zt26YbN27ovffe0/z585OMyZo1qyIiIiza/vrrL23cuFF+fn5W8W3bttX58+ctXmPHjk127uHh4Vb7P1g8P378uP7++2/t3btXvXv31oYNG/TGG2/ol19+SfZ5Et2+fVtVqlTR6NGj1a5dO+3YsUN79uxRx44dNW3aNB09etQifu7cufr444+1ZcsW/f3335KkKVOmWOT74HXs3bs3yXPv2rVLpUqV0u3bt7V69WqdOHFCI0aMUEREhN59913dvn3bIt7Z2Vm9e/dO8TVK0t69e835LF26VNK9cUxsmzlzpkaPHq2PP/7Y4guMCRMm6PTp05o1a5a5LTQ0VOfPn9fJkyfVvXt3DR48WOPGjbM43/3HTnxlypTpiXJ/mVB0BwAAAAAAAF5BISEh8vX11ahRox4ZN3fuXDVu3FjNmjXTvHnzkoypUaOG/vnnH23fvt3cNn/+fFWuXDnJIqqrq6t8fX0tXh4eHsnO3cvLy2p/Z2dni5hMmTLJ19dXefPmVcOGDbV9+3ZlzJhRHTp0SPZ5Ek2ePFlbtmzRxo0b1bFjRxUpUkQ5c+ZU48aNtXv3buXJk8ccGxsbq6+//lodOnRQ9erVzV9GeHp6WuT74HVkzJjR6ryGYahNmzYKDAzU999/r5IlSyp79ux6//339cMPP2jnzp2aNGmSxT7t2rXTrl27tGbNmhRfZ8aMGc35eHt7S/r/cfT19ZWnp6c+/vhjFS5cWG3btpUk/frrrxo4cKBmz56tDBkymI/l5OQkX19fZc+eXR06dFBISIhWrlxpcb77j534SpPm1S9Jv/pXCAAAAAAAALyG7OzsNHLkSE2bNk1//vlnkjH//fefvv32WzVt2lTvvvuuYmJitHXrVqs4R0dHNWnSROHh4ea2iIgItW7d+pnln1IuLi768MMPtX37dl26dClF+y5evFghISEqWrSoVZ+Dg4Pc3NzM2998843y58+vfPnyqWnTppo3b54Mw3iinCMjI3Xs2DF169bNqhhduHBhhYSE6Msvv7RoDwgI0Icffqi+ffsqISHhic77KCaTSeHh4dq6davmzJmjli1bqmHDhqpVq9Yj93NxcbGalf+6ougOAAAAAAAAvKLq1q2rIkWKaNCgQUn2f/XVV8qTJ48KFiwoOzs7NWzYUHPnzk0ytnXr1vrmm28UFxenLVu2KCYmRjVq1EgydsaMGXJ3d7d4LV68ONl5N2rUyGr/c+fOPXa//PnzS5LOnj2b7HNJ0smTJ837Ps7cuXPVtGlTSfeWWImJidHPP/+covMlOnHihCQpMDAwyf7AwEBzzP369++vM2fOpGhMUyJ79uyaPHmyPvzwQ50/f15Tpkx5aKxhGNqwYYN+/PFHvfPOOxZ9WbJksXgPCxYs+EzyfdHYp3YCAAAAAAAAAJ6dMWPG6J133lGPHj2s+ubNm2cuIEtS06ZNVb58eU2bNk1p06a1iC1cuLDy5Mmj7777Tps2bVKzZs1kb590ebFJkybq16+fRZuPj0+yc540aZJCQkIs2vz9/R+7X+KM86QeFpuc/R7n+PHj2rNnj5YtWyZJsre31wcffKC5c+cm60GmT3v+RBkzZlSPHj00cOBAffDBB0983kdp1aqVBgwYoI8//jjJpYFWrVold3d33blzRwkJCWrcuLHFA3UlaevWrRafIwcHh2eS64uGojsAAAAAAADwCitXrpyqVKmivn37qmXLlub2Y8eOadeuXdqzZ4/Fgznj4+P11Vdfmdf0vl/r1q312Wef6dixY9qzZ89Dz+np6ancuXM/cc6+vr5PtH9UVJQkKUeOHJIkDw8P/f7771ZxV69elZ2dnXnZmLx58+rXX3997PHnzp2ru3fvWnwBYBiGnJycNH36dHl6eqYo37x585rzTmppm6ioKHPMg7p166YZM2ZoxowZKTpnStjb2z/0i5WKFStq5syZcnR0lL+/f5JxAQEB8vLyemb5vahYXgYAAAAAAAB4xY0ePdr8YM5Ec+fOVbly5XTo0CFFRkaaX926dXvoEjONGzfWL7/8ojfeeEMFChR4Xukny40bNzR79myVK1fO/NDSfPny6ejRo7p165ZF7IEDBxQQEGCeed24cWNt2LBBBw8etDrunTt3FBcXp7t372rBggWaMGGCxXgdOnRI/v7+VmuvJ0eRIkWUP39+TZo0yWp99kOHDmnDhg1q1KhRkvu6u7trwIABGjFihP77778Un/tpubm5KXfu3MqWLdtDC/OvK4ruAAAAAAAAwCsuKChITZo00dSpUyXdKyQvXLhQjRo10htvvGHxCgsL0+7du3X06FGr46RLl07nz5/Xxo0bH3m+69ev68KFCxav6OjoZOd79epVq/3j4uIsYi5duqQLFy7o5MmT+uqrrxQcHKx//vlHM2fONMc0adJEJpNJzZs31/79+/Xbb79p3rx5mjx5srp3726O69q1q4KDg1WpUiV99tlnOnTokE6fPq1vvvlGb731lk6ePKlVq1YpOjpabdq0sRqz+vXrP/SLikcxmUyaO3eujh07pvr162vPnj06d+6cvv32W9WsWVOlS5dW165dH7p/u3bt5OnpqSVLlqT43M9D4nt0/+vOnTupndYzR9EdAAAALz3DMBQbG2t+pXRNTAAAgNfB0KFDzbOpV65cqX///Vd169a1igsMDFRgYOBDi8heXl7mZVkeZs6cOfLz87N4PWzGdlJatWpltf+0adMsYvLlyyd/f38VK1ZMo0ePVkhIiI4cOWIxA9/Ly0tbt27VnTt3VKtWLRUpUkRTp07VxIkT1b59e3Ock5OT1q9fr169eunzzz/XW2+9pRIlSmjq1Knq3Lmz3njjDc2dO1chISFJLiFTv3597du3T4cPH072NSYqU6aMdu3aJTs7O1WtWlW5c+dW37591aJFC61fv15OTk4P3dfBwUHDhg3TzZs3U3ze5yFfvnxW7+P+/ftTO61nzmTwPxKbuHbtmjw9PRUTE5PkgwUAAADw7MTGxqp27drm7RUrVsjd3T0VMwIA4NXxOtY8bt68qTNnziggIEDOzs6pnQ6AF0BK7gvMdAcAAAAAAAAAwEYougMAAAAAAAB4LkaOHCl3d/ckX1WrVk3t9F4JDxtfd3d3bd26NbXTey3wWFkAAAAAAAAAz8WHH36oBg0aJNnn4uLynLN5NUVGRj60L3PmzM8vkdcYRXcAAAAAAAAAz4W3t7e8vb1TO41XWu7cuVM7hdcey8sAAAAAAAAAAGAjFN0BAAAAAAAAALARiu4AAAAAAAAAANgIRXcAAAAAAAAAAGyEojsAAAAAAAAAADZC0R0AAAAAAAB4zURERMjLyytF+7Rs2VJ16tR5JvnYSoUKFdS1a9fUTuOJxhevDvvUTgAAAAAAAAB4WdSo9OlzPd+qjSNTFN+yZUtdvXpVy5cvt2jfvHmzKlasqOjoaHl5eemDDz5QtWrVbJjp6ytHjhzq2rWrRbGf8X29UXQHAAAAAAAAXjMuLi5ycXFJ7TQUHx8vk8mkNGlerQU5XpTxRepI1U/zli1bVLNmTfn7+8tkMll9A2cYhgYOHCg/Pz+5uLgoJCREJ0+etIi5cuWKmjRpIg8PD3l5ealNmzaKjY21iDl8+LDKli0rZ2dnZc2aVWPHjrXK5dtvv1X+/Pnl7OysoKAgrVmzxubXCwAAAAAAALwIklr+ZPjw4cqUKZPSpk2rsLAw9enTR0WKFLHad/z48fLz81P69OnVsWNH3blzx9x369Yt9ejRQ5kzZ5abm5tKlSqlzZs3W5135cqVKlCggJycnHTu3Lkkczxy5IiqVq0qd3d3+fj4qFmzZvrnn3/M/XFxcWrevLnc3d3l5+enCRMmWB0jqZqjl5eXIiIizNt//vmnGjVqJG9vb7m5ual48eLavXu3JOnUqVOqXbu2fHx85O7urhIlSmjDhg3mfStUqKDff/9dn3zyiUwmk0wm00PHd+bMmcqVK5ccHR2VL18+LVy40CrXL774QnXr1pWrq6vy5MmjlStXJjk2eLGlatE9Li5OhQsX1meffZZk/9ixYzV16lTNmjVLu3fvlpubm6pUqaKbN2+aY5o0aaKjR49q/fr1WrVqlbZs2aJ27dqZ+69du6bKlSsre/bs2r9/v8aNG6fBgwdr9uzZ5pgdO3aoUaNGatOmjQ4ePKg6deqoTp06OnLkyLO7eAAAAAAAAOAFsXjxYo0YMUJjxozR/v37lS1bNs2cOdMqbtOmTTp16pQ2bdqk+fPnKyIiwqKA3alTJ+3cuVNfffWVDh8+rPfff1+hoaEWE2mvX7+uMWPG6IsvvtDRo0eVKVMmq/NcvXpV77zzjooWLap9+/Zp3bp1unjxoho0aGCO6dmzp37++WetWLFCP/30kzZv3qwDBw6k6LpjY2NVvnx5/fXXX1q5cqUOHTqkXr16KSEhwdxfrVo1bdy4UQcPHlRoaKhq1qxp/qLg+++/V5YsWTR06FCdP39e58+fT/I8y5YtU5cuXdS9e3cdOXJE7du3V6tWrbRp0yaLuCFDhqhBgwY6fPiwqlWrpiZNmujKlSspuiakvlRdXqZq1aqqWrVqkn2GYWjy5Mnq37+/ateuLUlasGCBfHx8tHz5cjVs2FBRUVFat26d9u7dq+LFi0uSpk2bpmrVqmn8+PHy9/fX4sWLdfv2bc2bN0+Ojo4qWLCgIiMjNXHiRHNxfsqUKQoNDVXPnj0lScOGDdP69es1ffp0zZo1K8n8bt26pVu3bpm3r127ZrNxAQAAAAAAAJ7UqlWr5O7ubtEWHx//yH2mTZumNm3aqFWrVpKkgQMH6qeffrJaUSJdunSaPn267OzslD9/flWvXl0bN25U27Ztde7cOYWHh+vcuXPy9/eXJPXo0UPr1q1TeHi4Ro68tz79nTt3NGPGDBUuXPih+UyfPl1FixY17yNJ8+bNU9asWXXixAn5+/tr7ty5WrRokSpVqiRJmj9/vrJkyZLMUbpnyZIlunz5svbu3Stvb29JUu7cuc39hQsXtshz2LBhWrZsmVauXKlOnTrJ29tbdnZ2Sps2rXx9fR96nvHjx6tly5b66KOPJEndunXTrl27NH78eFWsWNEc17JlSzVq1EiSNHLkSE2dOlV79uxRaGhoiq4LqeuFXSzpzJkzunDhgkJCQsxtnp6eKlWqlHbu3ClJ2rlzp7y8vMwFd0kKCQlRmjRpzL8CsnPnTpUrV06Ojo7mmCpVquj48eOKjo42x9x/nsSYxPMkZdSoUfL09DS/smbN+vQXDQAAAAAAADylihUrKjIy0uL1xRdfPHKf48ePq2TJkhZtD25LUsGCBWVnZ2fe9vPz06VLlyRJv/zyi+Lj45U3b165u7ubXz///LNOnTpl3sfR0VGFChV6ZD6HDh3Spk2bLI6TP39+SfeWfDl16pRu376tUqVKmffx9vZWvnz5HnncB0VGRqpo0aLmgvuDYmNj1aNHDwUGBsrLy0vu7u6Kiop66JI4DxMVFaXg4GCLtuDgYEVFRVm03T8ubm5u8vDwMI8vXh4v7INUL1y4IEny8fGxaPfx8TH3XbhwwerXT+zt7eXt7W0RExAQYHWMxL506dLpwoULjzxPUvr27atu3bqZt69du0bhHQAAAAAAAKnOzc3NYra2dG/dcltwcHCw2DaZTBZLsdjZ2Wn//v0WhXlJFjPvXVxczGufP0xsbKxq1qypMWPGWPX5+fnpt99+S1a+JpNJhmFYtN2/Bv3jHnbao0cPrV+/XuPHj1fu3Lnl4uKi9957T7dv307W+VPqUeOLl8cLO9P9Refk5CQPDw+LFwAAAAAAAPAyypcvn/bu3WvR9uD24xQtWlTx8fG6dOmScufObfF61NIrSXnzzTd19OhR5ciRw+pYbm5uypUrlxwcHMyrXUhSdHS0Tpw4YXGcjBkzWqyzfvLkSV2/ft28XahQIUVGRj503fTt27erZcuWqlu3roKCguTr66uzZ89axDg6Oj52+Z7AwEBt377d6tgFChR45H54Ob2wRffEH8SLFy9atF+8eNHc5+vra/XrFXfv3tWVK1csYpI6xv3neFhMSm8GAAAAAAAAwMvo448/1ty5czV//nydPHlSw4cP1+HDhx87I/1+efPmVZMmTdS8eXN9//33OnPmjPbs2aNRo0Zp9erVKcqnY8eOunLliho1aqS9e/fq1KlT+vHHH9WqVSvFx8fL3d1dbdq0Uc+ePfW///1PR44cUcuWLZUmjWW585133tH06dN18OBB7du3Tx9++KHFbPJGjRrJ19dXderU0fbt23X69GktXbrUvOx0njx59P333ysyMlKHDh1S48aNrWae58iRQ1u2bNFff/2lf/75J8nr6dmzpyIiIjRz5kydPHlSEydO1Pfff68ePXqkaFzwcnhhl5cJCAiQr6+vNm7cqCJFiki6t4TL7t271aFDB0lS6dKldfXqVe3fv1/FihWTJP3vf/9TQkKCeT2n0qVLq1+/frpz5475B2r9+vXKly+f0qVLZ47ZuHGjunbtaj7/+vXrVbp06ed0tQAAAAAAAHgZrNo48vFBL6EmTZro9OnT6tGjh27evKkGDRqoZcuW2rNnT4qOEx4eruHDh6t79+7666+/lCFDBr311luqUaNGio7j7++v7du3q3fv3qpcubJu3bql7NmzKzQ01FxYHzdunHkZmrRp06p79+6KiYmxOM6ECRPUqlUrlS1bVv7+/poyZYr2799v7nd0dNRPP/2k7t27q1q1arp7964KFCigzz77TJI0ceJEtW7dWmXKlFGGDBnUu3dvXbt2zeIcQ4cOVfv27ZUrVy7dunXLajkbSapTp46mTJmi8ePHq0uXLgoICFB4eLgqVKiQonHBy8FkJPUpeE5iY2PN6y8VLVpUEydOVMWKFeXt7a1s2bJpzJgxGj16tObPn6+AgAANGDBAhw8f1rFjx+Ts7CxJqlq1qi5evKhZs2bpzp07atWqlYoXL64lS5ZIkmJiYpQvXz5VrlxZvXv31pEjR9S6dWtNmjRJ7dq1kyTt2LFD5cuX1+jRo1W9enV99dVXGjlypA4cOKA33ngjWddy7do1eXp6KiYmhqVmAAAAnrPY2FjVrl3bvL1ixQqLdUMBAMCTex1rHjdv3tSZM2cUEBBgrkG9jt599135+vpq4cKFqZ0KkOpScl9I1Znu+/btU8WKFc3biQ8mbdGihSIiItSrVy/FxcWpXbt2unr1qt5++22tW7fO4qIWL16sTp06qVKlSkqTJo3q16+vqVOnmvs9PT31008/qWPHjipWrJgyZMiggQMHmgvuklSmTBktWbJE/fv316effqo8efJo+fLlyS64AwAAAAAAAC+z69eva9asWapSpYrs7Oz05ZdfasOGDVq/fn1qpwa8dFJ1pvur5HX81hcAAOBFwUx3AACendex5vE6znS/ceOGatasqYMHD+rmzZvKly+f+vfvr3r16qV2asAL4aWZ6Q4AAAAAAAAg9bm4uGjDhg2pnQbwSkjz+BAAAAAAAAAAAJAcFN0BAAAAAAAAALARiu4AAAAAAAAAANgIRXcAAAAAAAAAAGyEojsAAAAAAAAAADZC0R0AAAAAAAAAABuh6A4AAAAAAAAg1bVs2VJ16tRJ7TReKZs3b5bJZNLVq1dTO5Xn7kmuvUKFCuratetTn9v+qY8AAAAAAAAAvCbKth/2XM+39fMBKYq/fPmyBg4cqNWrV+vixYtKly6dChcurIEDByo4OPgZZfnqaNWqlTJnzqzhw4endip4SmXKlNH58+fl6en53M9N0R0AAAAAAAB4RdSvX1+3b9/W/PnzlTNnTl28eFEbN27Uv//+m9qpPRd37tyRg4PDE+0bHx+vVatWafXq1TbO6uV2+/ZtOTo6pnYaKebo6ChfX99UOTfLywAAAAAAAACvgKtXr2rr1q0aM2aMKlasqOzZs6tkyZLq27evatWqZREXFhamjBkzysPDQ++8844OHTpkcawffvhBJUqUkLOzszJkyKC6deua+6Kjo9W8eXOlS5dOrq6uqlq1qk6ePGnuj4iIkJeXl3788UcFBgbK3d1doaGhOn/+vDkmPj5e3bp1k5eXl9KnT69evXrJMAyLHNatW6e3337bHFOjRg2dOnXK3H/27FmZTCZ9/fXXKl++vJydnTV79mx5eHjou+++szjW8uXL5ebmpv/++++h47djxw45ODioRIkSSfZ/9913CgoKkouLi9KnT6+QkBDFxcWZ+7/44gsFBgbK2dlZ+fPn14wZMyz2//PPP9WoUSN5e3vLzc1NxYsX1+7du839M2fOVK5cueTo6Kh8+fJp4cKFFvubTCZ98cUXqlu3rlxdXZUnTx6tXLnSImbNmjXKmzevXFxcVLFiRZ09e9ai/99//1WjRo2UOXNmubq6KigoSF9++aVFTIUKFdSpUyd17dpVGTJkUJUqVdS6dWvVqFHDIu7OnTvKlCmT5s6dm+R4/f7776pZs6bSpUsnNzc3FSxYUGvWrJH0/0u/rF69WoUKFZKzs7PeeustHTlyxOIY27ZtU9myZeXi4qKsWbOqc+fOFmN+69Yt9e7dW1mzZpWTk5Ny585tzufB5WWSc+22QtEdAAAAAAAAeAW4u7vL3d1dy5cv161btx4a9/777+vSpUtau3at9u/frzfffFOVKlXSlStXJEmrV69W3bp1Va1aNR08eFAbN25UyZIlzfu3bNlS+/bt08qVK7Vz504ZhqFq1arpzp075pjr169r/PjxWrhwobZs2aJz586pR48e5v4JEyYoIiJC8+bN07Zt23TlyhUtW7bMIs+4uDh169ZN+/bt08aNG5UmTRrVrVtXCQkJFnF9+vRRly5dFBUVpXr16qlhw4YKDw+3iAkPD9d7772ntGnTPnRcVq5cqZo1a8pkMln1nT9/Xo0aNVLr1q0VFRWlzZs3q169euYvChYvXqyBAwdqxIgRioqK0siRIzVgwADNnz9fkhQbG6vy5cvrr7/+0sqVK3Xo0CH16tXLfC3Lli1Tly5d1L17dx05ckTt27dXq1attGnTJos8hgwZogYNGujw4cOqVq2amjRpYn7f/vjjD9WrV081a9ZUZGSkwsLC1KdPH4v9b968qWLFimn16tU6cuSI2rVrp2bNmmnPnj0WcfPnz5ejo6O2b9+uWbNmKSwsTOvWrbP44mTVqlW6fv26PvjggyTHs2PHjrp165a2bNmiX375RWPGjJG7u7tFTM+ePTVhwgTt3btXGTNmVM2aNc2fo1OnTik0NFT169fX4cOH9fXXX2vbtm3q1KmTef/mzZvryy+/1NSpUxUVFaXPP//c6hwpvXZbMBkPfoWEJ3Lt2jV5enoqJiZGHh4eqZ0OAADAayU2Nla1a9c2b69YseKh/9gGAAAp8zrWPG7evKkzZ84oICBAzs7OFn0v+pruS5cuVdu2bXXjxg29+eabKl++vBo2bKhChQpJujdzuHr16rp06ZKcnJzM++XOnVu9evVSu3btVKZMGeXMmVOLFi2yOv7JkyeVN29ebd++XWXKlJF0bwZx1qxZNX/+fL3//vuKiIhQq1at9NtvvylXrlySpBkzZmjo0KG6cOGCJMnf31+ffPKJevbsKUm6e/euAgICVKxYMS1fvjzJa/vnn3+UMWNG/fLLL3rjjTd09uxZBQQEaPLkyerSpYs5bs+ePSpTpoz++OMP+fn56dKlS8qcObM2bNig8uXLP3Ts8ubNq0mTJql69epWfQcOHFCxYsV09uxZZc+e3ao/d+7cGjZsmBo1amRuGz58uNasWaMdO3Zo9uzZ6tGjh86ePStvb2+r/YODg1WwYEHNnj3b3NagQQPFxcWZl7sxmUzq37+/hg279xmMi4uTu7u71q5dq9DQUH366adasWKFjh49aj5Gnz59NGbMGEVHR8vLyyvJ665Ro4by58+v8ePHS7o30/3atWs6cOCARVzBggXVokUL9erVS5JUq1YtpU+f3uoLjkSFChVS/fr1NWjQIKu+zZs3q2LFivrqq6/MRfsrV64oS5YsioiIUIMGDRQWFiY7Ozt9/vnn5v22bdum8uXLKy4uTufOnVO+fPm0fv16hYSEPPQcKb32IkWKaPLkyVaxj7ovPIiZ7gAAAAAAAMAron79+vr777+1cuVKhYaGavPmzXrzzTcVEREhSTp06JBiY2OVPn1688x4d3d3nTlzxrx0S2RkpCpVqpTk8aOiomRvb69SpUqZ29KnT698+fIpKirK3Obq6mouuEsyF78lKSYmRufPn7c4hr29vYoXL25xrpMnT6pRo0bKmTOnPDw8lCNHDknSuXPnLOIe3K9kyZIqWLCgeZb5okWLlD17dpUrV+6h4xYVFaW///77oddduHBhVapUSUFBQXr//fc1Z84cRUdHS7pX/D516pTatGljMabDhw+3GNOiRYsmWXBPPP+DD7oNDg62GFNJ5i9PJMnNzU0eHh7mcY2KirIYU0kqXbq0xXZ8fLyGDRumoKAgeXt7y93dXT/++KPVmBYrVswqx7CwMHOB/eLFi1q7dq1at26d5PVIUufOnTV8+HAFBwdr0KBBOnz4sFXM/fl5e3tbfI4OHTqkiIgIizGtUqWKEhISdObMGUVGRsrOzu6RX6Q8ybXbAkV3AAAAAAAA4BXi7Oysd999VwMGDNCOHTvUsmVL82zj2NhY+fn5KTIy0uJ1/Phx86xzFxeXp87hwYeZmkwmqzXbH6dmzZq6cuWK5syZo927d5vXP799+7ZFnJubm9W+YWFh5i8awsPD1apVqySXjUm0cuVKvfvuuw+dwWxnZ6f169dr7dq1KlCggKZNm6Z8+fLpzJkzio2NlSTNmTPHYkyPHDmiXbt2SbLNmEpJj+uDy+08yrhx4zRlyhT17t1bmzZtUmRkpKpUqZKsMW3evLlOnz6tnTt3atGiRQoICFDZsmUfeq6wsDCdPn1azZo10y+//KLixYtr2rRpyc41NjZW7du3txjTQ4cO6eTJk8qVK1eKxzS5124LFN0BAAAAAACAV1iBAgXMD5988803deHCBdnb2yt37twWrwwZMki6N5t648aNSR4rMDBQd+/etXgA6L///qvjx4+rQIECycrH09NTfn5+Fse4e/eu9u/fb3XM/v37q1KlSgoMDDTPLE+Opk2b6vfff9fUqVN17NgxtWjR4pHxK1assFiuMCkmk0nBwcEaMmSIDh48KEdHRy1btkw+Pj7y9/fX6dOnrcY0ICBA0r0xjYyMNK+//qDAwEBt377dom379u3JHtPEYzy4Pnli0f/+Y9auXVtNmzZV4cKFlTNnTp04cSJZx0+fPr3q1Kmj8PBw8xJCj5M1a1Z9+OGH+v7779W9e3fNmTPnoflFR0frxIkTCgwMlHTvs3rs2DGrMc2dO7ccHR0VFBSkhIQE/fzzz8nK/2muPaXsn8lRAQAAAAAAADxX//77r95//321bt1ahQoVUtq0abVv3z6NHTvWXFAOCQlR6dKlVadOHY0dO1Z58+bV33//bX54avHixTVo0CBVqlRJuXLlUsOGDXX37l2tWbNGvXv3Vp48eVS7dm21bdtWn3/+udKmTas+ffooc+bMjy1a369Lly4aPXq08uTJo/z582vixIm6evWquT9dunRKnz69Zs+eLT8/P507d87qoaCPki5dOtWrV089e/ZU5cqVlSVLlofGXrp0yfxg2IfZvXu3Nm7cqMqVKytTpkzavXu3Ll++bC4QDxkyRJ07d5anp6dCQ0N169Yt7du3T9HR0erWrZsaNWqkkSNHqk6dOho1apT8/Px08OBB+fv7q3Tp0urZs6caNGigokWLKiQkRD/88IO+//57bdiwIdnX/OGHH2rChAnq2bOnwsLCtH//fvNs/0R58uTRd999px07dihdunSaOHGiLl68mOziflhYmGrUqKH4+PjHfpHRtWtXVa1aVXnz5lV0dLQ2bdpkHq9EQ4cOVfr06eXj46N+/fopQ4YMqlOnjiSpd+/eeuutt9SpUyeFhYXJzc1Nx44d0/r16zV9+nTlyJFDLVq0UOvWrTV16lQVLlxYv//+uy5duqQGDRpY5fO0154SFN0BAAAAAACAZErpg02fJ3d3d5UqVUqTJk3SqVOndOfOHWXNmlVt27bVp59+KunebO01a9aoX79+atWqlS5fvixfX1+VK1dOPj4+ku49TPLbb7/VsGHDNHr0aHl4eFishx4eHq4uXbqoRo0aun37tsqVK6c1a9ZYLX3yKN27d9f58+fVokULpUmTRq1bt1bdunUVExMjSUqTJo2++uorde7cWW+88Yby5cunqVOnqkKFCsk+R5s2bbRkyZJHrjsuST/88INKlixpnumfFA8PD23ZskWTJ0/WtWvXlD17dk2YMEFVq1aVdK8Y7erqqnHjxqlnz55yc3NTUFCQunbtKklydHTUTz/9pO7du6tatWq6e/euChQooM8++0ySVKdOHU2ZMkXjx49Xly5dFBAQoPDw8BRdb7Zs2bR06VJ98sknmjZtmkqWLKmRI0daXH///v11+vRpValSRa6urmrXrp3q1KljHvfHCQkJkZ+fnwoWLCh/f/9HxsbHx6tjx476888/5eHhodDQUE2aNMkiZvTo0erSpYtOnjypIkWK6IcffpCjo6Oke78d8PPPP6tfv34qW7asDMNQrly5zA9elaSZM2fq008/1UcffaR///1X2bJlM3/WH/S0154SJiOliykhSa/jk7wBAABeFLGxsRYzq1asWCF3d/dUzAgAgFfH61jzuHnzps6cOaOAgICHrvGNF9/ChQv1ySef6O+//zYXcpNSq1Ytvf322+rVq9dzzO7lFBsbq8yZMys8PFz16tV74uNs3rxZFStWVHR0tLy8vGyX4DOUkvsCM90BAAAAAAAAvDKuX7+u8+fPa/To0Wrfvv0jC+6S9Pbbb6tRo0bPKbuXU0JCgv755x9NmDBBXl5eqlWrVmqn9ELjQaoAAAAAAAAAXhljx45V/vz55evrq759+z42vlevXsqaNetzyOzlde7cOfn4+GjJkiWaN2+e7O2Zy/0ojA4AAAAAAACAV8bgwYM1ePDg1E7jlZIjRw7ZcpXyChUq2PR4LxpmugMAAAAAAAAAYCMU3QEAAAAAAAAAsBGK7gAAAAAAAAAA2AhFdwAAAAAAAAAAbISiOwAAAAAAAAAANkLRHQAAAAAAAAAAG7FP7QQAAAAAAACAl0WR4YOf6/ki+z/f871IBg8erOXLlysyMvK5n7tChQoqUqSIJk+e/NAYk8mkZcuWqU6dOsk65ubNm1WxYkVFR0fLy8vLJnnixcRMdwAAAAAAAOAV0bJly2QXgV81Z8+elclkem5F+vPnz6tq1arP5Vx4uTDTHQAAAAAAAABSyNfXN7VTkCTduXNHDg4OqZ0G7sNMdwAAAAAAAOAVVaFCBXXu3Fm9evWSt7e3fH19NXjwYIuYq1evqn379vLx8ZGzs7PeeOMNrVq1yty/dOlSFSxYUE5OTsqRI4cmTJhgsX+OHDk0fPhwNW/eXO7u7sqePbtWrlypy5cvq3bt2nJ3d1ehQoW0b98+8z4RERHy8vLS8uXLlSdPHjk7O6tKlSr6448/Hnk9X3zxhQIDA+Xs7Kz8+fNrxowZ5r6AgABJUtGiRWUymVShQoVk7fcwCQkJjxw3k8mk5cuXm7d37NihIkWKyNnZWcWLF9fy5cuTnHm/f/9+FS9eXK6uripTpoyOHz9u0b9ixQq9+eabcnZ2Vs6cOTVkyBDdvXvX4rwzZ85UrVq15ObmphEjRjz2WvB8UXQHAAAAAAAAXmHz58+Xm5ubdu/erbFjx2ro0KFav369pHuF5apVq2r79u1atGiRjh07ptGjR8vOzk7SvQJxgwYN1LBhQ/3yyy8aPHiwBgwYoIiICItzTJo0ScHBwTp48KCqV6+uZs2aqXnz5mratKkOHDigXLlyqXnz5jIMw7zP9evXNWLECC1YsEDbt2/X1atX1bBhw4dex+LFizVw4ECNGDFCUVFRGjlypAYMGKD58+dLkvbs2SNJ2rBhg86fP6/vv/8+Wfs9ybg96Nq1a6pZs6aCgoJ04MABDRs2TL17904ytl+/fpowYYL27dsne3t7tW7d2ty3detWNW/eXF26dNGxY8f0+eefKyIiwqqwPnjwYNWtW1e//PKLxf54MbC8DAAAAAAAAPAKK1SokAYNGiRJypMnj6ZPn66NGzfq3Xff1YYNG7Rnzx5FRUUpb968kqScOXOa9504caIqVaqkAQMGSJLy5s2rY8eOady4cWrZsqU5rlq1amrfvr0kaeDAgZo5c6ZKlCih999/X5LUu3dvlS5dWhcvXjQvy3Lnzh1Nnz5dpUqVknSvyB0YGKg9e/aoZMmSVtcxaNAgTZgwQfXq1ZN0b2Z7YmG6RYsWypgxoyQpffr0Fku/PG6/Jxm3By1ZskQmk0lz5syRs7OzChQooL/++ktt27a1ih0xYoTKly8vSerTp4+qV6+umzdvytnZWUOGDFGfPn3MeeXMmVPDhg1Tr169zLlIUuPGjdWqVauH5o7URdEdAAAAAAAAeIUVKlTIYtvPz0+XLl2SJEVGRipLlizmgvuDoqKiVLt2bYu24OBgTZ48WfHx8eYZ8fefw8fHR5IUFBRk1Xbp0iVzQdze3l4lSpQwx+TPn19eXl6KioqyKrrHxcXp1KlTatOmjUUh++7du/L09HzotT/pfg9ek2Q5bg86fvy4ChUqJGdnZ3NbUl8cPHhcPz8/SffGJVu2bDp06JC2b99uMbM9Pj5eN2/e1PXr1+Xq6ipJKl68+CNzR+qi6A4AAAAAAAC8wh58yKbJZFJCQoIkycXFxebnMJlMD21LPG9KxcbGSpLmzJljnhmfKLHwb8v9pEeP29N41LjExsZqyJAh5ln597u/oO/m5vbUeeDZoegOAAAAAAAAvKYKFSqkP//8UydOnEhytntgYKC2b99u0bZ9+3blzZv3sUXrx7l796727dtnnhF+/PhxXb16VYGBgVaxPj4+8vf31+nTp9WkSZMkj+fo6Cjp3szwlOxnC/ny5dOiRYt069YtOTk5SZL27t2b4uO8+eabOn78uHLnzm3rFPEcUXQHAAAAAAAAXlPly5dXuXLlVL9+fU2cOFG5c+fWr7/+KpPJpNDQUHXv3l0lSpTQsGHD9MEHH2jnzp2aPn26ZsyY8dTndnBw0Mcff6ypU6fK3t5enTp10ltvvfXQZVmGDBmizp07y9PTU6Ghobp165b27dun6OhodevWTZkyZZKLi4vWrVunLFmyyNnZWZ6eno/dzxYaN26sfv36qV27durTp4/OnTun8ePHS/r/2ezJMXDgQNWoUUPZsmXTe++9pzRp0ujQoUM6cuSIhg8fbpNc8exRdAcAAAAAAACSKbL/4NROweaWLl2qHj16qFGjRoqLi1Pu3Lk1evRoSfdmXn/zzTcaOHCghg0bJj8/Pw0dOtTiIapPytXVVb1791bjxo31119/qWzZspo7d+5D48PCwuTq6qpx48apZ8+ecnNzU1BQkLp27Srp3hrxU6dO1dChQzVw4ECVLVtWmzdvfux+tuDh4aEffvhBHTp0UJEiRRQUFKSBAweqcePGFsvCPE6VKlW0atUqDR06VGPGjJGDg4Py58+vsLAwm+WKZ89kGIaR2km8Cq5duyZPT0/FxMTIw8MjtdMBAAB4rcTGxlo84GvFihVyd3dPxYwAAHh1vI41j5s3b+rMmTMKCAhIUcEUyRcREaGuXbvq6tWrqZ3KM7N48WK1atVKMTExNls7H6knJfcFZroDAAAAAAAAwFNasGCBcubMqcyZM+vQoUPq3bu3GjRoQMH9NUTRHQAAAAAAAACe0oULFzRw4EBduHBBfn5+ev/99zVixIjUTgupIE1qJwAAAAAAAADg9dKyZctXbmmZXr166ezZs+ZlSCZNmiRXV9fUTgupgKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICNUHQHAAAAAAAAAMBGKLoDAAAAAAAAAGAjFN0BAAAAAAAAALAR+9ROAAAAAAAAAHhZVP6q73M9308NRz3X8yH5Nm/erIoVKyo6OlpeXl6pnQ5eIMx0BwAAAAAAAF4RLVu2VJ06dVI7DeC1RtEdAAAAAAAAwHNx+/bt1E7hhcJ4vJoougMAAAAAAACviZ9//lklS5aUk5OT/Pz81KdPH929e1eStGrVKnl5eSk+Pl6SFBkZKZPJpD59+pj3DwsLU9OmTc3b27ZtU9myZeXi4qKsWbOqc+fOiouLM/fnyJFDw4YNU/PmzeXh4aF27dolmdd3332noKAgubi4KH369AoJCbE4zhdffKHAwEA5Ozsrf/78mjFjhsX+f/75pxo1aiRvb2+5ubmpePHi2r17t7l/5syZypUrlxwdHZUvXz4tXLjQYn+TyaQvvvhCdevWlaurq/LkyaOVK1daxKxZs0Z58+aVi4uLKlasqLNnz1r0//vvv2rUqJEyZ84sV1dXBQUF6csvv7SIqVChgjp16qSuXbsqQ4YMqlKlilq3bq0aNWpYxN25c0eZMmXS3LlzkxwvvNgougMAAAAAAACvgb/++kvVqlVTiRIldOjQIc2cOVNz587V8OHDJUlly5bVf//9p4MHD0q6V6DPkCGDNm/ebD7Gzz//rAoVKkiSTp06pdDQUNWvX1+HDx/W119/rW3btqlTp04W5x0/frwKFy6sgwcPasCAAVZ5nT9/Xo0aNVLr1q0VFRWlzZs3q169ejIMQ5K0ePFiDRw4UCNGjFBUVJRGjhypAQMGaP78+ZKk2NhYlS9fXn/99ZdWrlypQ4cOqVevXkpISJAkLVu2TF26dFH37t115MgRtW/fXq1atdKmTZss8hgyZIgaNGigw4cPq1q1amrSpImuXLkiSfrjjz9Ur1491axZU5GRkQoLC7P4MkKSbt68qWLFimn16tU6cuSI2rVrp2bNmmnPnj0WcfPnz5ejo6O2b9+uWbNmKSwsTOvWrdP58+fNMatWrdL169f1wQcfPP6NxQvHZCR+evFUrl27Jk9PT8XExMjDwyO10wEAAHitxMbGqnbt2ubtFStWyN3dPRUzAgDg1fE61jxu3rypM2fOKCAgQM7OzhZ9L/qDVFu2bKmrV69q+fLlVn39+vXT0qVLFRUVJZPJJEmaMWOGevfurZiYGKVJk0bFihVTo0aN1KNHD9WtW1clSpTQkCFD9O+//yomJkZZsmTRiRMnlCdPHoWFhcnOzk6ff/65+Rzbtm1T+fLlFRcXJ2dnZ+XIkUNFixbVsmXLHprzgQMHVKxYMZ09e1bZs2e36s+dO7eGDRumRo0amduGDx+uNWvWaMeOHZo9e7Z69Oihs2fPytvb22r/4OBgFSxYULNnzza3NWjQQHFxcVq9erWkezPd+/fvr2HDhkmS4uLi5O7urrVr1yo0NFSffvqpVqxYoaNHj5qP0adPH40ZM+aRD1KtUaOG8ufPr/Hjx0u6N9P92rVrOnDggEVcwYIF1aJFC/Xq1UuSVKtWLaVPn17h4eEPHTc8X4+6LzyIme4AAAAAAADAayAqKkqlS5c2F9ylewXp2NhY/fnnn5Kk8uXLa/PmzTIMQ1u3blW9evUUGBiobdu26eeff5a/v7/y5MkjSTp06JAiIiLk7u5uflWpUkUJCQk6c+aM+RzFixd/ZF6FCxdWpUqVFBQUpPfff19z5sxRdHS0pHvF71OnTqlNmzYW5xk+fLhOnTol6d4yOEWLFk2y4J543cHBwRZtwcHBioqKsmgrVKiQ+c9ubm7y8PDQpUuXzMcoVaqURXzp0qUttuPj4zVs2DAFBQXJ29tb7u7u+vHHH3Xu3DmLuGLFilnlGBYWZi6wX7x4UWvXrlXr1q2THjC88OxTOwEAAAAAAAAAL4YKFSpo3rx5OnTokBwcHJQ/f35VqFBBmzdvVnR0tMqXL2+OjY2NVfv27dW5c2er42TLls38Zzc3t0ee087OTuvXr9eOHTv0008/adq0aerXr592794tV1dXSdKcOXOsit52dnaSJBcXlye+3vs5ODhYbJtMJvMSNckxbtw4TZkyRZMnT1ZQUJDc3NzUtWtXq4elJjUezZs3V58+fbRz507t2LFDAQEBKlu27JNdCFIdM90BAAAAAACA10BgYKB27typ+1eb3r59u9KmTassWbJI+v913SdNmmQusCcW3Tdv3mxez12S3nzzTR07dky5c+e2ejk6OqYoN5PJpODgYA0ZMkQHDx6Uo6Ojli1bJh8fH/n7++v06dNW5wgICJB0b4Z6ZGSkef31pK57+/btFm3bt29XgQIFkp1fYGCg1drsu3btsjpm7dq11bRpUxUuXFg5c+bUiRMnknX89OnTq06dOgoPD1dERIRatWqV7Nzw4mGmOwAAAAAAAPAKiYmJUWRkpEVb+vTp9dFHH2ny5Mn6+OOP1alTJx0/flyDBg1St27dlCbNvbm56dKlU6FChbR48WJNnz5dklSuXDk1aNBAd+7csZjp3rt3b7311lvq1KmTwsLC5ObmpmPHjmn9+vXmfZNj9+7d2rhxoypXrqxMmTJp9+7dunz5sgIDAyXde8Bp586d5enpqdDQUN26dUv79u1TdHS0unXrpkaNGmnkyJGqU6eORo0aJT8/Px08eFD+/v4qXbq0evbsqQYNGqho0aIKCQnRDz/8oO+//14bNmxIdo4ffvihJkyYoJ49eyosLEz79+9XRESERUyePHn03XffaceOHUqXLp0mTpyoixcvJru4HxYWpho1aig+Pl4tWrRIdm548VB0BwAAAAAAAJIppQ82TQ2bN29W0aJFLdratGmjL774QmvWrFHPnj1VuHBheXt7q02bNurfv79FbPny5RUZGWme1e7t7a0CBQro4sWLypcvnzmuUKFC+vnnn9WvXz+VLVtWhmEoV65c+uCDD1KUr4eHh7Zs2aLJkyfr2rVryp49uyZMmKCqVatKuleMdnV11bhx49SzZ0+5ubkpKChIXbt2lSQ5Ojrqp59+Uvfu3VWtWjXdvXtXBQoU0GeffSZJqlOnjqZMmaLx48erS5cuCggIUHh4uMWs/cfJli2bli5dqk8++UTTpk1TyZIlNXLkSIt11/v376/Tp0+rSpUqcnV1Vbt27VSnTh3FxMQk6xwhISHy8/NTwYIF5e/vn+zc8OIxGff/Pgme2Ov4JG8AAIAXRWxsrGrXrm3eXrFihdzd3VMxIwAAXh2vY83j5s2bOnPmjAICAuTs7Jza6eA1ERsbq8yZMys8PFz16tVL7XTwgJTcF5jpDgAAAAAAAACpJCEhQf/8848mTJggLy8v1apVK7VTwlOi6A4AAIAXwuTtKfs15PvduZFgsT1zVys5uKR54uN1Df76ifcFAAAAUuLcuXMKCAhQlixZFBERIXt7SrYvO95BAAAAAAAAAEglOXLkECuAv1qefPoPAAAAAAAAAACwQNEdAAAAAAAAAAAboegOAAAAAAAAAICNUHQHAAAAAAAAAMBGKLoDAAAAAAAAAGAjFN0BAAAAAAAAALAR+9ROAAAAAAAAAHhZTN7+wXM9X9fgr5/r+Z7U5s2bVbFiRUVHR8vLy+uZnSciIkJdu3bV1atXbXbMwYMHa/ny5YqMjLTZMfF6Y6Y7AAAAAAAA8IrZuXOn7OzsVL169dROxaY++OADnThxIrXTAB6JojsAAAAAAADwipk7d64+/vhjbdmyRX///Xdqp2MzLi4uypQpU2qnkWKGYeju3bupnQaeE4ruAAAAAAAAwCskNjZWX3/9tTp06KDq1asrIiLCKuaHH35QiRIl5OzsrAwZMqhu3brmvoULF6p48eJKmzatfH191bhxY126dMli/zVr1ihv3rxycXFRxYoVdfbsWatzbNu2TWXLlpWLi4uyZs2qzp07Ky4uztyfI0cODR8+XM2bN5e7u7uyZ8+ulStX6vLly6pdu7bc3d1VqFAh7du3z7xPRESE1fI1j7qWpIwePVo+Pj5Kmzat2rRpo5s3b1rFfPHFFwoMDJSzs7Py58+vGTNmWPTv2LFDRYoUkbOzs4oXL67ly5fLZDKZl6jZvHmzTCaT1q5dq2LFisnJyUnbtm1TQkKCRo0apYCAALm4uKhw4cL67rvvLI595MgRVa1aVe7u7vLx8VGzZs30zz//PPKa8GKh6A4AAAAAAAC8Qr755hvlz59f+fLlU9OmTTVv3jwZhmHuX716terWratq1arp4MGD2rhxo0qWLGnuv3PnjoYNG6ZDhw5p+fLlOnv2rFq2bGnu/+OPP1SvXj3VrFlTkZGRCgsLU58+fSxyOHXqlEJDQ1W/fn0dPnxYX3/9tbZt26ZOnTpZxE2aNEnBwcE6ePCgqlevrmbNmql58+Zq2rSpDhw4oFy5cql58+YW+d/vcdeS1NgMHjxYI0eO1L59++Tn52dVUF+8eLEGDhyoESNGKCoqSiNHjtSAAQM0f/58SdK1a9dUs2ZNBQUF6cCBAxo2bJh69+6d5Pn69Omj0aNHKyoqSoUKFdKoUaO0YMECzZo1S0ePHtUnn3yipk2b6ueff5YkXb16Ve+8846KFi2qffv2ad26dbp48aIaNGjw0GvCi8dkPOwTixS5du2aPD09FRMTIw8Pj9ROBwAA4KXzNA8lu3MjQetGXTFvh/b1loPLk88veVkeWAYAwPPwOtY8bt68qTNnziggIEDOzs4WfS/Dg1SDg4PVoEEDdenSRXfv3pWfn5++/fZbVahQQZJUpkwZ5cyZU4sWLUrW8fbt26cSJUrov//+k7u7uz799FOtWLFCR48eNcf06dNHY8aMMT9INSwsTHZ2dvr888/NMdu2bVP58uUVFxcnZ2dn5ciRQ2XLltXChQslSRcuXJCfn58GDBigoUOHSpJ27dql0qVL6/z58/L19bV6kGpKr6VMmTIqWrSoPvvsM3PbW2+9pZs3b5pnqefOnVvDhg1To0aNzDHDhw/XmjVrtGPHDs2aNUv9+/fXn3/+af58fPHFF2rbtq0OHjyoIkWKmB8su3z5ctWuXVuSdOvWLXl7e2vDhg0qXbq0+dhhYWG6fv26lixZouHDh2vr1q368ccfzf1//vmnsmbNquPHjytv3rzJuk7Y3qPuCw9ipjsAAAAAAADwijh+/Lj27NljLhjb29vrgw8+0Ny5c80xkZGRqlSp0kOPsX//ftWsWVPZsmVT2rRpVb58eUnSuXPnJElRUVEqVaqUxT73F5El6dChQ4qIiJC7u7v5VaVKFSUkJOjMmTPmuEKFCpn/7OPjI0kKCgqyantweZvkXsuDHpd7XFycTp06pTZt2ljkPnz4cJ06dUrSvTEuVKiQReH1YbPrixcvbv7zb7/9puvXr+vdd9+1OPaCBQvMxz506JA2bdpk0Z8/f35JMsfgxWef2gkAAAAAAAAAsI25c+fq7t278vf3N7cZhiEnJydNnz5dnp6ecnFxeej+cXFxqlKliqpUqaLFixcrY8aMOnfunKpUqaLbt28nO4/Y2Fi1b99enTt3turLli2b+c8ODg7mP5tMpoe2JSQkJHmeR13Lk4iNjZUkzZkzx6o4b2dnl+Ljubm5WR179erVypw5s0Wck5OTOaZmzZoaM2aM1bH8/PxSfH6kDoruAAAAAAAAwCvg7t27WrBggSZMmKDKlStb9NWpU0dffvmlPvzwQxUqVEgbN25Uq1atrI7x66+/6t9//9Xo0aOVNWtWSbJ4kKkkBQYGauXKlRZtu3btsth+8803dezYMeXOndsWl/ZQj7qWpAQGBmr37t1q3ry5ue3+3H18fOTv76/Tp0+rSZMmSR4jX758WrRokW7dumUulu/du/ex5y5QoICcnJx07tw5828PPOjNN9/U0qVLlSNHDtnbU7p9WbG8DAAAAAAAAPAKWLVqlaKjo9WmTRu98cYbFq/69eubl5gZNGiQvvzySw0aNEhRUVH65ZdfzDOrs2XLJkdHR02bNk2nT5/WypUrNWzYMIvzfPjhhzp58qR69uyp48ePa8mSJYqIiLCI6d27t3bs2KFOnTopMjJSJ0+e1IoVK6wepPq0HnUtSenSpYvmzZun8PBwnThxQoMGDbJYm16ShgwZolGjRmnq1Kk6ceKEfvnlF4WHh2vixImSpMaNGyshIUHt2rVTVFSUfvzxR40fP17S/8/MT0ratGnVo0cPffLJJ5o/f75OnTqlAwcOaNq0aeaHtHbs2FFXrlxRo0aNtHfvXp06dUo//vijWrVqpfj4+KcdLjwnfF0CAAAAAAAAJNOL/MD1uXPnKiQkRJ6enlZ99evX19ixY3X48GFVqFBB3377rYYNG6bRo0fLw8ND5cqVkyRlzJhRERER+vTTTzV16lS9+eabGj9+vGrVqmU+VrZs2bR06VJ98sknmjZtmkqWLKmRI0eqdevW5phChQrp559/Vr9+/VS2bFkZhqFcuXLpgw9s+yDaR11LUj744AOdOnVKvXr10s2bN1W/fn116NDB4sGlYWFhcnV11bhx49SzZ0+5ubkpKChIXbt2lSR5eHjohx9+UIcOHVSkSBEFBQVp4MCBaty48WMfsDls2DBlzJhRo0aN0unTp+Xl5aU333xTn376qSTJ399f27dvV+/evVW5cmXdunVL2bNnV2hoqNKkYf70y8JkGIaR2km8Cl7HJ3kDAADY0uTtT/4fsDs3ErRu1BXzdmhfbzm4PPl/Sl7k/0wDAPC8vY41j5s3b+rMmTMKCAh4bBEVkKTFixerVatWiomJsfk683gxpOS+wEx3AAAAAAAAAEiBBQsWKGfOnMqcObMOHTqk3r17q0GDBhTcIYmiOwAAAAAAAACkyIULFzRw4EBduHBBfn5+ev/99zVixIjUTgsvCIruAAAAAAAAAJACvXr1Uq9evVI7DbygWH0fAAAAAAAAAAAboegOAAAAAAAAJMEwjNROAcALIiX3A4ruAAAAAAAAwH0cHBwkSdevX0/lTAC8KG7fvi1JsrOze2zsC72me3x8vAYPHqxFixbpwoUL8vf3V8uWLdW/f3+ZTCZJ975hGDRokObMmaOrV68qODhYM2fOVJ48eczHuXLlij7++GP98MMPSpMmjerXr68pU6bI3d3dHHP48GF17NhRe/fuVcaMGfXxxx+zLhMAAAAAAMBryM7OTl5eXrp06ZIkydXV1VyLAvD6SUhI0OXLl+Xq6ip7+8eX1F/oovuYMWM0c+ZMzZ8/XwULFtS+ffvUqlUreXp6qnPnzpKksWPHaurUqZo/f74CAgI0YMAAValSRceOHZOzs7MkqUmTJjp//rzWr1+vO3fuqFWrVmrXrp2WLFkiSbp27ZoqV66skJAQzZo1S7/88otat24tLy8vtWvXLtWuHwAAAAAAAKnD19dXksyFdwCvtzRp0ihbtmzJ+gLuhS6679ixQ7Vr11b16tUlSTly5NCXX36pPXv2SLo3y33y5Mnq37+/ateuLUlasGCBfHx8tHz5cjVs2FBRUVFat26d9u7dq+LFi0uSpk2bpmrVqmn8+PHy9/fX4sWLdfv2bc2bN0+Ojo4qWLCgIiMjNXHiRIruAAAAAAAAryGTySQ/Pz9lypRJd+7cSe10AKQyR0dHpUmTvNXaX+iie5kyZTR79mydOHFCefPm1aFDh7Rt2zZNnDhRknTmzBlduHBBISEh5n08PT1VqlQp7dy5Uw0bNtTOnTvl5eVlLrhLUkhIiNKkSaPdu3erbt262rlzp8qVKydHR0dzTJUqVTRmzBhFR0crXbp0VrndunVLt27dMm9fu3btWQwBAAAAAAAAUpGdnV2y1nAGgEQvdNG9T58+unbtmvLnzy87OzvFx8drxIgRatKkiSTpwoULkiQfHx+L/Xx8fMx9Fy5cUKZMmSz67e3t5e3tbRETEBBgdYzEvqSK7qNGjdKQIUNscJUAAAAAAAAAgFdF8ubDp5JvvvlGixcv1pIlS3TgwAHNnz9f48eP1/z581M7NfXt21cxMTHm1x9//JHaKQEAAAAAAAAAUtkLPdO9Z8+e6tOnjxo2bChJCgoK0u+//65Ro0apRYsW5gdaXLx4UX5+fub9Ll68qCJFiki699CLBx94cffuXV25csW8v6+vry5evGgRk7idGPMgJycnOTk5Pf1FAgAAAAAAAABeGS/0TPfr169bLU5vZ2enhIQESVJAQIB8fX21ceNGc/+1a9e0e/dulS5dWpJUunRpXb16Vfv37zfH/O9//1NCQoJKlSpljtmyZYvFQzHWr1+vfPnyJbm0DAAAAAAAAAAASXmhi+41a9bUiBEjtHr1ap09e1bLli3TxIkTVbduXUn3niLdtWtXDR8+XCtXrtQvv/yi5s2by9/fX3Xq1JEkBQYGKjQ0VG3bttWePXu0fft2derUSQ0bNpS/v78kqXHjxnJ0dFSbNm109OhRff3115oyZYq6deuWWpcOAAAAAAAAAHgJvdDLy0ybNk0DBgzQRx99pEuXLsnf31/t27fXwIEDzTG9evVSXFyc2rVrp6tXr+rtt9/WunXr5OzsbI5ZvHixOnXqpEqVKilNmjSqX7++pk6dau739PTUTz/9pI4dO6pYsWLKkCGDBg4cqHbt2j3X6wUAAAAAAAAAvNxMhmEYqZ3Eq+DatWvy9PRUTEyMPDw8UjsdAACAl87k7R888b53biRo3agr5u3Qvt5ycHnyX+rsGvz1E+8LAMCrhpoHAKTMC728DAAAAAAAAAAALxOK7gAAAAAAAAAA2AhFdwAAAAAAAAAAbISiOwAAAAAAAAAANkLRHQAAAAAAAAAAG6HoDgAAAAAAAACAjVB0BwAAAAAAAADARii6AwAAAAAAAABgIxTdAQAAAAAAAACwEYruAAAAAAAAAADYCEV3AAAAAAAAAABshKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICN2Kd2AgAAAAAAAE+i8ld9UzsFs58ajkrtFAAALwhmugMAAAAAAAAAYCMU3QEAAAAAAAAAsBGK7gAAAAAAAAAA2AhFdwAAAAAAAAAAbISiOwAAAAAAAAAANkLRHQAAAAAAAAAAG6HoDgAAAAAAAACAjVB0BwAAAAAAAADARii6AwAAAAAAAABgIxTdAQAAAAAAAACwEYruAAAAAAAAAADYCEV3AAAAAAAAAABshKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICN2Kd2AgAAAHh5GYahuLg487abm5tMJlMqZgQAAAAAqYuiOwAAAJ5YXFycateubd5esWKF3N3dUzEjAAAAAEhdLC8DAAAAAAAAAICNUHQHAAAAAAAAAMBGKLoDAAAAAAAAAGAjrOkOAACAl569s0mhfb0ttgEAAAAgNVB0BwAAwEvPZDLJwYVCOwAAAIDUx/IyAAAAAAAAAADYCEV3AAAAAAAAAABshKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICNUHQHAAAAAAAAAMBGKLoDAAAAAAAAAGAjFN0BAAAAAAAAALARiu4AAAAAAAAAANgIRXcAAAAAAAAAAGyEojsAAAAAAAAAADZC0R0AAAAAAAAAABuh6A4AAAAAAAAAgI1QdAcAAAAAAAAAwEYougMAAAAAAAAAYCMU3QEAAAAAAAAAsBGK7gAAAAAAAAAA2AhFdwAAAAAAAAAAbISiOwAAAAAAAAAANkLRHQAAAAAAAAAAG6HoDgAAAAAAAACAjVB0BwAAAAAAAADARii6AwAAAAAAAABgIxTdAQAAAAAAAACwEYruAAAAAAAAAADYCEV3AAAAAAAAAABshKI7AAAAAAAAAAA2QtEdAAAAAAAAAAAboegOAAAAAAAAAICNUHQHAAAAAAAAAMBGKLoDAAAAAAAAAGAjFN0BAAAAAAAAALARiu4AAAAAAAAAANgIRXcAAAAAAAAAAGyEojsAAAAAAAAAADZC0R0AAAAAAAAAABuh6A4AAAAAAAAAgI1QdAcAAAAAAAAAwEYougMAAAAAAAAAYCMU3QEAAAAAAAAAsBGK7gAAAAAAAAAA2AhFdwAAAAAAAAAAbISiOwAAAAAAAAAANmKf2gkAAAAAAIDXh2EYiouLM2+7ubnJZDKlYkYAANgWRXcAAIDXWOWv+j7V/satuxbbdZcOkcnpyf6JWS3rU6UCAHhJxMXFqXbt2ubtFStWyN3dPRUzAgDAtlheBgAAAAAAAAAAG6HoDgAAAAAAAACAjVB0BwAAAAAAAADARp6o6L5161Y1bdpUpUuX1l9//SVJWrhwobZt22bT5AAAAAAAAAAAeJmkuOi+dOlSValSRS4uLjp48KBu3bolSYqJidHIkSNtniAAAAAAAAAAAC+LFBfdhw8frlmzZmnOnDlycHAwtwcHB+vAgQM2TQ4AAAAAAAAAgJdJiovux48fV7ly5azaPT09dfXqVVvkBAAAAAAAAADASynFRXdfX1/99ttvVu3btm1Tzpw5bZLU/f766y81bdpU6dOnl4uLi4KCgrRv3z5zv2EYGjhwoPz8/OTi4qKQkBCdPHnS4hhXrlxRkyZN5OHhIS8vL7Vp00axsbEWMYcPH1bZsmXl7OysrFmzauzYsTa/FgAAAAAAAADAqy3FRfe2bduqS5cu2r17t0wmk/7++28tXrxYPXr0UIcOHWyaXHR0tIKDg+Xg4KC1a9fq2LFjmjBhgtKlS2eOGTt2rKZOnapZs2Zp9+7dcnNzU5UqVXTz5k1zTJMmTXT06FGtX79eq1at0pYtW9SuXTtz/7Vr11S5cmVlz55d+/fv17hx4zR48GDNnj3bptcDAAAAAAAAAHi12ad0hz59+ighIUGVKlXS9evXVa5cOTk5OalHjx76+OOPbZrcmDFjlDVrVoWHh5vbAgICzH82DEOTJ09W//79Vbt2bUnSggUL5OPjo+XLl6thw4aKiorSunXrtHfvXhUvXlySNG3aNFWrVk3jx4+Xv7+/Fi9erNu3b2vevHlydHRUwYIFFRkZqYkTJ1oU5wEAAAAAAAAAeJQUzXSPj4/X1q1b1bFjR125ckVHjhzRrl27dPnyZQ0bNszmya1cuVLFixfX+++/r0yZMqlo0aKaM2eOuf/MmTO6cOGCQkJCzG2enp4qVaqUdu7cKUnauXOnvLy8zAV3SQoJCVGaNGm0e/duc0y5cuXk6OhojqlSpYqOHz+u6OjoJHO7deuWrl27ZvECAAAAAAAAALzeUlR0t7OzU+XKlRUdHS1HR0cVKFBAJUuWlLu7+zNJ7vTp05o5c6by5MmjH3/8UR06dFDnzp01f/58SdKFCxckST4+Phb7+fj4mPsuXLigTJkyWfTb29vL29vbIiapY9x/jgeNGjVKnp6e5lfWrFmf8moBAAAAAAAAAC+7FK/p/sYbb+j06dPPIhcrCQkJevPNNzVy5EgVLVpU7dq1U9u2bTVr1qzncv5H6du3r2JiYsyvP/74I7VTAgAAAAAAAACkshSv6T58+HD16NFDw4YNU7FixeTm5mbR7+HhYbPk/Pz8VKBAAYu2wMBALV26VJLk6+srSbp48aL8/PzMMRcvXlSRIkXMMZcuXbI4xt27d3XlyhXz/r6+vrp48aJFTOJ2YsyDnJyc5OTk9IRXBgAAAADAy6nI8MFPtb/pzl1537dddtxoGQ4pLk9IkjLlfqpUAAB4JlI8071atWo6dOiQatWqpSxZsihdunRKly6dvLy8lC5dOpsmFxwcrOPHj1u0nThxQtmzZ5d076Gqvr6+2rhxo7n/2rVr2r17t0qXLi1JKl26tK5evar9+/ebY/73v/8pISFBpUqVMsds2bJFd+7cMcesX79e+fLls/k1AQAAAAAAAABeXSn+KnnTpk3PIo8kffLJJypTpoxGjhypBg0aaM+ePZo9e7Zmz54tSTKZTOratauGDx+uPHnyKCAgQAMGDJC/v7/q1Kkj6d7M+NDQUPOyNHfu3FGnTp3UsGFD+fv7S5IaN26sIUOGqE2bNurdu7eOHDmiKVOmaNKkSc/tWgEAAAAAAAAAL78UF93Lly//LPJIUokSJbRs2TL17dtXQ4cOVUBAgCZPnqwmTZqYY3r16qW4uDi1a9dOV69e1dtvv61169bJ2dnZHLN48WJ16tRJlSpVUpo0aVS/fn1NnTrV3O/p6amffvpJHTt2VLFixZQhQwYNHDhQ7dq1e27XCgAAAAAAAAB4+T3RomlXr17V3LlzFRUVJUkqWLCgWrduLU9PT5smJ0k1atRQjRo1HtpvMpk0dOhQDR069KEx3t7eWrJkySPPU6hQIW3duvWJ8wQAAAAAAAAAIMVruu/bt0+5cuXSpEmTdOXKFV25ckUTJ05Urly5dODAgWeRIwAAAAAAAAAAL4UUz3T/5JNPVKtWLc2ZM0f29vd2v3v3rsLCwtS1a1dt2bLF5kkCAAAAAAAAAPAySHHRfd++fRYFd0myt7dXr169VLx4cZsmBwAAAAAAAADAyyTFy8t4eHjo3LlzVu1//PGH0qZNa5OkAAAAAAAAAAB4GaW46P7BBx+oTZs2+vrrr/XHH3/ojz/+0FdffaWwsDA1atToWeQIAAAAAAAAAMBLIcXLy4wfP14mk0nNmzfX3bt3JUkODg7q0KGDRo8ebfMEAQAAAAB4GRmGobi4OPO2m5ubTCZTKmYEAACehxQX3R0dHTVlyhSNGjVKp06dkiTlypVLrq6uNk8OAAAAAICXVVxcnGrXrm3eXrFihdzd3VMxIwAA8DykuOgeExOj+Ph4eXt7KygoyNx+5coV2dvby8PDw6YJAgAAAAAAvMr4rQgAeLWkeE33hg0b6quvvrJq/+abb9SwYUObJAUAAAAAqcUwDMXGxppfhmGkdkoAXnGJvxWR+Lq/AA8AePmkeKb77t27NXHiRKv2ChUqqF+/fjZJCgAAAABSC0uCAM+WYW+nK2+XttgGAOBVkuKi+61bt8wPUL3fnTt3dOPGDZskBQAAAAAAXlEmkwyHFJcjAAB4aaT4b7mSJUtq9uzZmjZtmkX7rFmzVKxYMZslBgAAAABAaqtR6dMn3teQ5YS1D2oPlSnl/w03W7Vx5BPvCwAAnp8U/20/fPhwhYSE6NChQ6pUqZIkaePGjdq7d69++uknmycIvOp4YA4AIKX4uwMAAAAAXlwpLroHBwdr586dGjdunL755hu5uLioUKFCmjt3rvLkyfMscgReaawZCgBIKf7uAACkFF/YAgDw/DzR77UVKVJEixcvtnUuAAAAAADgGeALWwAAnp9kF93v3r2r+Ph4OTk5mdsuXryoWbNmKS4uTrVq1dLbb7/9TJIEAAAAAAAAAOBlkOyie9u2beXo6KjPP/9ckvTff/+pRIkSunnzpvz8/DRp0iStWLFC1apVe2bJAgAAAAAAAADwIkuT3MDt27erfv365u0FCxYoPj5eJ0+e1KFDh9StWzeNGzfumSQJAAAAAMDLx07OKmZ+SXapnRAAAHgOkl10/+uvvywelLpx40bVr19fnp6ekqQWLVro6NGjts8QAAAAAICXkEkmmWR/34sHlwIA8DpIdtHd2dlZN27cMG/v2rVLpUqVsuiPjY21bXYAAAAAAAAAALxEkr2me5EiRbRw4UKNGjVKW7du1cWLF/XOO++Y+0+dOiV/f/9nkiQAAMCrpMjwwU+1v+nOXXnft1123GgZDsn+Z52FTLmfKhW85AzDUFxcnHnbzc1NJhMzcYEXVdn2w5585/g7crxvs2rXsZKdw5MdK+uTpwEAwOsg2f87GzhwoKpWrapvvvlG58+fV8uWLeXn52fuX7ZsmYKDg59JkgAAAABsLy4uTrVr1zZvr1ixQu7u7qmYEQAAAPDyS3bRvXz58tq/f79++ukn+fr66v3337foL1KkiEqWLGnzBAEAAAAAAAAAeFmk6PeQAwMDFRgYmGRfu3btLLarV6+uL774wmI2PAAAAAAAAAAAr7JkP0g1pbZs2WLx4FUAAAAAAAAAAF51z6zoDgAAAAAAAADA6yZFy8sAAAAAFhztlKb5mxbbAIAXUBp73Q4IttgGAADPBn/LAgAA4ImZTCbJiX9SAsALz2SS7BxSOwsAAF4LLC8DAAAAAAAAAICNMC0JAAC8sAzDUFxcnHnbzc3t3szq15xhb6crb5e22AYAAAAAvBieWdH9008/lbe397M6PAAAeA3ExcWpdu3a5u0VK1bI3d09FTN6QZhMMhyYOwEAAAAAL6Jk/W9t5cqVyT5grVq1JEl9+/Z9sowAAAAAAAAAAHhJJavoXqdOnWQdzGQyKT4+/mnyAQAA/9fefcdZUZ99478OZZeyLohIkyIqIlYUFbGBSlh88BFbJIqxoUbFW8FYbgwRy60i1jvGGhXiHQ3KHSPGgiKKDSxBiLRgQ0GlRBFQQJYyvz/ycH4cl7K7DOwuvN+v13nJzHxnzjXjXGeWD7NzAACocu5+u1e5112xbHXO9P3vnBM1a5f/a/j6HfZkudcFYNOVKnRfvXr1xgcBAKzDccdcU+51k1iZM92r5w2R2YSn4z035uZyrwsAAACl4WGgAACl4Etdoepo/1/XbdL6mRUrY+1vpzritsHl/h6FSQM3rRYAAKqecv3kuGTJknj99ddj1qxZUVxcnLPs0ksvTaUwAIDKxJe6Uln5bRIAAKhcyvwT9cSJE+P//J//E0uXLo0lS5ZEgwYN4ptvvok6depEo0aNhO4AAAAAAGyzyvytHP3794//+3//b3z33XdRu3bteOedd+KLL76IDh06xO233745agQAtlnVo1Z0yL4iqld0QQAAALBBZb7TfdKkSfHggw9GtWrVonr16rF8+fLYZZddYsiQIXHWWWfFSSedtDnqBAC2QZnIRJpfQXPEr24s/8qrVkTeWpPH9hsSUb1m+bbVovxlAAAAULmV+U73mjVrRrVq/16tUaNGMWvWrIiIqFevXsyePTvd6gAAAAAAoAop861j+++/f7z//vvRpk2b6Ny5c1x77bXxzTffxP/8z//E3nvvvTlqBAAAAACAKqHMd7rffPPN0bRp04iIuOmmm2L77bePiy66KP71r3/Fgw8+mHqBAAAAAABQVZT5TvcDDzww++dGjRrFqFGjUi0IAKBSqlYjilsfljMNAAAAP1XmO92PPvroWLhwYYn5ixcvjqOPPjqNmgAAKp9M5t9fnLrmlclUdEUAAABUQmUO3ceOHRvFxcUl5v/444/x5ptvplIUAAAAAABURaX+vegPP/ww++dp06bF3Llzs9OrVq2KUaNGxU477ZRudQAAAAAAUIWUOnRv3759ZDKZyGQy63yMTO3ateOee+5JtTgAqqYkSWLJkiXZ6bp160bGozgAAACAbUCpQ/eZM2dGkiSxyy67xHvvvRc77rhjdlleXl40atQoqlevvlmKBKBqWbJkSfTs2TM7PXLkyCgoKKjAigAAAAC2jFKH7q1atYqIiNWrV2+2YgAAgC2petSKDjnTAADApil16L62Tz/9NO6+++6YPn16RETsueeecdlll8Wuu+6aanEAAMDmk4lMlPOvBAAAwHpUK+sKL730Uuy5557x3nvvxb777hv77rtvvPvuu7HXXnvF6NGjN0eNAAAAAABQJZT5tpb//M//jP79+8fgwYNLzL/66qvjZz/7WWrFAVAx2v/XdZu0fmbFymiw1vQRtw2OpGb57qScNHDTagEAAADYksp8p/v06dOjT58+Jeafe+65MW3atFSKAgAAAACAqqjMofuOO+4YkyZNKjF/0qRJ0ahRozRqAgAAAACAKqnUv+t/ww03xBVXXBHnn39+XHDBBfHZZ5/FoYceGhERb7/9dtx6661x+eWXb7ZCASqjJEliyZIl2em6detGJpOpwIoAAAAAqEilDt2vv/76uPDCC+O3v/1tbLfddnHHHXfEgAEDIiKiWbNmcd1118Wll1662QoFqIyWLFkSPXv2zE6PHDkyCgoKKrAiAAAAACpSqUP3JEkiIiKTyUT//v2jf//+8f3330dExHbbbbd5qgMAAADYytWolYnuAxrkTANQdZU6dI+IEo9MELYDW4Pjjrmm3OsmsTJnulfPGyJTto/WHM+Nubnc61YmSY3qseDwTjnTAFBVuI4BW1omk4matQXtAFuLMiVDu++++0afVbxgwYJNKgiArUAmE0nN8v/jw9bI8/8BNqxSfU66jgEAsAnK9JPk9ddfH/Xq1dtctQDAVsvz/wE2zOckAABbizKF7r/4xS+iUaNGm6sWAAAAAACo0koduvsVeIB1qR61okPONAAAAADbrlKH7kmSbM46AKqkTGSijL80BAAAAMBWrNRJ0erVqzdnHQAAAAAAUOVVq+gCAAAAAABga+GZCABbiSRJYsmSJdnpunXr+j4OAAAAgC1M6A6wlViyZEn07NkzOz1y5MgoKCiowIoAAAAAtj1Cd4BK5Ihf3Vj+lVetiLy1Jo/tNySies3ybatF+csAAAAA2JYJ3QEAgFT4x2MAAPBFqgAAAAAAkBp3um/lfLEibEOq1Yji1oflTAMAAACwZUlktnK+WBG2IZlM+X8NHwAAAIBUeLwMAAAAAACkxJ3usIm6DR+wSesny1fmTJ/4l+sjk1++1nz5F7dsUi0AAAAAwKZxpzsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBJfpAoAAFS8ajWiuPVhOdMAAFAV+UkWAACoeJlMRPWaFV0FAABsMo+XAQAAAACAlLjTHYCtWpIksWTJkux03bp1I5PJVGBFAAAAwNZM6A7AVm3JkiXRs2fP7PTIkSOjoKCgXNu6++1e5a5jxbLVOdP3v3NO1Kxd/l8463fYk+VeFwAAANh8PF4GAAAAAABSInQHAAAAAICUCN0BAAAAACAlQncAAAAAAEiJ0B0AAAAAAFIidAcAAAAAgJRUqdB98ODBkclkol+/ftl5P/74Y/Tt2zd22GGHKCgoiJNPPjnmzZuXs96sWbOiR48eUadOnWjUqFFceeWVsXLlypwxY8eOjQMOOCDy8/Njt912i2HDhm2BPQIAAAAAYGtSo6ILKK33338/Hnzwwdh3331z5vfv3z+ef/75GDFiRNSrVy8uueSSOOmkk+Ltt9+OiIhVq1ZFjx49okmTJjFu3LiYM2dOnHnmmVGzZs24+eabIyJi5syZ0aNHj7jwwgvj8ccfjzFjxsR5550XTZs2jaKioi2+rz913DHXlHvdJHL/caFXzxsiswn/258bc3O51wUoj27DB2zS+sny3M/BE/9yfWTyy/c5+H9abFIpAAAAwDagStzp/sMPP0Tv3r3jD3/4Q2y//fbZ+YsWLYpHHnkk7rzzzjj66KOjQ4cOMXTo0Bg3bly88847ERHx8ssvx7Rp0+JPf/pTtG/fPo499ti48cYb4957743i4uKIiHjggQeidevWcccdd0S7du3ikksuiVNOOSXuuuuu9da0fPnyWLx4cc4LAAAAAIBtW5UI3fv27Rs9evSIrl275syfMGFCrFixImf+HnvsES1btozx48dHRMT48eNjn332icaNG2fHFBUVxeLFi2Pq1KnZMT/ddlFRUXYb63LLLbdEvXr1sq8WLdz+CAAAAACwrav0ofvw4cPjgw8+iFtuuaXEsrlz50ZeXl7Ur18/Z37jxo1j7ty52TFrB+5rlq9ZtqExixcvjmXLlq2zrgEDBsSiRYuyr9mzZ5dr/wAAAAAA2HpU6me6z549Oy677LIYPXp01KpVq6LLyZGfnx/5+fkVXQYAAAAAAJVIpb7TfcKECTF//vw44IADokaNGlGjRo14/fXX43e/+13UqFEjGjduHMXFxbFw4cKc9ebNmxdNmjSJiIgmTZrEvHnzSixfs2xDYwoLC6N27dqbae8AAAAAANjaVOrQ/ZhjjonJkyfHpEmTsq8DDzwwevfunf1zzZo1Y8yYMdl1ZsyYEbNmzYpOnTpFRESnTp1i8uTJMX/+/OyY0aNHR2FhYey5557ZMWtvY82YNdsAAAAAAIDSqNSPl9luu+1i7733zplXt27d2GGHHbLz+/TpE5dffnk0aNAgCgsL4z/+4z+iU6dOccghh0RERLdu3WLPPfeMX/7ylzFkyJCYO3duDBw4MPr27Zt9PMyFF14Yv//97+Oqq66Kc889N1599dV46qmn4vnnn9+yOwwAAAAAQJVWqUP30rjrrruiWrVqcfLJJ8fy5cujqKgo7rvvvuzy6tWrx3PPPRcXXXRRdOrUKerWrRtnnXVW3HDDDdkxrVu3jueffz769+8f//3f/x3NmzePhx9+OIqKiipilwBIU171qHbmATnTAAAAAJtLlQvdx44dmzNdq1atuPfee+Pee+9d7zqtWrWKF154YYPb7dKlS0ycODGNEgGoRDKZTER+lbvcAQAAAFVUpX6mOwAAAAAAVCVCdwAAAAAASInft2eblCRJLFmyJDtdt27dfz+CAgAAAABgEwjd2SYtWbIkevbsmZ0eOXJkFBQUVGBFAAAAAMDWQOgOAFtAjVqZ6D6gQc40AAAAsPURugPAFpDJZKJmbUE7AAAAbO18kSoAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApKRGRRfA5lY9akWHnGkAAAAAADYPoftWLhOZ8L8ZAAAAAGDL8HgZAAAAAABIidAdAAAAAABS4rkjbDFJksSSJUuy03Xr1o1MJlOBFQEAAAAApEvozhazZMmS6NmzZ3Z65MiRUVBQUIEVAQAAAACky+NlAAAAAAAgJUJ3AAAAAABIidAdAAAAAABSInQHAAAAAICUCN0BAAAAACAlNSq6AKqWI351Y/lXXrUi8taaPLbfkIjqNcu1qTcf/G356wAAAAAA2Ezc6Q4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBLPdKdKav9f123S+pkVK6PBWtNH3DY4kprla4dGu21SKQAAAADAVsSd7gAAAAAAkBKhOwAAAAAApMTjZdhyqtWI4taH5UwTEXnVo9qZB+RMAwAAAABVk9STLSeTiahes6KrqHQymUxEvlYEAAAAgK2Bx8sAAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASmpUdAFQEZIa1WPB4Z1ypgEAAAAANpXQnW1TJhNJTac/AAAAAJAuj5cBAAAAAICUCN0BAAAAACAlQncAAAAAAEiJ0B0AAAAAAFIidAcAAAAAgJQI3QEAAAAAICVCdwAAAAAASInQHQAAAAAAUiJ0BwAAAACAlAjdAQAAAAAgJUJ3AAAAAABIidAdAAAAAABSInQHAAAAAICUCN0BAAAAACAlQncAAAAAAEiJ0B0AAAAAAFIidAcAAAAAgJQI3QEAAAAAICVCdwAAAAAASInQHQAAAAAAUiJ0BwAAAACAlAjdAQAAAAAgJUJ3AAAAAABIidAdAAAAAABSInQHAAAAAICUCN0BAAAAACAlQncAAAAAAEiJ0B0AAAAAAFIidAcAAAAAgJQI3QEAAAAAICVCdwAAAAAASInQHQAAAAAAUiJ0BwAAAACAlAjdAQAAAAAgJZU+dL/lllvioIMOiu222y4aNWoUJ5xwQsyYMSNnzI8//hh9+/aNHXbYIQoKCuLkk0+OefPm5YyZNWtW9OjRI+rUqRONGjWKK6+8MlauXJkzZuzYsXHAAQdEfn5+7LbbbjFs2LDNvXsAAAAAAGxFKn3o/vrrr0ffvn3jnXfeidGjR8eKFSuiW7dusWTJkuyY/v37x9/+9rcYMWJEvP766/H111/HSSedlF2+atWq6NGjRxQXF8e4cePij3/8YwwbNiyuvfba7JiZM2dGjx494qijjopJkyZFv3794rzzzouXXnppi+4vAAAAAABVV42KLmBjRo0alTM9bNiwaNSoUUyYMCGOPPLIWLRoUTzyyCPxxBNPxNFHHx0REUOHDo127drFO++8E4cccki8/PLLMW3atHjllVeicePG0b59+7jxxhvj6quvjuuuuy7y8vLigQceiNatW8cdd9wRERHt2rWLt956K+66664oKira4vsNAAAAAEDVU+nvdP+pRYsWRUREgwYNIiJiwoQJsWLFiujatWt2zB577BEtW7aM8ePHR0TE+PHjY5999onGjRtnxxQVFcXixYtj6tSp2TFrb2PNmDXb+Knly5fH4sWLc14AAAAAAGzbqlTovnr16ujXr18cdthhsffee0dExNy5cyMvLy/q16+fM7Zx48Yxd+7c7Ji1A/c1y9cs29CYxYsXx7Jly0rUcsstt0S9evWyrxYtWqSyjwAAAAAAVF1VKnTv27dvTJkyJYYPH17RpcSAAQNi0aJF2dfs2bMruiQAAAAAACpYpX+m+xqXXHJJPPfcc/HGG29E8+bNs/ObNGkSxcXFsXDhwpy73efNmxdNmjTJjnnvvfdytjdv3rzssjX/XTNv7TGFhYVRu3btEvXk5+dHfn5+KvsGAAAAAMDWodLf6Z4kSVxyySXx17/+NV599dVo3bp1zvIOHTpEzZo1Y8yYMdl5M2bMiFmzZkWnTp0iIqJTp04xefLkmD9/fnbM6NGjo7CwMPbcc8/smLW3sWbMmm0AAAAAAMDGVPo73fv27RtPPPFEjBw5MrbbbrvsM9jr1asXtWvXjnr16kWfPn3i8ssvjwYNGkRhYWH8x3/8R3Tq1CkOOeSQiIjo1q1b7LnnnvHLX/4yhgwZEnPnzo2BAwdG3759s3erX3jhhfH73/8+rrrqqjj33HPj1Vdfjaeeeiqef/75Ctt3AAAAAACqlkp/p/v9998fixYtii5dukTTpk2zryeffDI75q677orjjjsuTj755DjyyCOjSZMm8fTTT2eXV69ePZ577rmoXr16dOrUKc4444w488wz44YbbsiOad26dTz//PMxevTo2G+//eKOO+6Ihx9+OIqKirbo/gIAAAAAUHVV+jvdkyTZ6JhatWrFvffeG/fee+96x7Rq1SpeeOGFDW6nS5cuMXHixDLXCAAAAAAAEVXgTncAAAAAAKgqhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACkROgOAAAAAAApEboDAAAAAEBKhO4AAAAAAJASoTsAAAAAAKRE6A4AAAAAACkRugMAAAAAQEqE7j9x7733xs477xy1atWKjh07xnvvvVfRJQEAAAAAUEUI3dfy5JNPxuWXXx6DBg2KDz74IPbbb78oKiqK+fPnV3RpAAAAAABUAUL3tdx5551x/vnnxznnnBN77rlnPPDAA1GnTp149NFHK7o0AAAAAACqgBoVXUBlUVxcHBMmTIgBAwZk51WrVi26du0a48ePLzF++fLlsXz58uz0okWLIiJi8eLFqde2YuXyjQ/aQlYWZyq6hIiIWPXj6oouIWvl0srz/2dznH/bAj1Wkh5btx+XrKjoErKqUr/rsZL02LrpsfLRYyVVph6rSucS66bHSqpMPeY6tm5pf/as2V6SJKluF2BrlUl8YkZExNdffx077bRTjBs3Ljp16pSdf9VVV8Xrr78e7777bs746667Lq6//votXSYAAABAhZg9e3Y0b968ossAqPTc6V5OAwYMiMsvvzw7vXr16liwYEHssMMOkclUjrsP2LDFixdHixYtYvbs2VFYWFjR5cBWR4/B5qXHYPPSY7B56bGqJUmS+P7776NZs2YVXQpAlSB0/38aNmwY1atXj3nz5uXMnzdvXjRp0qTE+Pz8/MjPz8+ZV79+/c1ZIptJYWGhH/JgM9JjsHnpMdi89BhsXnqs6qhXr15FlwBQZfgi1f8nLy8vOnToEGPGjMnOW716dYwZMybncTMAAAAAALA+7nRfy+WXXx5nnXVWHHjggXHwwQfH3XffHUuWLIlzzjmnoksDAAAAAKAKELqvpVevXvGvf/0rrr322pg7d260b98+Ro0aFY0bN67o0tgM8vPzY9CgQSUeEwSkQ4/B5qXHYPPSY7B56TEAtmaZJEmSii4CAAAAAAC2Bp7pDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7W1yXLl0ik8lEJpOJSZMmVXQ5FeqQQw6Jv/zlLxVdBhVEL1Rderfy0U9br+Li4th5553j73//e0WXsk3TY1uvadOmRfPmzWPJkiUVXco2RU9t237xi1/EHXfcUdFlALAZCd2pEOeff37MmTMn9t577+y8WbNmRY8ePaJOnTrRqFGjuPLKK2PlypVl2u51112X/eF1zWuPPfYoMW78+PFx9NFHR926daOwsDCOPPLIWLZsWUREfP7559GnT59o3bp11K5dO3bdddcYNGhQFBcXZ9f//PPPS7xPJpOJd955J+d9RowYEXvssUfUqlUr9tlnn3jhhRdylg8cODD+8z//M1avXl2m/WTrsa5eWNe5NXz48Jz1li9fHr/5zW+iVatWkZ+fHzvvvHM8+uij2eV/+MMf4ogjjojtt98+tt9+++jatWu89957Ods4++yzS7xP9+7dc8YsWLAgevfuHYWFhVG/fv3o06dP/PDDD2Xax9LUEhExffr0OP7446NevXpRt27dOOigg2LWrFnZ5Q899FB06dIlCgsLI5PJxMKFC0tsozT1fvjhh3HEEUdErVq1okWLFjFkyJAS29G7VdNP++kf//hHnHbaadGiRYuoXbt2tGvXLv77v/+7xHob66epU6fGySefHDvvvHNkMpm4++671/n+9957b+y8885Rq1at6NixY4nz/Mcff4y+ffvGDjvsEAUFBXHyySfHvHnzcsakcS1c2+DBgyOTyUS/fv1y5pemn2666aY49NBDo06dOlG/fv0Sy4cNG7bOz6tMJhPz58+PiIixY8euc/ncuXNztrWhY5eXlxdXXHFFXH311eU+DqRjXdesNb799tto3rx5ifNpzpw5cfrpp8fuu+8e1apVK3EuRpSux9Ys++mrb9++2TFrh5hrXhdeeGHOdrZUj6VVy9ixY+OAAw6I/Pz82G233WLYsGElatjUz54999wzDjnkkLjzzjvLfRwon/L0VBqfqxHpXZNKc45uyPr+XpXJZGLEiBGp11JZjsvAgQPjpptuikWLFpXpeAFQdQjdqRB16tSJJk2aRI0aNSIiYtWqVdGjR48oLi6OcePGxR//+McYNmxYXHvttWXe9l577RVz5szJvt56662c5ePHj4/u3btHt27d4r333ov3338/LrnkkqhW7d/t8M9//jNWr14dDz74YEydOjXuuuuueOCBB+Kaa64p8V6vvPJKznt16NAhu2zcuHFx2mmnRZ8+fWLixIlxwgknxAknnBBTpkzJjjn22GPj+++/jxdffLHM+8nW4ae9sMbQoUNzzq0TTjghZ/mpp54aY8aMiUceeSRmzJgRf/7zn6Nt27bZ5WPHjo3TTjstXnvttRg/fny0aNEiunXrFl999VXOdrp3757zPn/+859zlvfu3TumTp0ao0ePjueeey7eeOONuOCCC8q0j6Wp5dNPP43DDz889thjjxg7dmx8+OGH8dvf/jZq1aqVHbN06dLo3r37OnuxtPUuXrw4unXrFq1atYoJEybEbbfdFtddd1089NBD2TF6t+r6aT9NmDAhGjVqFH/6059i6tSp8Zvf/CYGDBgQv//973PW21g/LV26NHbZZZcYPHhwNGnSZJ3v/eSTT8bll18egwYNig8++CD222+/KCoqyobPERH9+/ePv/3tbzFixIh4/fXX4+uvv46TTjopuzzNa2FExPvvvx8PPvhg7LvvviWWlaafiouL4+c//3lcdNFF61zeq1evnM+POXPmRFFRUXTu3DkaNWqUM3bGjBk549ZeXppj17t373jrrbdi6tSpZT0MpGh916yIiD59+qzzXFu+fHnsuOOOMXDgwNhvv/3Wud3S9Nj777+fcw6NHj06IiJ+/vOf54xbE2Kuea39D6tbssfSqGXmzJnRo0ePOOqoo2LSpEnRr1+/OO+88+Kll17Kjknjsyci4pxzzon7779/k/4BgrIrT0+tsamfq2lck0pzjm5MixYtSlxLrr/++igoKIhjjz021Voq03HZe++9Y9ddd40//elPpT5WAFQxCWxhnTt3Ti677LKceS+88EJSrVq1ZO7cudl5999/f1JYWJgsX7681NseNGhQst9++21wTMeOHZOBAweWpeRkyJAhSevWrbPTM2fOTCIimThx4nrXOfXUU5MePXqUeO9f/epXOfPOOeec5IwzzihTPWwd1tULSZIkEZH89a9/Xe96L774YlKvXr3k22+/LfV7rVy5Mtluu+2SP/7xj9l5Z511VtKzZ8/1rjNt2rQkIpL3338/570zmUzy1Vdflfq9S1NLr169St0Hr732WhIRyXfffVfmeu+7775k++23z/lcufrqq5O2bdtmp/Vu1bS+fvqpiy++ODnqqKOy02Xtp1atWiV33XVXifkHH3xw0rdv3+z0qlWrkmbNmiW33HJLkiRJsnDhwqRmzZrJiBEjsmOmT5+eREQyfvz4JEnSuxYmSZJ8//33SZs2bZLRo0dv8Nisr5/WNnTo0KRevXobfc/58+cnNWvWTB577LEybX9jx26No446qszXb9KzofPovvvuSzp37pyMGTNmg/+/S9On6+uxn7rsssuSXXfdNVm9enWpt78leyyNWq666qpkr732ylmvV69eSVFRUXY6jc+eJEmS5cuXJ/n5+ckrr7xS+oPAJilvT6XxuZrWNak052h5tG/fPjn33HOz05WpX9I8Ltdff31y+OGHl+HIAFCVuNOdSmH8+PGxzz77ROPGjbPzioqKYvHixWW+q+3jjz+OZs2axS677BK9e/fOeTzF/Pnz4913341GjRrFoYceGo0bN47OnTuXuBv+pxYtWhQNGjQoMf/444+PRo0axeGHHx7PPvtsiX3q2rVrzryioqIYP358zryDDz443nzzzTLtI1u/vn37RsOGDePggw+ORx99NJIkyS579tln48ADD4whQ4bETjvtFLvvvntcccUV2UckrcvSpUtjxYoVJc7jsWPHRqNGjaJt27Zx0UUXxbfffptdNn78+Khfv34ceOCB2Xldu3aNatWqxbvvvlvufftpLatXr47nn38+dt999ygqKopGjRpFx44d45lnninTdktT7/jx4+PII4+MvLy87JiioqKYMWNGfPfdd9kxenfr9dPP8/L0008VFxfHhAkTcs6batWqRdeuXbPnzYQJE2LFihU5Y/bYY49o2bJldkya18K+fftGjx49SpzLm9Njjz0WderUiVNOOaXEsvbt20fTpk3jZz/7Wbz99tvZ+aU5dmvoucpp2rRpccMNN8Rjjz2W/a3Bza24uDj+9Kc/xbnnnhuZTCZn2eOPPx4NGzaMvffeOwYMGBBLly7NLtvSPbaptWzsepTWZ0/Evx/j1L59ez1WCZS2pzblczWta1Jpf2YqiwkTJsSkSZOiT58+2XmVqV/SPC4HH3xwvPfee7F8+fIyHiUAqoKSv8cGFWDu3Lk5P7hERHb6p88n3JCOHTvGsGHDom3bttlfTTziiCNiypQpsd1228Vnn30WEf9+9vvtt98e7du3j8ceeyyOOeaYmDJlSrRp06bENj/55JO455574vbbb8/OKygoiDvuuCMOO+ywqFatWvzlL3+JE044IZ555pk4/vjjN7hPP92fZs2axezZs2P16tVb7C+rVG433HBDHH300VGnTp14+eWX4+KLL44ffvghLr300oiI+Oyzz+Ktt96KWrVqxV//+tf45ptv4uKLL45vv/02hg4dus5tXn311dGsWbOcvwB07949TjrppGjdunV8+umncc0118Sxxx4b48ePj+rVq8fcuXNLPCKiRo0a0aBBgzL15cZqmT9/fvzwww8xePDg+K//+q+49dZbY9SoUXHSSSfFa6+9Fp07dy7VdktT79y5c6N169Y5Y9b+rNl+++317lZs3Lhx8eSTT8bzzz+fnVeefvqpb775JlatWrXO8+af//xnRPz7/MrLyyvxbPS1z620roXDhw+PDz74IN5///1Sr5OGRx55JE4//fSoXbt2dl7Tpk3jgQceiAMPPDCWL18eDz/8cHTp0iXefffdOOCAA0p17NZo1qxZfPHFF1tkXyid5cuXx2mnnRa33XZbtGzZMvtz1ub2zDPPxMKFC+Pss8/OmX/66adHq1atolmzZvHhhx/G1VdfHTNmzIinn346IrZsj6VRy/rGLF68OJYtWxbfffddKp89a+ixileankrjczWta9LGztG1rwel9cgjj0S7du3i0EMPzc6rTP2S5nFp1qxZFBcXx9y5c6NVq1alODoAVCVCd7Yqa577FxGx7777RseOHaNVq1bx1FNPRZ8+fbJfevirX/0qzjnnnIiI2H///WPMmDHx6KOPxi233JKzva+++iq6d+8eP//5z+P888/Pzm/YsGFcfvnl2emDDjoovv7667jtttuyoXtp1a5dO1avXh3Lly8v1w+mbH1++9vfZv+8//77x5IlS+K2227Lhu6rV6+OTCYTjz/+eNSrVy8iIu6888445ZRT4r777itxHg0ePDiGDx8eY8eOzXlG+i9+8Yvsn/fZZ5/Yd999Y9ddd42xY8fGMcccs1n2bV21rOnLnj17Rv/+/SPi33dvjRs3Lh544IFSh+5bmt6tWqZMmRI9e/aMQYMGRbdu3bLzy9pPld3s2bPjsssui9GjR+f0++Y2fvz4mD59evzP//xPzvy2bdvmPB//0EMPjU8//TTuuuuuEmM3pnbt2jl3ClPxBgwYEO3atYszzjhji77vI488Escee2w0a9YsZ/7a3+Gxzz77RNOmTeOYY46JTz/9NHbddddU3ru0PbYlakmbHqt4pempND9XK5tly5bFE088kfOz8NZszc8Y+g5g6+TWPCqFJk2alPhW+DXT6/tCrdKoX79+7L777vHJJ59ExL/vDImI2HPPPXPGtWvXLucxNBERX3/9dRx11FFx6KGH5nzJ4vp07Ngx+z5r6l7XPv10fxYsWBB169atcsEOW07Hjh3jyy+/zP7qadOmTWOnnXbKBoQR/z6HkySJL7/8Mmfd22+/PQYPHhwvv/zyBr+MKyJil112iYYNG2bP4yZNmuR8sVRExMqVK2PBggXl6sv11dKwYcOoUaNGqfpyQ0pTb2k+a/Tu1mfatGlxzDHHxAUXXBADBw7MWVaWflqfhg0bRvXq1Td43jRp0iSKi4tj4cKFGxyzqdfCCRMmxPz58+OAAw6IGjVqRI0aNeL111+P3/3ud1GjRo1YtWpVqbZTVg8//HC0b98+5wvF1+fggw/Ofs6U5titsWDBgthxxx3TK5pN9uqrr8aIESOy59qaf7Bt2LBhDBo0aLO85xdffBGvvPJKnHfeeRsd27Fjx4iInOtaRfVYeWpZ35jCwsKoXbt2ap89a+ixilfenirr52pa16SNnaNl9b//+7+xdOnSOPPMM3PmV6Z+SfO4LFiwICJC3wFspYTuVAqdOnWKyZMn5wRmo0ePjsLCwhJBXFn88MMP8emnn2bD9p133jmaNWsWM2bMyBn30Ucf5fxK31dffRVdunSJDh06xNChQ0v16IhJkyZl32fNPo0ZMyZnzOjRo6NTp04586ZMmRL7779/mfeNbcekSZNi++23j/z8/IiIOOyww+Lrr7+OH374ITvmo48+imrVqkXz5s2z84YMGRI33nhjjBo1Kuc55+vz5Zdfxrfffps9jzt16hQLFy6MCRMmZMe8+uqrsXr16mx4UFobqiUvLy8OOuigjfblxpSm3k6dOsUbb7wRK1asyI4ZPXp0tG3bNrbffvvsGL279Zg6dWocddRRcdZZZ8VNN91UYnlp+2lD8vLyokOHDjnnzerVq2PMmDHZ86ZDhw5Rs2bNnDEzZsyIWbNmZcekcS085phjYvLkyTFp0qTs68ADD4zevXvHpEmTonr16qXaTln88MMP2d8oK421r5elOXZr6LnK5y9/+Uv84x//yJ5rDz/8cEREvPnmm9G3b9/N8p5Dhw6NRo0aRY8ePTY6dtKkSREROde1iuqx8tSysetRWp89a+ixilfenirr52pa16TS/sxUWo888kgcf/zxJULoytQvaR6XKVOmRPPmzaNhw4ZlOEoAVBkV/EWubIM6d+6cXHbZZTnzVq5cmey9995Jt27dkkmTJiWjRo1Kdtxxx2TAgAFl2vavf/3rZOzYscnMmTOTt99+O+natWvSsGHDZP78+dkxd911V1JYWJiMGDEi+fjjj5OBAwcmtWrVSj755JMkSZLkyy+/THbbbbfkmGOOSb788stkzpw52dcaw4YNS5544olk+vTpyfTp05ObbropqVatWvLoo49mx7z99ttJjRo1kttvvz2ZPn16MmjQoKRmzZrJ5MmTSxyPG264oUz7ydZhXb3w7LPPJn/4wx+SyZMnJx9//HFy3333JXXq1Emuvfba7Jjvv/8+ad68eXLKKackU6dOTV5//fWkTZs2yXnnnZcdM3jw4CQvLy/53//935xz+Pvvv89u44orrkjGjx+fzJw5M3nllVeSAw44IGnTpk3y448/ZrfTvXv3ZP/990/efffd5K233kratGmTnHbaaWXaz43VkiRJ8vTTTyc1a9ZMHnrooeTjjz9O7rnnnqR69erJm2++mR0zZ86cZOLEickf/vCHJCKSN954I5k4cWLy7bfflrrehQsXJo0bN05++ctfJlOmTEmGDx+e1KlTJ3nwwQezY/Ru1bSufpo8eXKy4447JmeccUbOubf2NaE0/bR8+fJk4sSJycSJE5OmTZsmV1xxRTJx4sTk448/zo4ZPnx4kp+fnwwbNiyZNm1acsEFFyT169dP5s6dmx1z4YUXJi1btkxeffXV5O9//3vSqVOnpFOnTtnlaV0LS3NsStNPX3zxRTJx4sTk+uuvTwoKCrLHYO3eTZIkefjhh5NatWol3333XYn3vuuuu5Jnnnkm+fjjj5PJkycnl112WVKtWrXklVdeKdOxS5IkadWqVfLYY49t0rGg/NZ1Hv3Ua6+9lkREiXNhzbnToUOH5PTTT08mTpyYTJ06Nbu8ND2WJEmyatWqpGXLlsnVV19d4r0/+eST5IYbbkj+/ve/JzNnzkxGjhyZ7LLLLsmRRx6ZHbOleiytWj777LOkTp06yZVXXplMnz49uffee5Pq1asno0aNyo5J47MnSZJk5syZSSaTST7//PNNOhaUXnl7Kq3P1TSuSaU5R0vr448/TjKZTPLiiy+WWFaZ+iXN43LWWWcl5557bpmPFQBVg9CdLW59P2B+/vnnybHHHpvUrl07adiwYfLrX/86WbFiRXb5zJkzk4hIXnvttfVuu1evXknTpk2TvLy8ZKeddkp69eqVDdPXdssttyTNmzdP6tSpk3Tq1Ckn2Bs6dGgSEet8rTFs2LCkXbt2SZ06dZLCwsLk4IMPTkaMGFHifZ566qlk9913T/Ly8pK99toref7553OWf/nll0nNmjWT2bNnb+iQsZVaVy+8+OKLSfv27ZOCgoKkbt26yX777Zc88MADyapVq3LGTZ8+PenatWtSu3btpHnz5snll1+eLF26NLu8VatW6zyHBw0alCRJkixdujTp1q1bsuOOOyY1a9ZMWrVqlZx//vklQq5vv/02Oe2005KCgoKksLAwOeecc0oEbhGRDB06dL37ubFa1njkkUeS3XbbLalVq1ay3377Jc8880zO8kGDBq1zO2u/d2nq/cc//pEcfvjhSX5+frLTTjslgwcPLlGz3q161tVP6ztnWrVqlTNuY/205vrz01fnzp1ztnPPPfckLVu2TPLy8pKDDz44eeedd3KWL1u2LLn44ouT7bffPqlTp05y4okn5vyDbpKkcy3clGOzdj+dddZZ6xzz0/fu1KlTcvrpp6/zvW+99dZk1113TWrVqpU0aNAg6dKlS/Lqq6+WGLexYzdu3Likfv36Of9f2LI2JXTfWB+WtsdeeumlJCKSGTNmlHjvWbNmJUceeWTSoEGDJD8/P9ltt92SK6+8Mlm0aFHOuC3RY2nVkiT/Pqbt27dP8vLykl122WWd19s0PntuvvnmpKioqNT7zKYrb0+l9bmaxjVpTY0bOkfX/N1qYwYMGJC0aNGixM+8adZSmY7LsmXLknr16iXjx4/f6LEBoGrKJEmSpHDDPJRaly5don379nH33XeXab3XXnstTjrppPjss8+yj4Go6q6++ur47rvvSvXMeLY+5e2FymTmzJmx++67x7Rp06JNmzYVXc4Wo3crn62hn0pja7wWlkavXr1iv/32i2uuuaaiS9lm6bGtV3FxcbRp0yaeeOKJOOywwyq6nG3GttJTgwYNitdffz3Gjh1b0aVUKvfff3/89a9/jZdffrmiSwFgM/FMdyrEfffdFwUFBTF58uRSr/PCCy/ENddcs1X9BahRo0Zx4403VnQZVKDy9EJl8sILL8QFF1ywTQXuEXq3sqrq/VQaW+O1cGOKi4tjn332if79+1d0Kds8PbZ1mjVrVlxzzTUC9wqwLfTUiy++GEOGDKnoMiqdmjVrxj333FPRZQCwGbnTnS3uq6++imXLlkVERMuWLSMvL6+CK4KKoRcgPfoJNi89BunSUwCwdRO6AwAAAABASjxeBgAAAAAAUiJ0BwAAAACAlAjdAQAAAAAgJUJ3AAAAAABIidAdAAAAAABSInQHAAAAAICUCN0BgK3a2WefHSeccEL2z5lMJgYPHpwz5plnnolMJpMzL0mSeOihh6Jjx45RUFAQ9evXjwMPPDDuvvvuWLp0aXbcggULol+/ftGqVavIy8uLZs2axbnnnhuzZs0qUUcmk4kLL7ywRI19+/aNTCYTZ599donxP31179691Ps+ceLE6NWrVzRt2jTy8/OjVatWcdxxx8Xf/va3SJIkIiI+//zznO03aNAgOnfuHG+++WaJ7ZV2X7t06RL9+vUrsf6wYcOifv362enrrrsu+741atSInXfeOfr37x8//PBDqfcRAACgshG6AwDblFq1asWtt94a33333QbH/fKXv4x+/fpFz54947XXXotJkybFb3/72xg5cmS8/PLLEfHvEPqQQw6JV155JR544IH45JNPYvjw4fHJJ5/EQQcdFJ999lnONlu0aBHDhw+PZcuWZef9+OOP8cQTT0TLli1L1NC9e/eYM2dOzuvPf/5zqfZz5MiRccghh8QPP/wQf/zjH2P69OkxatSoOPHEE2PgwIGxaNGinPGvvPJKzJkzJ954441o1qxZHHfccTFv3rzs8rLua2nttddeMWfOnPj888/j1ltvjYceeih+/etfl2tbAAAAlUGNii4AAGBL6tq1a3zyySdxyy23xJAhQ9Y55qmnnorHH388nnnmmejZs2d2/s477xzHH398LF68OCIifvOb38TXX38dn3zySTRp0iQiIlq2bBkvvfRStGnTJvr27Rsvvvhidv0DDjggPv3003j66aejd+/eERHx9NNPR8uWLaN169Yl6sjPz89utyyWLFkSffr0iR49esTTTz+ds6xdu3bRp0+f7J3ua+ywww7RpEmTaNKkSVxzzTUxfPjwePfdd+P4448v176WVo0aNbLb69WrV4wZMyaeffbZePDBB8u8LQAAgMrAne4AwDalevXqcfPNN8c999wTX3755TrHPP7449G2bducwH2NTCYT9erVi9WrV8fw4cOjd+/eJYLx2rVrx8UXXxwvvfRSLFiwIGfZueeeG0OHDs1OP/roo3HOOeeksGf/v5dffjm+/fbbuOqqq9Y75qeP01lj2bJl8dhjj0VERF5eXkREufe1PGrXrh3FxcWbvB0AAICKInQHALY5J554YrRv3z4GDRq0zuUff/xxtG3bdoPb+Ne//hULFy6Mdu3arXN5u3btIkmS+OSTT3Lmn3HGGfHWW2/FF198EV988UW8/fbbccYZZ6xzG88991wUFBTkvG6++eaN7t9HH30UEZGzD++//37Odp577rmcdQ499NAoKCiIunXrxu233x4dOnSIY445ZpP2tawmTJgQTzzxRBx99NGbtB0AAICK5PEyAMA26dZbb42jjz46rrjiihLLfvrolQ0py9iIiB133DF69OgRw4YNiyRJokePHtGwYcN1jj3qqKPi/vvvz5nXoEGDMr3fGvvuu29MmjQpIiLatGkTK1euzFn+5JNPxh577BFTpkyJq666KoYNGxY1a9bMGVPWfS2NyZMnR0FBQaxatSqKi4ujR48e8fvf/z719wEAANhShO4AwDbpyCOPjKKiohgwYECcffbZOct23333+Oc//7nB9XfccceoX79+TJ8+fZ3Lp0+fHplMJnbbbbcSy84999y45JJLIiLi3nvvXe971K1bd53rb0ybNm0iImLGjBlxyCGHRMS/nw+/oW21aNEi2rRpkw3kTzzxxJgyZUrk5+eXeV8LCwtLfFFrRMTChQujXr16OfPatm0bzz77bNSoUSOaNWuWfaQNAABAVeXxMgDANmvw4MHxt7/9LcaPH58z//TTT4+PPvooRo4cWWKdJEli0aJFUa1atTj11FPjiSeeiLlz5+aMWbZsWdx3331RVFS0zjvTu3fvHsXFxbFixYooKipKd6ciolu3btGgQYO49dZby7X+KaecEjVq1Ij77rsvIqLM+9q2bdv44IMPSmz3gw8+iN133z1nXl5eXuy2226x8847C9wBAICtgtAdANhm7bPPPtG7d+/43e9+lzP/1FNPjV69esVpp50WN998c/z973+PL774Ip577rno2rVrvPbaaxERcfPNN0eTJk3iZz/7Wbz44osxe/bseOONN6KoqChWrFix3rvYq1evHtOnT49p06ZF9erV11vf8uXLY+7cuTmvb775ZqP7VVBQEA8//HA8//zz0aNHj3jppZfis88+iw8//DCGDBmSrWF9MplMXHrppTF48OBYunRpmff1oosuio8++iguvfTS+PDDD2PGjBlx5513xp///Of49a9/vdH6AQAAqjKhOwCwTbvhhhti9erVOfMymUw88cQTceedd8YzzzwTnTt3jn333Teuu+666NmzZ/bu9B122CHeeeedOOqoo+JXv/pV7LrrrnHqqafGrrvuGu+//37ssssu633fwsLCKCws3GBto0aNiqZNm+a8Dj/88FLt14knnhjjxo2LOnXqxJlnnhlt27aNo48+Ol599dUYPnx4HHfccRtc/6yzzooVK1Zkn69eln3dZZdd4o033oh//vOf0bVr1+jYsWM89dRTMWLEiOjevXup6gcAAKiqMsnm+EYsAAAAAADYBrnTHQAAAAAAUiJ0BwCoYh5//PEoKChY52uvvfaq6PIAAAC2aR4vAwBQxXz//fcxb968dS6rWbNmtGrVagtXBAAAwBpCdwAAAAAASInHywAAAAAAQEqE7gAAAAAAkBKhOwAAAAAApEToDgAAAAAAKRG6AwAAAABASoTuAAAAAACQEqE7AAAAAACk5P8D7XpXvnRAmqAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gzlemler:\n"
      ],
      "metadata": {
        "id": "Rus14D6szgx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='INCOME_GROUP', y='Total_Score', hue='NAME_INCOME_TYPE', palette='viridis')\n",
        "plt.title('Total_Score by INCOME_GROUP and NAME_INCOME_TYPE')\n",
        "plt.xlabel('INCOME_GROUP')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='NAME_INCOME_TYPE', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "oPlfTTfo4j76",
        "outputId": "e44c1fc7-46ba-4f54-9baa-69774bf458dd"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gzlemler:\n"
      ],
      "metadata": {
        "id": "LIdBARh8zvzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='NAME_HOUSING_TYPE', y='Total_Score', hue='INCOME_GROUP', palette='viridis')\n",
        "plt.title('Total_Score by NAME_HOUSING_TYPE and INCOME_GROUP')\n",
        "plt.xlabel('NAME_HOUSING_TYPE')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='INCOME_GROUP', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k2yKcGbM5aD5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "e2c6ebaf-9223-4219-e00d-ec8644b43721"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gzlemler:\n"
      ],
      "metadata": {
        "id": "WUL_SrIDz6Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='AGE_GROUP', y='Total_Score', hue='TARGET_LABEL', palette='viridis')\n",
        "plt.title('Total_Score by AGE_GROUP and TARGET_LABEL')\n",
        "plt.xlabel('AGE_GROUP')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='TARGET_LABEL', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "KRUt_n_H_EPH",
        "outputId": "575d80bb-ea30-4a52-90d1-c13b907a521d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='NAME_INCOME_TYPE', y='Total_Score', hue='TARGET_LABEL', palette='viridis')\n",
        "plt.title('Total_Score by NAME_INCOME_TYPE and TARGET_LABEL')\n",
        "plt.xlabel('NAME_INCOME_TYPE')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='TARGET_LABEL', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "xzEhJviE-isB",
        "outputId": "434e8b31-8349-49c7-9ed3-b64645da48fd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='INCOME_GROUP', y='Total_Score', hue='TARGET_LABEL', palette='viridis')\n",
        "plt.title('Total_Score by INCOME_GROUP and TARGET_LABEL')\n",
        "plt.xlabel('INCOME_GROUP')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='TARGET_LABEL', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "id": "0YJz3Chj-ZpC",
        "outputId": "fa7071ff-fec9-4704-a50a-5f9fc3296ff3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=merged_df, x='NAME_HOUSING_TYPE', y='Total_Score', hue='TARGET_LABEL', palette='viridis')\n",
        "plt.title('Total_Score by NAME_HOUSING_TYPE and TARGET_LABEL')\n",
        "plt.xlabel('NAME_HOUSING_TYPE')\n",
        "plt.ylabel('Total_Score')\n",
        "plt.legend(title='TARGET_LABEL', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "KL75wBhA-Jwx",
        "outputId": "0730a62f-5166-422f-d886-585e121c9196"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"8\"></a>\n",
        "## 8. Data Preprocessing and Splitting"
      ],
      "metadata": {
        "id": "5xdK6hyhajru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "3DWmI_7SdegL",
        "outputId": "44513910-7a47-4b66-ceaf-ac28f1d421f8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  AMT_INCOME_TOTAL  \\\n",
              "0       5008804           M            Y               Y          427500.0   \n",
              "1       5008805           M            Y               Y          427500.0   \n",
              "2       5008806           M            Y               Y          112500.0   \n",
              "3       5008808           F            N               Y          270000.0   \n",
              "4       5008809           F            N               Y          270000.0   \n",
              "...         ...         ...          ...             ...               ...   \n",
              "438505  6840104           M            N               Y          135000.0   \n",
              "438506  6840222           F            N               N          103500.0   \n",
              "438507  6841878           F            N               N           54000.0   \n",
              "438508  6842765           F            N               Y           72000.0   \n",
              "438509  6842885           F            N               Y          121500.0   \n",
              "\n",
              "            NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
              "0                    Working               Higher education   \n",
              "1                    Working               Higher education   \n",
              "2                    Working  Secondary / secondary special   \n",
              "3       Commercial associate  Secondary / secondary special   \n",
              "4       Commercial associate  Secondary / secondary special   \n",
              "...                      ...                            ...   \n",
              "438505             Pensioner  Secondary / secondary special   \n",
              "438506               Working  Secondary / secondary special   \n",
              "438507  Commercial associate               Higher education   \n",
              "438508             Pensioner  Secondary / secondary special   \n",
              "438509               Working  Secondary / secondary special   \n",
              "\n",
              "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  FLAG_WORK_PHONE  ...  AGE  \\\n",
              "0             Civil marriage   Rented apartment                1  ...   32   \n",
              "1             Civil marriage   Rented apartment                1  ...   32   \n",
              "2                    Married  House / apartment                0  ...   58   \n",
              "3       Single / not married  House / apartment                0  ...   52   \n",
              "4       Single / not married  House / apartment                0  ...   52   \n",
              "...                      ...                ...              ...  ...  ...   \n",
              "438505             Separated  House / apartment                0  ...   62   \n",
              "438506  Single / not married  House / apartment                0  ...   43   \n",
              "438507  Single / not married       With parents                1  ...   22   \n",
              "438508               Married  House / apartment                0  ...   59   \n",
              "438509               Married  House / apartment                0  ...   51   \n",
              "\n",
              "        AGE_GROUP      INCOME_GROUP  MONTHS_EMPLOYED  Evaluation_Score  \\\n",
              "0        [30, 40)  [411750, 450000)              149             20300   \n",
              "1        [30, 40)  [411750, 450000)              149             20300   \n",
              "2        [50, 60)   [56250, 261000)               37             20300   \n",
              "3        [50, 60)  [261000, 411750)              100             19800   \n",
              "4        [50, 60)  [261000, 411750)              100             19800   \n",
              "...           ...               ...              ...               ...   \n",
              "438505   [60, 70)   [56250, 261000)              137             10300   \n",
              "438506   [40, 50)   [56250, 261000)               98              4800   \n",
              "438507    [0, 30)        [0, 56250)               12              9800   \n",
              "438508   [50, 60)   [56250, 261000)              122             10800   \n",
              "438509   [50, 60)   [56250, 261000)               39             15300   \n",
              "\n",
              "        Total_Score Total_Score_SCALED Total_Score_CATEGORY    Income_Bin  \\\n",
              "0           14910.0               1226               Normal           NaN   \n",
              "1           14210.0               1211               Normal           NaN   \n",
              "2           10500.0               1134               Normal           NaN   \n",
              "3            5800.0               1037          Medium risk        Middle   \n",
              "4            5940.0               1040          Medium risk        Middle   \n",
              "...             ...                ...                  ...           ...   \n",
              "438505       3090.0                981          Medium risk  Lower Middle   \n",
              "438506       1440.0                947          Medium risk  Lower Middle   \n",
              "438507       2940.0                978          Medium risk           Low   \n",
              "438508       3240.0                984          Medium risk  Lower Middle   \n",
              "438509       4590.0               1012          Medium risk  Lower Middle   \n",
              "\n",
              "        TARGET_LABEL  \n",
              "0                0.0  \n",
              "1                0.0  \n",
              "2                0.0  \n",
              "3                1.0  \n",
              "4                0.0  \n",
              "...              ...  \n",
              "438505           0.0  \n",
              "438506           1.0  \n",
              "438507           0.0  \n",
              "438508           0.0  \n",
              "438509           1.0  \n",
              "\n",
              "[438510 rows x 25 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25d6757c-cca6-4f98-b0ba-f562002d0df9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>NAME_INCOME_TYPE</th>\n",
              "      <th>NAME_EDUCATION_TYPE</th>\n",
              "      <th>NAME_FAMILY_STATUS</th>\n",
              "      <th>NAME_HOUSING_TYPE</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>...</th>\n",
              "      <th>AGE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>INCOME_GROUP</th>\n",
              "      <th>MONTHS_EMPLOYED</th>\n",
              "      <th>Evaluation_Score</th>\n",
              "      <th>Total_Score</th>\n",
              "      <th>Total_Score_SCALED</th>\n",
              "      <th>Total_Score_CATEGORY</th>\n",
              "      <th>Income_Bin</th>\n",
              "      <th>TARGET_LABEL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5008804</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>[30, 40)</td>\n",
              "      <td>[411750, 450000)</td>\n",
              "      <td>149</td>\n",
              "      <td>20300</td>\n",
              "      <td>14910.0</td>\n",
              "      <td>1226</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008805</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>427500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Civil marriage</td>\n",
              "      <td>Rented apartment</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>[30, 40)</td>\n",
              "      <td>[411750, 450000)</td>\n",
              "      <td>149</td>\n",
              "      <td>20300</td>\n",
              "      <td>14210.0</td>\n",
              "      <td>1211</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5008806</td>\n",
              "      <td>M</td>\n",
              "      <td>Y</td>\n",
              "      <td>Y</td>\n",
              "      <td>112500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>58</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>37</td>\n",
              "      <td>20300</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>1134</td>\n",
              "      <td>Normal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5008808</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[261000, 411750)</td>\n",
              "      <td>100</td>\n",
              "      <td>19800</td>\n",
              "      <td>5800.0</td>\n",
              "      <td>1037</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Middle</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5008809</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>270000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>52</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[261000, 411750)</td>\n",
              "      <td>100</td>\n",
              "      <td>19800</td>\n",
              "      <td>5940.0</td>\n",
              "      <td>1040</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Middle</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438505</th>\n",
              "      <td>6840104</td>\n",
              "      <td>M</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>135000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Separated</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>62</td>\n",
              "      <td>[60, 70)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>137</td>\n",
              "      <td>10300</td>\n",
              "      <td>3090.0</td>\n",
              "      <td>981</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438506</th>\n",
              "      <td>6840222</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>103500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>43</td>\n",
              "      <td>[40, 50)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>98</td>\n",
              "      <td>4800</td>\n",
              "      <td>1440.0</td>\n",
              "      <td>947</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438507</th>\n",
              "      <td>6841878</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>54000.0</td>\n",
              "      <td>Commercial associate</td>\n",
              "      <td>Higher education</td>\n",
              "      <td>Single / not married</td>\n",
              "      <td>With parents</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>22</td>\n",
              "      <td>[0, 30)</td>\n",
              "      <td>[0, 56250)</td>\n",
              "      <td>12</td>\n",
              "      <td>9800</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>978</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Low</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438508</th>\n",
              "      <td>6842765</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>72000.0</td>\n",
              "      <td>Pensioner</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>59</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>122</td>\n",
              "      <td>10800</td>\n",
              "      <td>3240.0</td>\n",
              "      <td>984</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438509</th>\n",
              "      <td>6842885</td>\n",
              "      <td>F</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>121500.0</td>\n",
              "      <td>Working</td>\n",
              "      <td>Secondary / secondary special</td>\n",
              "      <td>Married</td>\n",
              "      <td>House / apartment</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>51</td>\n",
              "      <td>[50, 60)</td>\n",
              "      <td>[56250, 261000)</td>\n",
              "      <td>39</td>\n",
              "      <td>15300</td>\n",
              "      <td>4590.0</td>\n",
              "      <td>1012</td>\n",
              "      <td>Medium risk</td>\n",
              "      <td>Lower Middle</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438510 rows  25 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25d6757c-cca6-4f98-b0ba-f562002d0df9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25d6757c-cca6-4f98-b0ba-f562002d0df9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25d6757c-cca6-4f98-b0ba-f562002d0df9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6de1d264-ab4f-4c37-bb86-4804dc6deb04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6de1d264-ab4f-4c37-bb86-4804dc6deb04')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6de1d264-ab4f-4c37-bb86-4804dc6deb04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_82983a64-c55f-4d82-b790-19b56410c6ad\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('merged_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_82983a64-c55f-4d82-b790-19b56410c6ad button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('merged_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "merged_df"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.drop('ID', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "d2LTIrLWdSwz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop specified columns and set target variable\n",
        "y = merged_df['TARGET_LABEL']\n",
        "\n",
        "columns_to_drop = ['AGE_GROUP', 'INCOME_GROUP', 'Evaluation_Score', 'Total_Score',\n",
        "                   'Total_Score_SCALED', 'Total_Score_CATEGORY', 'Income_Bin', 'TARGET_LABEL']\n",
        "X = merged_df.drop(columns=columns_to_drop)"
      ],
      "metadata": {
        "id": "QfriXlwtl2pn"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identify column types"
      ],
      "metadata": {
        "id": "TGY3RxU0sD5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = X.select_dtypes(include=['object']).columns\n",
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns"
      ],
      "metadata": {
        "id": "qhmJt45jruge"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create preprocessing pipelines"
      ],
      "metadata": {
        "id": "rFR4ulY8sBG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_categorical(df, column):\n",
        "    unique_values = df[column].unique()\n",
        "\n",
        "    if len(unique_values) == 2:\n",
        "        # kili deikenler iin tek stun olutur\n",
        "        return pd.DataFrame({column: (df[column] == unique_values[0]).astype(int)})\n",
        "    else:\n",
        "        # ok kategorili deikenler iin one-hot encoding uygula\n",
        "        dummies = pd.get_dummies(df[column], prefix=column, dtype=int)\n",
        "\n",
        "        # Stun adlarn orijinal formata dntr\n",
        "        new_column_names = {col: f\"{column}_{val}\" for col, val in\n",
        "                            zip(dummies.columns, unique_values)}\n",
        "        dummies.rename(columns=new_column_names, inplace=True)\n",
        "\n",
        "        return dummies"
      ],
      "metadata": {
        "id": "TA4hy7k1ErKl"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kategorik deikenleri ile\n",
        "categorical_encoded = pd.concat([process_categorical(X, col) for col in categorical_columns], axis=1)"
      ],
      "metadata": {
        "id": "XUUYKVINEugt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "R0Cd9pIiejk0",
        "outputId": "df08520f-8b17-4192-c518-0e6952d839fa"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  NAME_INCOME_TYPE_Working  \\\n",
              "0                 1             1                1                         0   \n",
              "1                 1             1                1                         0   \n",
              "2                 1             1                1                         0   \n",
              "3                 0             0                1                         1   \n",
              "4                 0             0                1                         1   \n",
              "...             ...           ...              ...                       ...   \n",
              "438505            1             0                1                         0   \n",
              "438506            0             0                0                         0   \n",
              "438507            0             0                0                         1   \n",
              "438508            0             0                1                         0   \n",
              "438509            0             0                1                         0   \n",
              "\n",
              "        NAME_INCOME_TYPE_Commercial associate  NAME_INCOME_TYPE_Pensioner  \\\n",
              "0                                           0                           0   \n",
              "1                                           0                           0   \n",
              "2                                           0                           0   \n",
              "3                                           0                           0   \n",
              "4                                           0                           0   \n",
              "...                                       ...                         ...   \n",
              "438505                                      1                           0   \n",
              "438506                                      0                           0   \n",
              "438507                                      0                           0   \n",
              "438508                                      1                           0   \n",
              "438509                                      0                           0   \n",
              "\n",
              "        NAME_INCOME_TYPE_State servant  NAME_INCOME_TYPE_Student  \\\n",
              "0                                    0                         1   \n",
              "1                                    0                         1   \n",
              "2                                    0                         1   \n",
              "3                                    0                         0   \n",
              "4                                    0                         0   \n",
              "...                                ...                       ...   \n",
              "438505                               0                         0   \n",
              "438506                               0                         1   \n",
              "438507                               0                         0   \n",
              "438508                               0                         0   \n",
              "438509                               0                         1   \n",
              "\n",
              "        NAME_EDUCATION_TYPE_Higher education  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "...                                      ...   \n",
              "438505                                     0   \n",
              "438506                                     0   \n",
              "438507                                     0   \n",
              "438508                                     0   \n",
              "438509                                     0   \n",
              "\n",
              "        NAME_EDUCATION_TYPE_Secondary / secondary special  ...  \\\n",
              "0                                                       1  ...   \n",
              "1                                                       1  ...   \n",
              "2                                                       0  ...   \n",
              "3                                                       0  ...   \n",
              "4                                                       0  ...   \n",
              "...                                                   ...  ...   \n",
              "438505                                                  0  ...   \n",
              "438506                                                  0  ...   \n",
              "438507                                                  1  ...   \n",
              "438508                                                  0  ...   \n",
              "438509                                                  0  ...   \n",
              "\n",
              "        OCCUPATION_TYPE_Cleaning staff  OCCUPATION_TYPE_Private service staff  \\\n",
              "0                                    0                                      0   \n",
              "1                                    0                                      0   \n",
              "2                                    0                                      0   \n",
              "3                                    0                                      0   \n",
              "4                                    0                                      0   \n",
              "...                                ...                                    ...   \n",
              "438505                               0                                      0   \n",
              "438506                               0                                      0   \n",
              "438507                               0                                      0   \n",
              "438508                               0                                      0   \n",
              "438509                               0                                      0   \n",
              "\n",
              "        OCCUPATION_TYPE_Cooking staff  OCCUPATION_TYPE_Low-skill Laborers  \\\n",
              "0                                   0                                   0   \n",
              "1                                   0                                   0   \n",
              "2                                   0                                   0   \n",
              "3                                   0                                   0   \n",
              "4                                   0                                   0   \n",
              "...                               ...                                 ...   \n",
              "438505                              0                                   0   \n",
              "438506                              0                                   0   \n",
              "438507                              0                                   0   \n",
              "438508                              0                                   0   \n",
              "438509                              0                                   0   \n",
              "\n",
              "        OCCUPATION_TYPE_Medicine staff  OCCUPATION_TYPE_Secretaries  \\\n",
              "0                                    0                            0   \n",
              "1                                    0                            0   \n",
              "2                                    0                            0   \n",
              "3                                    0                            1   \n",
              "4                                    0                            1   \n",
              "...                                ...                          ...   \n",
              "438505                               0                            0   \n",
              "438506                               0                            0   \n",
              "438507                               0                            1   \n",
              "438508                               0                            0   \n",
              "438509                               0                            1   \n",
              "\n",
              "        OCCUPATION_TYPE_Waiters/barmen staff  OCCUPATION_TYPE_HR staff  \\\n",
              "0                                          0                         0   \n",
              "1                                          0                         0   \n",
              "2                                          0                         1   \n",
              "3                                          0                         0   \n",
              "4                                          0                         0   \n",
              "...                                      ...                       ...   \n",
              "438505                                     0                         0   \n",
              "438506                                     0                         0   \n",
              "438507                                     0                         0   \n",
              "438508                                     0                         0   \n",
              "438509                                     0                         0   \n",
              "\n",
              "        OCCUPATION_TYPE_Realty agents  OCCUPATION_TYPE_IT staff  \n",
              "0                                   1                         0  \n",
              "1                                   1                         0  \n",
              "2                                   0                         0  \n",
              "3                                   0                         0  \n",
              "4                                   0                         0  \n",
              "...                               ...                       ...  \n",
              "438505                              1                         0  \n",
              "438506                              0                         0  \n",
              "438507                              0                         0  \n",
              "438508                              1                         0  \n",
              "438509                              0                         0  \n",
              "\n",
              "[438510 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6dd9869c-9bc6-4034-8449-861db086aa45\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>NAME_INCOME_TYPE_Working</th>\n",
              "      <th>NAME_INCOME_TYPE_Commercial associate</th>\n",
              "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
              "      <th>NAME_INCOME_TYPE_State servant</th>\n",
              "      <th>NAME_INCOME_TYPE_Student</th>\n",
              "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
              "      <th>NAME_EDUCATION_TYPE_Secondary / secondary special</th>\n",
              "      <th>...</th>\n",
              "      <th>OCCUPATION_TYPE_Cleaning staff</th>\n",
              "      <th>OCCUPATION_TYPE_Private service staff</th>\n",
              "      <th>OCCUPATION_TYPE_Cooking staff</th>\n",
              "      <th>OCCUPATION_TYPE_Low-skill Laborers</th>\n",
              "      <th>OCCUPATION_TYPE_Medicine staff</th>\n",
              "      <th>OCCUPATION_TYPE_Secretaries</th>\n",
              "      <th>OCCUPATION_TYPE_Waiters/barmen staff</th>\n",
              "      <th>OCCUPATION_TYPE_HR staff</th>\n",
              "      <th>OCCUPATION_TYPE_Realty agents</th>\n",
              "      <th>OCCUPATION_TYPE_IT staff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438505</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438506</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438507</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438508</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438509</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438510 rows  43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6dd9869c-9bc6-4034-8449-861db086aa45')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6dd9869c-9bc6-4034-8449-861db086aa45 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6dd9869c-9bc6-4034-8449-861db086aa45');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69286c45-9223-4657-ae41-60a328422de1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69286c45-9223-4657-ae41-60a328422de1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69286c45-9223-4657-ae41-60a328422de1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_27296b7a-05e1-4f37-a6ea-d9ec46b7a87d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('categorical_encoded')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_27296b7a-05e1-4f37-a6ea-d9ec46b7a87d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('categorical_encoded');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "categorical_encoded"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit and transform the data"
      ],
      "metadata": {
        "id": "Q-eTlvJCsNeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saysal deikenleri normalize et\n",
        "scaler = StandardScaler()\n",
        "numeric_normalized = pd.DataFrame(scaler.fit_transform(X[numeric_columns]),\n",
        "                                  columns=numeric_columns,\n",
        "                                  index=X.index)\n",
        "\n",
        "categorical_normalized = pd.DataFrame(scaler.fit_transform(categorical_encoded[categorical_encoded.columns]),\n",
        "                                      columns=categorical_encoded.columns,\n",
        "                                      index=X.index)\n",
        "# lenmi verileri birletir\n",
        "processed_features = pd.concat([categorical_normalized, numeric_normalized], axis=1)"
      ],
      "metadata": {
        "id": "j1tYxDZpr0lG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "63Vi8abXF3Mz",
        "outputId": "d901fe9a-dc1d-4448-b610-7ca173b0aa6b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  NAME_INCOME_TYPE_Working  \\\n",
              "0          1.429384      1.299574         0.665029                 -0.546119   \n",
              "1          1.429384      1.299574         0.665029                 -0.546119   \n",
              "2          1.429384      1.299574         0.665029                 -0.546119   \n",
              "3         -0.699602     -0.769483         0.665029                  1.831101   \n",
              "4         -0.699602     -0.769483         0.665029                  1.831101   \n",
              "...             ...           ...              ...                       ...   \n",
              "438505     1.429384     -0.769483         0.665029                 -0.546119   \n",
              "438506    -0.699602     -0.769483        -1.503695                 -0.546119   \n",
              "438507    -0.699602     -0.769483        -1.503695                  1.831101   \n",
              "438508    -0.699602     -0.769483         0.665029                 -0.546119   \n",
              "438509    -0.699602     -0.769483         0.665029                 -0.546119   \n",
              "\n",
              "        NAME_INCOME_TYPE_Commercial associate  NAME_INCOME_TYPE_Pensioner  \\\n",
              "0                                   -0.455990                   -0.299895   \n",
              "1                                   -0.455990                   -0.299895   \n",
              "2                                   -0.455990                   -0.299895   \n",
              "3                                   -0.455990                   -0.299895   \n",
              "4                                   -0.455990                   -0.299895   \n",
              "...                                       ...                         ...   \n",
              "438505                               2.193032                   -0.299895   \n",
              "438506                              -0.455990                   -0.299895   \n",
              "438507                              -0.455990                   -0.299895   \n",
              "438508                               2.193032                   -0.299895   \n",
              "438509                              -0.455990                   -0.299895   \n",
              "\n",
              "        NAME_INCOME_TYPE_State servant  NAME_INCOME_TYPE_Student  \\\n",
              "0                            -0.006226                  0.969311   \n",
              "1                            -0.006226                  0.969311   \n",
              "2                            -0.006226                  0.969311   \n",
              "3                            -0.006226                 -1.031661   \n",
              "4                            -0.006226                 -1.031661   \n",
              "...                                ...                       ...   \n",
              "438505                       -0.006226                 -1.031661   \n",
              "438506                       -0.006226                  0.969311   \n",
              "438507                       -0.006226                 -1.031661   \n",
              "438508                       -0.006226                 -1.031661   \n",
              "438509                       -0.006226                  0.969311   \n",
              "\n",
              "        NAME_EDUCATION_TYPE_Higher education  \\\n",
              "0                                  -0.026683   \n",
              "1                                  -0.026683   \n",
              "2                                  -0.026683   \n",
              "3                                  -0.026683   \n",
              "4                                  -0.026683   \n",
              "...                                      ...   \n",
              "438505                             -0.026683   \n",
              "438506                             -0.026683   \n",
              "438507                             -0.026683   \n",
              "438508                             -0.026683   \n",
              "438509                             -0.026683   \n",
              "\n",
              "        NAME_EDUCATION_TYPE_Secondary / secondary special  ...  \\\n",
              "0                                                1.652790  ...   \n",
              "1                                                1.652790  ...   \n",
              "2                                               -0.605038  ...   \n",
              "3                                               -0.605038  ...   \n",
              "4                                               -0.605038  ...   \n",
              "...                                                   ...  ...   \n",
              "438505                                          -0.605038  ...   \n",
              "438506                                          -0.605038  ...   \n",
              "438507                                           1.652790  ...   \n",
              "438508                                          -0.605038  ...   \n",
              "438509                                          -0.605038  ...   \n",
              "\n",
              "        OCCUPATION_TYPE_Realty agents  OCCUPATION_TYPE_IT staff  \\\n",
              "0                            1.505956                 -0.061737   \n",
              "1                            1.505956                 -0.061737   \n",
              "2                           -0.664030                 -0.061737   \n",
              "3                           -0.664030                 -0.061737   \n",
              "4                           -0.664030                 -0.061737   \n",
              "...                               ...                       ...   \n",
              "438505                       1.505956                 -0.061737   \n",
              "438506                      -0.664030                 -0.061737   \n",
              "438507                      -0.664030                 -0.061737   \n",
              "438508                       1.505956                 -0.061737   \n",
              "438509                      -0.664030                 -0.061737   \n",
              "\n",
              "        AMT_INCOME_TOTAL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL  \\\n",
              "0               2.180031         1.962448   -0.635631   -0.348326   \n",
              "1               2.180031         1.962448   -0.635631   -0.348326   \n",
              "2              -0.681509        -0.509568   -0.635631   -0.348326   \n",
              "3               0.749261        -0.509568    1.573239    2.870872   \n",
              "4               0.749261        -0.509568    1.573239    2.870872   \n",
              "...                  ...              ...         ...         ...   \n",
              "438505         -0.477113        -0.509568   -0.635631   -0.348326   \n",
              "438506         -0.763267        -0.509568   -0.635631   -0.348326   \n",
              "438507         -1.212937         1.962448   -0.635631   -0.348326   \n",
              "438508         -1.049421        -0.509568   -0.635631   -0.348326   \n",
              "438509         -0.599750        -0.509568    1.573239   -0.348326   \n",
              "\n",
              "        CNT_ADLT_FAM_MEMBERS  CREDIT_SCORE       AGE  MONTHS_EMPLOYED  \n",
              "0                   0.550545      2.705900 -0.985666         0.758871  \n",
              "1                   0.550545      2.479044 -0.985666         0.758871  \n",
              "2                   0.550545      1.276705  1.283177        -0.759059  \n",
              "3                  -1.816382     -0.197862  0.759598         0.094776  \n",
              "4                  -1.816382     -0.152491  0.759598         0.094776  \n",
              "...                      ...           ...       ...              ...  \n",
              "438505             -1.816382     -0.152491  1.632230         0.596235  \n",
              "438506             -1.816382     -0.152491 -0.025771         0.067670  \n",
              "438507             -1.816382     -0.152491 -1.858299        -1.097883  \n",
              "438508              0.550545     -0.152491  1.370440         0.392941  \n",
              "438509              0.550545     -0.152491  0.672335        -0.731954  \n",
              "\n",
              "[438510 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04772ec4-6a6a-43ec-9d14-28d758c979b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CODE_GENDER</th>\n",
              "      <th>FLAG_OWN_CAR</th>\n",
              "      <th>FLAG_OWN_REALTY</th>\n",
              "      <th>NAME_INCOME_TYPE_Working</th>\n",
              "      <th>NAME_INCOME_TYPE_Commercial associate</th>\n",
              "      <th>NAME_INCOME_TYPE_Pensioner</th>\n",
              "      <th>NAME_INCOME_TYPE_State servant</th>\n",
              "      <th>NAME_INCOME_TYPE_Student</th>\n",
              "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
              "      <th>NAME_EDUCATION_TYPE_Secondary / secondary special</th>\n",
              "      <th>...</th>\n",
              "      <th>OCCUPATION_TYPE_Realty agents</th>\n",
              "      <th>OCCUPATION_TYPE_IT staff</th>\n",
              "      <th>AMT_INCOME_TOTAL</th>\n",
              "      <th>FLAG_WORK_PHONE</th>\n",
              "      <th>FLAG_PHONE</th>\n",
              "      <th>FLAG_EMAIL</th>\n",
              "      <th>CNT_ADLT_FAM_MEMBERS</th>\n",
              "      <th>CREDIT_SCORE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>MONTHS_EMPLOYED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.429384</td>\n",
              "      <td>1.299574</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>0.969311</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>1.652790</td>\n",
              "      <td>...</td>\n",
              "      <td>1.505956</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>2.180031</td>\n",
              "      <td>1.962448</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>0.550545</td>\n",
              "      <td>2.705900</td>\n",
              "      <td>-0.985666</td>\n",
              "      <td>0.758871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.429384</td>\n",
              "      <td>1.299574</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>0.969311</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>1.652790</td>\n",
              "      <td>...</td>\n",
              "      <td>1.505956</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>2.180031</td>\n",
              "      <td>1.962448</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>0.550545</td>\n",
              "      <td>2.479044</td>\n",
              "      <td>-0.985666</td>\n",
              "      <td>0.758871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.429384</td>\n",
              "      <td>1.299574</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>0.969311</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-0.681509</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>0.550545</td>\n",
              "      <td>1.276705</td>\n",
              "      <td>1.283177</td>\n",
              "      <td>-0.759059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>1.831101</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-1.031661</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>0.749261</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>1.573239</td>\n",
              "      <td>2.870872</td>\n",
              "      <td>-1.816382</td>\n",
              "      <td>-0.197862</td>\n",
              "      <td>0.759598</td>\n",
              "      <td>0.094776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>1.831101</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-1.031661</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>0.749261</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>1.573239</td>\n",
              "      <td>2.870872</td>\n",
              "      <td>-1.816382</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>0.759598</td>\n",
              "      <td>0.094776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438505</th>\n",
              "      <td>1.429384</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>2.193032</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-1.031661</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>1.505956</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-0.477113</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>-1.816382</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>1.632230</td>\n",
              "      <td>0.596235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438506</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>-1.503695</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>0.969311</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-0.763267</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>-1.816382</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>-0.025771</td>\n",
              "      <td>0.067670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438507</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>-1.503695</td>\n",
              "      <td>1.831101</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-1.031661</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>1.652790</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-1.212937</td>\n",
              "      <td>1.962448</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>-1.816382</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>-1.858299</td>\n",
              "      <td>-1.097883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438508</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>2.193032</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>-1.031661</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>1.505956</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-1.049421</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>-0.635631</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>0.550545</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>1.370440</td>\n",
              "      <td>0.392941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438509</th>\n",
              "      <td>-0.699602</td>\n",
              "      <td>-0.769483</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-0.546119</td>\n",
              "      <td>-0.455990</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.006226</td>\n",
              "      <td>0.969311</td>\n",
              "      <td>-0.026683</td>\n",
              "      <td>-0.605038</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.664030</td>\n",
              "      <td>-0.061737</td>\n",
              "      <td>-0.599750</td>\n",
              "      <td>-0.509568</td>\n",
              "      <td>1.573239</td>\n",
              "      <td>-0.348326</td>\n",
              "      <td>0.550545</td>\n",
              "      <td>-0.152491</td>\n",
              "      <td>0.672335</td>\n",
              "      <td>-0.731954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>438510 rows  51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04772ec4-6a6a-43ec-9d14-28d758c979b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04772ec4-6a6a-43ec-9d14-28d758c979b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04772ec4-6a6a-43ec-9d14-28d758c979b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d48460d-30c6-4226-a81a-43df17ea18a2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d48460d-30c6-4226-a81a-43df17ea18a2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d48460d-30c6-4226-a81a-43df17ea18a2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_01455cff-56bf-4c96-b422-22d1efa24f60\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('processed_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_01455cff-56bf-4c96-b422-22d1efa24f60 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('processed_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "processed_features"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data"
      ],
      "metadata": {
        "id": "CJk7owVJsCnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "dS7tZl6rq6Jn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"9\"></a>\n",
        "## 9. Model Training and Evaluation"
      ],
      "metadata": {
        "id": "iwNEqlYXJJ0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Selection"
      ],
      "metadata": {
        "id": "XhN709xqsUVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import clone\n",
        "from joblib import Parallel, delayed"
      ],
      "metadata": {
        "id": "ht2W-1Pin5Kf"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, name, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"Evaluate a single model\"\"\"\n",
        "    model = clone(model)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "    return name, model, accuracy, report\n",
        "\n",
        "def train_evaluate_model(models, X_train, y_train, X_test, y_test, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Train and evaluate multiple models in parallel.\n",
        "\n",
        "    Parameters:\n",
        "    models (dict): A dictionary of model names and their corresponding instances.\n",
        "    X_train (array-like): Training features.\n",
        "    y_train (array-like): Training labels.\n",
        "    X_test (array-like): Test features.\n",
        "    y_test (array-like): Test labels.\n",
        "    n_jobs (int): Number of jobs to run in parallel. -1 means using all processors.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing evaluation results for each model.\n",
        "    \"\"\"\n",
        "    results = Parallel(n_jobs=n_jobs)(\n",
        "        delayed(evaluate_model)(model, name, X_train, y_train, X_test, y_test)\n",
        "        for name, model in models.items()\n",
        "    )\n",
        "\n",
        "    results_dict = {}\n",
        "    for name, model, accuracy, report in results:\n",
        "        results_dict[name] = {\n",
        "            'model': model,\n",
        "            'accuracy': accuracy,\n",
        "            'classification_report': report\n",
        "        }\n",
        "        print(f\"\\n{name} Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_test, model.predict(X_test)))\n",
        "\n",
        "    return results_dict"
      ],
      "metadata": {
        "id": "L6Zwsca0nLJX"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'Linear SVC': LinearSVC(random_state=42),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'KNeighbors': KNeighborsClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'Light GBM': lgb.LGBMClassifier(random_state=42),\n",
        "    'XGB Classifier': xgb.XGBClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "results = train_evaluate_model(models, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp1rZcxTsaI2",
        "outputId": "c49da2b6-8fca-42ba-e122-c78080f9a276",
        "collapsed": true
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear SVC Results:\n",
            "Accuracy: 0.6442\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.94      0.77     54585\n",
            "         1.0       0.62      0.15      0.24     33117\n",
            "\n",
            "    accuracy                           0.64     87702\n",
            "   macro avg       0.63      0.55      0.50     87702\n",
            "weighted avg       0.64      0.64      0.57     87702\n",
            "\n",
            "\n",
            "Naive Bayes Results:\n",
            "Accuracy: 0.6073\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.81      0.72     54585\n",
            "         1.0       0.47      0.28      0.35     33117\n",
            "\n",
            "    accuracy                           0.61     87702\n",
            "   macro avg       0.56      0.54      0.53     87702\n",
            "weighted avg       0.58      0.61      0.58     87702\n",
            "\n",
            "\n",
            "KNeighbors Results:\n",
            "Accuracy: 0.5925\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.75      0.70     54585\n",
            "         1.0       0.45      0.34      0.38     33117\n",
            "\n",
            "    accuracy                           0.59     87702\n",
            "   macro avg       0.55      0.54      0.54     87702\n",
            "weighted avg       0.57      0.59      0.58     87702\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.6022\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.77      0.71     54585\n",
            "         1.0       0.46      0.33      0.39     33117\n",
            "\n",
            "    accuracy                           0.60     87702\n",
            "   macro avg       0.56      0.55      0.55     87702\n",
            "weighted avg       0.58      0.60      0.59     87702\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.6526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.97      0.78     54585\n",
            "         1.0       0.72      0.13      0.22     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.69      0.55      0.50     87702\n",
            "weighted avg       0.68      0.65      0.57     87702\n",
            "\n",
            "\n",
            "Light GBM Results:\n",
            "Accuracy: 0.6529\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.97      0.78     54585\n",
            "         1.0       0.73      0.13      0.22     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.69      0.55      0.50     87702\n",
            "weighted avg       0.68      0.65      0.57     87702\n",
            "\n",
            "\n",
            "XGB Classifier Results:\n",
            "Accuracy: 0.6509\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.94      0.77     54585\n",
            "         1.0       0.65      0.17      0.27     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.65      0.56      0.52     87702\n",
            "weighted avg       0.65      0.65      0.58     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating Class Weights for an Imbalanced Dataset\n",
        "\n",
        "To improve the performance of our classification models and address the class imbalance in the dataset, we will calculate the weights for each class. This will give more importance to the minority class, allowing the model to learn more balanced."
      ],
      "metadata": {
        "id": "phh4l-5d9OiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "\n",
        "print(\"Class Weights:\", class_weight_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZl95J6KRwBG",
        "outputId": "f7512e18-c5b5-4285-da7f-24a94b4de3a1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0.0: 0.8031281908049872, 1.0: 1.3247335865928538}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update models\n",
        "models = {\n",
        "    'Light GBM': lgb.LGBMClassifier(class_weight=class_weight_dict),\n",
        "    'XGB Classifier': xgb.XGBClassifier(scale_pos_weight=class_weight_dict[1]/class_weight_dict[0]),\n",
        "}\n",
        "\n",
        "results = train_evaluate_model(models, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jul--AERyw1",
        "outputId": "974388ad-9874-4f24-86eb-67a4a62f5448"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Light GBM Results:\n",
            "Accuracy: 0.6515\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.58      0.28      0.38     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.62      0.58      0.57     87702\n",
            "weighted avg       0.63      0.65      0.61     87702\n",
            "\n",
            "\n",
            "XGB Classifier Results:\n",
            "Accuracy: 0.6307\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.81      0.73     54585\n",
            "         1.0       0.52      0.33      0.40     33117\n",
            "\n",
            "    accuracy                           0.63     87702\n",
            "   macro avg       0.59      0.57      0.57     87702\n",
            "weighted avg       0.61      0.63      0.61     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"10\"></a>\n",
        "## 10. Future Extraction and Importance"
      ],
      "metadata": {
        "id": "FyCZeLY_Wa71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of features:\", X.shape[1])\n",
        "print(\"\\nFeature names:\")\n",
        "print(X.columns.tolist())\n",
        "\n",
        "print(\"\\nNumerical features:\")\n",
        "print(numeric_columns.tolist())\n",
        "print(\"\\nCategorical features:\")\n",
        "print(categorical_columns.tolist())\n",
        "\n",
        "# Display statistics of numeric features\n",
        "print(\"\\nNumerical features:\")\n",
        "print(X[numeric_columns].describe())\n",
        "\n",
        "# Display unique values of categorical features\n",
        "print(\"\\nUnique values of categorical features:\")\n",
        "for feature in categorical_columns:\n",
        "  print(f\"{feature}: {X[feature].nunique()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhboVXZPShC1",
        "outputId": "01479e0f-4196-45d7-a287-dd1c8b314a23"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features: 16\n",
            "\n",
            "Feature names:\n",
            "['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_ADLT_FAM_MEMBERS', 'CREDIT_SCORE', 'AGE', 'MONTHS_EMPLOYED']\n",
            "\n",
            "Numerical features:\n",
            "['AMT_INCOME_TOTAL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL', 'CNT_ADLT_FAM_MEMBERS', 'CREDIT_SCORE', 'AGE', 'MONTHS_EMPLOYED']\n",
            "\n",
            "Categorical features:\n",
            "['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE']\n",
            "\n",
            "Numerical features:\n",
            "       AMT_INCOME_TOTAL  FLAG_WORK_PHONE     FLAG_PHONE     FLAG_EMAIL  \\\n",
            "count      4.385100e+05    438510.000000  438510.000000  438510.000000   \n",
            "mean       1.875209e+05         0.206134       0.287763       0.108203   \n",
            "std        1.100807e+05         0.404529       0.452721       0.310637   \n",
            "min        2.610000e+04         0.000000       0.000000       0.000000   \n",
            "25%        1.215000e+05         0.000000       0.000000       0.000000   \n",
            "50%        1.611000e+05         0.000000       0.000000       0.000000   \n",
            "75%        2.250000e+05         0.000000       1.000000       0.000000   \n",
            "max        6.750000e+06         1.000000       1.000000       1.000000   \n",
            "\n",
            "       CNT_ADLT_FAM_MEMBERS   CREDIT_SCORE            AGE  MONTHS_EMPLOYED  \n",
            "count         438510.000000  438510.000000  438510.000000    438510.000000  \n",
            "mean               1.767401     672.191512      43.295325        93.006969  \n",
            "std                0.422489    4408.079124      11.459595        73.784776  \n",
            "min                1.000000  -72100.000000      20.000000         0.000000  \n",
            "25%                2.000000       0.000000      34.000000        35.000000  \n",
            "50%                2.000000       0.000000      42.000000        82.000000  \n",
            "75%                2.000000       0.000000      53.000000       131.000000  \n",
            "max                2.000000   59000.000000      68.000000       575.000000  \n",
            "\n",
            "Unique values of categorical features:\n",
            "CODE_GENDER: 2\n",
            "FLAG_OWN_CAR: 2\n",
            "FLAG_OWN_REALTY: 2\n",
            "NAME_INCOME_TYPE: 5\n",
            "NAME_EDUCATION_TYPE: 5\n",
            "NAME_FAMILY_STATUS: 5\n",
            "NAME_HOUSING_TYPE: 6\n",
            "OCCUPATION_TYPE: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create new features\n",
        "X['INCOME_AGE_RATIO'] = X['AMT_INCOME_TOTAL'] / X['AGE']\n",
        "X['EMPLOYMENT_RATIO'] = X['MONTHS_EMPLOYED'] / (X['AGE'] * 12)"
      ],
      "metadata": {
        "id": "woUbC0elWePL"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "numeric_columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDTUAt-j4eTc",
        "outputId": "6be35c8c-02a6-45e3-bdc3-1640103e460c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['AMT_INCOME_TOTAL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
              "       'CNT_ADLT_FAM_MEMBERS', 'CREDIT_SCORE', 'AGE', 'MONTHS_EMPLOYED',\n",
              "       'INCOME_AGE_RATIO', 'EMPLOYMENT_RATIO'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kategorik deikenleri ile\n",
        "categorical_encoded = pd.concat([process_categorical(X, col) for col in categorical_columns], axis=1)\n",
        "# Saysal deikenleri normalize et\n",
        "scaler = StandardScaler()\n",
        "numeric_normalized = pd.DataFrame(scaler.fit_transform(X[numeric_columns]),\n",
        "                                  columns=numeric_columns,\n",
        "                                  index=X.index)\n",
        "\n",
        "categorical_normalized = pd.DataFrame(scaler.fit_transform(categorical_encoded[categorical_encoded.columns]),\n",
        "                                      columns=categorical_encoded.columns,\n",
        "                                      index=X.index)\n",
        "# lenmi verileri birletir\n",
        "processed_features = pd.concat([categorical_normalized, numeric_normalized], axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gnk7RDfc4k5o"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'Light GBM': lgb.LGBMClassifier(class_weight=class_weight_dict),\n",
        "    'XGB Classifier': xgb.XGBClassifier(scale_pos_weight=class_weight_dict[1]/class_weight_dict[0])\n",
        "}"
      ],
      "metadata": {
        "id": "lAoS848x7DJq"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = train_evaluate_model(models, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "p710QfjMBN-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "135e94aa-ebe3-4661-baa2-c47e08cf41e6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.6526\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.97      0.78     54585\n",
            "         1.0       0.73      0.13      0.22     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.69      0.55      0.50     87702\n",
            "weighted avg       0.68      0.65      0.57     87702\n",
            "\n",
            "\n",
            "Light GBM Results:\n",
            "Accuracy: 0.6512\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.58      0.28      0.38     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.62      0.58      0.57     87702\n",
            "weighted avg       0.63      0.65      0.61     87702\n",
            "\n",
            "\n",
            "XGB Classifier Results:\n",
            "Accuracy: 0.6281\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.81      0.73     54585\n",
            "         1.0       0.51      0.33      0.40     33117\n",
            "\n",
            "    accuracy                           0.63     87702\n",
            "   macro avg       0.59      0.57      0.57     87702\n",
            "weighted avg       0.61      0.63      0.61     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating feature importance levels with Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Ag4LYJksXP5D",
        "outputId": "3c7f538b-4995-4c10-dc16-9fbebb2741df"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display feature importance levels\n",
        "feature_importance = pd.DataFrame({'feature': X_train.columns, 'importance': rf.feature_importances_})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "print(\"The 20 most important features:\")\n",
        "print(feature_importance.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPUv3F3HcIT7",
        "outputId": "1d2f9e07-9078-4202-c01b-f1265ce5d859"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 20 most important features:\n",
            "                                  feature  importance\n",
            "43                       AMT_INCOME_TOTAL    0.167351\n",
            "51                       INCOME_AGE_RATIO    0.160206\n",
            "52                       EMPLOYMENT_RATIO    0.122870\n",
            "50                        MONTHS_EMPLOYED    0.106596\n",
            "48                           CREDIT_SCORE    0.099677\n",
            "49                                    AGE    0.097092\n",
            "45                             FLAG_PHONE    0.019118\n",
            "2                         FLAG_OWN_REALTY    0.019089\n",
            "1                            FLAG_OWN_CAR    0.013498\n",
            "0                             CODE_GENDER    0.013226\n",
            "44                        FLAG_WORK_PHONE    0.011476\n",
            "46                             FLAG_EMAIL    0.009326\n",
            "14             NAME_FAMILY_STATUS_Married    0.008982\n",
            "32  OCCUPATION_TYPE_High skill tech staff    0.008689\n",
            "41          OCCUPATION_TYPE_Realty agents    0.007691\n",
            "7                NAME_INCOME_TYPE_Student    0.007463\n",
            "47                   CNT_ADLT_FAM_MEMBERS    0.007128\n",
            "19    NAME_HOUSING_TYPE_House / apartment    0.007120\n",
            "13      NAME_FAMILY_STATUS_Civil marriage    0.006721\n",
            "16           NAME_FAMILY_STATUS_Separated    0.006701\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting the most important features (e.g. until the total importance exceeds 0.95)\n",
        "cumulative_importance = 0\n",
        "important_features = []\n",
        "for idx, row in feature_importance.iterrows():\n",
        "    important_features.append(row['feature'])\n",
        "    cumulative_importance += row['importance']\n",
        "    if cumulative_importance > 0.95:\n",
        "        break\n",
        "\n",
        "print(f\"\\nNumber of selected features: {len(important_features)}\")\n",
        "print(\"Selected features:\")\n",
        "print(important_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gIbEyAkcCGB",
        "outputId": "c07b476f-1b82-4e75-9a32-85e85ff72e1a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of selected features: 29\n",
            "Selected features:\n",
            "['AMT_INCOME_TOTAL', 'INCOME_AGE_RATIO', 'EMPLOYMENT_RATIO', 'MONTHS_EMPLOYED', 'CREDIT_SCORE', 'AGE', 'FLAG_PHONE', 'FLAG_OWN_REALTY', 'FLAG_OWN_CAR', 'CODE_GENDER', 'FLAG_WORK_PHONE', 'FLAG_EMAIL', 'NAME_FAMILY_STATUS_Married', 'OCCUPATION_TYPE_High skill tech staff', 'OCCUPATION_TYPE_Realty agents', 'NAME_INCOME_TYPE_Student', 'CNT_ADLT_FAM_MEMBERS', 'NAME_HOUSING_TYPE_House / apartment', 'NAME_FAMILY_STATUS_Civil marriage', 'NAME_FAMILY_STATUS_Separated', 'NAME_INCOME_TYPE_Working', 'OCCUPATION_TYPE_Accountants', 'OCCUPATION_TYPE_Secretaries', 'OCCUPATION_TYPE_Private service staff', 'NAME_EDUCATION_TYPE_Academic degree', 'NAME_EDUCATION_TYPE_Secondary / secondary special', 'NAME_INCOME_TYPE_Pensioner', 'NAME_FAMILY_STATUS_Single / not married', 'OCCUPATION_TYPE_Laborers']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new datasets with selected features\n",
        "X_train_selected = X_train[important_features]\n",
        "X_test_selected = X_test[important_features]\n",
        "\n",
        "results = train_evaluate_model(models, X_train_selected, y_train, X_test_selected, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwStkp9ecMCL",
        "outputId": "6fe8d9b7-6ec8-4992-da72-2dae61fbee82"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.6528\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.97      0.78     54585\n",
            "         1.0       0.73      0.13      0.22     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.69      0.55      0.50     87702\n",
            "weighted avg       0.68      0.65      0.56     87702\n",
            "\n",
            "\n",
            "Light GBM Results:\n",
            "Accuracy: 0.6509\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.58      0.28      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.62      0.58      0.57     87702\n",
            "weighted avg       0.63      0.65      0.61     87702\n",
            "\n",
            "\n",
            "XGB Classifier Results:\n",
            "Accuracy: 0.6306\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.81      0.73     54585\n",
            "         1.0       0.52      0.34      0.41     33117\n",
            "\n",
            "    accuracy                           0.63     87702\n",
            "   macro avg       0.59      0.57      0.57     87702\n",
            "weighted avg       0.61      0.63      0.61     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"11\"></a>\n",
        "## 11. Hyperparameter Tuning and Optimization for LightGBM ve Gradient Boosting"
      ],
      "metadata": {
        "id": "TWS7UJK6Qc_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import parallel_backend\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from sklearn.metrics import make_scorer, log_loss"
      ],
      "metadata": {
        "id": "cMKX40BERFxN"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Bh_aj4UFKpZ5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'Light GBM': lgb.LGBMClassifier(\n",
        "        class_weight=class_weight_dict,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,  # Use all CPU cores\n",
        "        importance_type='gain'  # For better feature importance\n",
        "    ),\n",
        "    'XGB Classifier': xgb.XGBClassifier(\n",
        "    random_state=42,\n",
        "    eval_metric='logloss',\n",
        "    scale_pos_weight=class_weight_dict[1]/class_weight_dict[0],\n",
        "    enable_categorical=True  # Kategorik zellikleri otomatik ilemek iin\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "2wiy3EvvJz7N"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_with_hyperopt(models, param_dists, X_train, y_train, X_test, y_test, n_iter=30, cv=3, n_jobs=-1):\n",
        "    \"\"\"\n",
        "    Train and evaluate models with hyperparameter optimization.\n",
        "\n",
        "    Parameters:\n",
        "    models (dict): A dictionary of model names and their corresponding instances.\n",
        "    param_dists (dict): A dictionary of hyperparameter distributions for each model.\n",
        "    X_train (array-like): Training features.\n",
        "    y_train (array-like): Training labels.\n",
        "    X_test (array-like): Test features.\n",
        "    y_test (array-like): Test labels.\n",
        "    n_iter (int): Number of parameter settings sampled in RandomizedSearchCV.\n",
        "    cv (int): Number of cross-validation folds.\n",
        "    n_jobs (int): Number of jobs to run in parallel.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing evaluation results and best models for each model type.\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    best_models = {}\n",
        "\n",
        "    # Use F1 score as the scoring metric\n",
        "    f1_scorer = make_scorer(f1_score, average='weighted')\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nOptimizing {name}...\")\n",
        "\n",
        "        with parallel_backend('threading', n_jobs=n_jobs):\n",
        "            random_search = RandomizedSearchCV(\n",
        "                model,\n",
        "                param_distributions=param_dists[name],\n",
        "                n_iter=n_iter,\n",
        "                cv=cv,\n",
        "                scoring=f1_scorer,\n",
        "                n_jobs=1,  # Use 1 here because we're using parallel_backend\n",
        "                random_state=42\n",
        "            )\n",
        "\n",
        "            random_search.fit(X_train, y_train)\n",
        "\n",
        "        best_model = random_search.best_estimator_\n",
        "        best_models[name] = best_model\n",
        "\n",
        "        y_pred = best_model.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "        results[name] = {\n",
        "            'best_model': best_model,\n",
        "            'best_params': random_search.best_params_,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_score': f1,\n",
        "            'classification_report': report\n",
        "        }\n",
        "\n",
        "        print(f\"\\n{name} Results:\")\n",
        "        print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return results, best_models"
      ],
      "metadata": {
        "id": "9jpUFX0k8kbC"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparametre dalmlar\n",
        "gb_param_dist = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "lgbm_param_dist = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'num_leaves': [31, 6],  # Larger values for better accuracy, but not too large\n",
        "    'max_depth': [5, 7],  # Limit depth to prevent overfitting\n",
        "    'learning_rate': [0.05, 0.1],  # Smaller learning rates\n",
        "    'feature_fraction': [0.8, 0.9],  # Feature subsampling to prevent overfitting\n",
        "    'min_child_samples': [20, 50],  # Prevent overfitting on small leaves\n",
        "    'lambda_l1': [0, 1.0],  # L1 regularization\n",
        "    'lambda_l2': [0, 1.0],  # L2 regularization\n",
        "    'boosting_type': ['gbdt', 'dart'],  # Try both gbdt and dart\n",
        "}\n",
        "\n",
        "xgb_param_dist = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'min_child_weight': [1, 3],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0],\n",
        "    'gamma': [0, 0.1],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [0, 0.1]\n",
        "}\n",
        "\n",
        "param_dists = {\n",
        "    'Gradient Boosting': gb_param_dist,\n",
        "    'Light GBM': lgbm_param_dist,\n",
        "    'XGB Classifier': xgb_param_dist\n",
        "}"
      ],
      "metadata": {
        "id": "jPNCo_LYO3mJ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonksiyonu arma\n",
        "results, best_models = train_evaluate_with_hyperopt(models, param_dists, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlRx25M89sKR",
        "outputId": "3a180c0a-a824-433d-ef6e-06e701d5a314"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122475 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082858 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079187 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078714 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079208 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081024 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.149869 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079624 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080268 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079464 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081298 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087816 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078884 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080247 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092127 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150255 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.155499 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.138037 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089847 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081244 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083021 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129950 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138315 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207854 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082607 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.244809 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078620 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.118144 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077922 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.122230 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.132245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076423 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077294 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078964 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081134 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083921 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147602 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126918 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150885 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078880 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127597 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080028 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079235 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080820 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078888 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083249 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134071 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143214 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079492 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076642 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132869 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079112 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.128357 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142457 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092347 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088886 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078311 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.149509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077210 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125901 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078192 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079078 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125483 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.154494 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085898 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078894 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080070 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.150404 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.207088 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.204865 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88272, number of negative: 145600\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.142565 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000012\n",
            "[LightGBM] [Info] Start training from score 0.000012\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082681 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Info] Number of positive: 88271, number of negative: 145601\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1419\n",
            "[LightGBM] [Info] Number of data points in the train set: 233872, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499998 -> initscore=-0.000006\n",
            "[LightGBM] [Info] Start training from score -0.000006\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 132407, number of negative: 218401\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121172 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1417\n",
            "[LightGBM] [Info] Number of data points in the train set: 350808, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "\n",
            "Light GBM Results:\n",
            "Best Parameters: {'num_leaves': 31, 'n_estimators': 200, 'min_child_samples': 20, 'max_depth': 7, 'learning_rate': 0.05, 'lambda_l2': 0, 'lambda_l1': 0, 'feature_fraction': 0.8, 'boosting_type': 'gbdt'}\n",
            "Accuracy: 0.6528\n",
            "F1 Score: 0.6137\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.59      0.27      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.63      0.58      0.57     87702\n",
            "weighted avg       0.64      0.65      0.61     87702\n",
            "\n",
            "\n",
            "Optimizing XGB Classifier...\n",
            "\n",
            "XGB Classifier Results:\n",
            "Best Parameters: {'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alpha': 0.1, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
            "Accuracy: 0.6511\n",
            "F1 Score: 0.6124\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.58      0.27      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.62      0.58      0.56     87702\n",
            "weighted avg       0.63      0.65      0.61     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# En iyi modelleri al\n",
        "best_lgbm = best_models.get('Light GBM')\n",
        "best_gb = best_models.get('Gradient Boosting')\n",
        "best_xgb = best_models.get('XGB Classifier')"
      ],
      "metadata": {
        "id": "PZ304JxUWmO5"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"12\"></a>\n",
        "## 12. Ensemble Methods"
      ],
      "metadata": {
        "id": "h1y948-tQXAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Weighted Voting\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lgbm', best_lgbm), ('xgb', best_xgb)],\n",
        "    voting='soft',\n",
        "    weights=[1, 1]\n",
        ")\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=[('lgbm', best_lgbm), ('xgb', best_xgb)],\n",
        "    final_estimator=LogisticRegression(),\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Compare both ensemble methods\n",
        "voting_scores = cross_val_score(voting_clf, X_train, y_train, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
        "stacking_scores = cross_val_score(stacking_clf, X_train, y_train, cv=3, scoring='f1_weighted', n_jobs=-1)\n",
        "\n",
        "print(\"Weighted Voting mean F1 score:\", voting_scores.mean())\n",
        "print(\"Stacking mean F1 score:\", stacking_scores.mean())\n",
        "\n",
        "# Choose and train the best ensemble method\n",
        "if voting_scores.mean() > stacking_scores.mean():\n",
        "    best_ensemble = voting_clf\n",
        "    print(\"Weighted Voting is better\")\n",
        "else:\n",
        "    best_ensemble = stacking_clf\n",
        "    print(\"Stacking is better\")\n",
        "\n",
        "best_ensemble.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "wbQTJ3OSQSnR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "b329c9f9-608a-4b48-9deb-c95956fbb722"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Voting mean F1 score: 0.6116464981089108\n",
            "Stacking mean F1 score: 0.6111533509320801\n",
            "Weighted Voting is better\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 132407, number of negative: 218401\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133665 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1417\n",
            "[LightGBM] [Info] Number of data points in the train set: 350808, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Start training from score 0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lgbm',\n",
              "                              LGBMClassifier(class_weight={0.0: 0.8031281908049872,\n",
              "                                                           1.0: 1.3247335865928538},\n",
              "                                             feature_fraction=0.8,\n",
              "                                             importance_type='gain',\n",
              "                                             lambda_l1=0, lambda_l2=0,\n",
              "                                             learning_rate=0.05, max_depth=7,\n",
              "                                             n_estimators=200, n_jobs=-1,\n",
              "                                             random_state=42)),\n",
              "                             ('xgb',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsa...\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None, min_child_weight=3,\n",
              "                                            missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                 voting='soft', weights=[1, 1])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                              LGBMClassifier(class_weight={0.0: 0.8031281908049872,\n",
              "                                                           1.0: 1.3247335865928538},\n",
              "                                             feature_fraction=0.8,\n",
              "                                             importance_type=&#x27;gain&#x27;,\n",
              "                                             lambda_l1=0, lambda_l2=0,\n",
              "                                             learning_rate=0.05, max_depth=7,\n",
              "                                             n_estimators=200, n_jobs=-1,\n",
              "                                             random_state=42)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsa...\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None, min_child_weight=3,\n",
              "                                            missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                 voting=&#x27;soft&#x27;, weights=[1, 1])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lgbm&#x27;,\n",
              "                              LGBMClassifier(class_weight={0.0: 0.8031281908049872,\n",
              "                                                           1.0: 1.3247335865928538},\n",
              "                                             feature_fraction=0.8,\n",
              "                                             importance_type=&#x27;gain&#x27;,\n",
              "                                             lambda_l1=0, lambda_l2=0,\n",
              "                                             learning_rate=0.05, max_depth=7,\n",
              "                                             n_estimators=200, n_jobs=-1,\n",
              "                                             random_state=42)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsa...\n",
              "                                            importance_type=None,\n",
              "                                            interaction_constraints=None,\n",
              "                                            learning_rate=0.1, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None, min_child_weight=3,\n",
              "                                            missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            random_state=42, ...))],\n",
              "                 voting=&#x27;soft&#x27;, weights=[1, 1])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lgbm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight={0.0: 0.8031281908049872, 1.0: 1.3247335865928538},\n",
              "               feature_fraction=0.8, importance_type=&#x27;gain&#x27;, lambda_l1=0,\n",
              "               lambda_l2=0, learning_rate=0.05, max_depth=7, n_estimators=200,\n",
              "               n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=True, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, gamma=0.1, grow_policy=None,\n",
              "              importance_type=None, interaction_constraints=None,\n",
              "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=3, missing=nan,\n",
              "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
              "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best ensemble on the test set\n",
        "y_pred = best_ensemble.predict(X_test)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"\\nBest Ensemble F1 Score on Test Set: {f1:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AssWfiXUW_1w",
        "outputId": "8cd8ec1f-b4a6-4f38-eae8-a859a7d404af"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "\n",
            "Best Ensemble F1 Score on Test Set: 0.6135\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.59      0.27      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.63      0.58      0.57     87702\n",
            "weighted avg       0.64      0.65      0.61     87702\n",
            "\n",
            "\n",
            "Gradient Boosting F1 Score on Test Set: 0.5782\n",
            "Gradient Boosting Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.95      0.77     54585\n",
            "         1.0       0.67      0.16      0.26     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.66      0.56      0.51     87702\n",
            "weighted avg       0.66      0.65      0.58     87702\n",
            "\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "\n",
            "Light GBM F1 Score on Test Set: 0.6137\n",
            "Light GBM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.59      0.27      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.63      0.58      0.57     87702\n",
            "weighted avg       0.64      0.65      0.61     87702\n",
            "\n",
            "\n",
            "XGB Classifier F1 Score on Test Set: 0.6124\n",
            "XGB Classifier Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.67      0.88      0.76     54585\n",
            "         1.0       0.58      0.27      0.37     33117\n",
            "\n",
            "    accuracy                           0.65     87702\n",
            "   macro avg       0.62      0.58      0.56     87702\n",
            "weighted avg       0.63      0.65      0.61     87702\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"12\"></a>\n",
        "## 13. Handling Class Imbalance"
      ],
      "metadata": {
        "id": "Nft74ylUQg1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Oversampling techniques\n",
        "oversamplers = {\n",
        "    'SMOTE': SMOTE(random_state=42),\n",
        "    'ADASYN': ADASYN(random_state=42),\n",
        "    'RandomOverSampler': RandomOverSampler(random_state=42)\n",
        "}\n",
        "\n",
        "# Try every oversampling technique\n",
        "for name, oversampler in oversamplers.items():\n",
        "    X_resampled, y_resampled = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "    # En iyi ensemble modelini kullanarak skorlar hesapla\n",
        "    scores = cross_val_score(best_ensemble, X_resampled, y_resampled, cv=5, scoring='f1')\n",
        "\n",
        "    print(f\"{name} mean F1 score: {scores.mean()}\")\n",
        "\n",
        "# En iyi oversampling tekniini se\n",
        "best_oversampler = max(oversamplers.items(), key=lambda x: cross_val_score(best_ensemble, *x[1].fit_resample(X_train, y_train), cv=5, scoring='f1').mean())[1]\n",
        "\n",
        "# Apply best oversampling technique\n",
        "X_resampled, y_resampled = best_oversampler.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "2FaBcA7KQaNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8248ab4b-4265-4c59-a782-76662778baed"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.698866 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4498\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622567 -> initscore=0.500458\n",
            "[LightGBM] [Info] Start training from score 0.500458\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174720, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.115321 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4499\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622564 -> initscore=0.500447\n",
            "[LightGBM] [Info] Start training from score 0.500447\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122208 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4509\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135994 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3533\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135071 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3589\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "SMOTE mean F1 score: 0.6775056730911494\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122147 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4570\n",
            "[LightGBM] [Info] Number of data points in the train set: 366952, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644734 -> initscore=0.595971\n",
            "[LightGBM] [Info] Start training from score 0.595971\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.329083 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4574\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126746 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4522\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128638 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3885\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.210862 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3859\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "ADASYN mean F1 score: 0.6990626383371334\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1413\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622567 -> initscore=0.500458\n",
            "[LightGBM] [Info] Start training from score 0.500458\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174720, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.714056 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1414\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622564 -> initscore=0.500447\n",
            "[LightGBM] [Info] Start training from score 0.500447\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1413\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.120937 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1415\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.192653 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "RandomOverSampler mean F1 score: 0.6788597420345102\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.177481 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4498\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622567 -> initscore=0.500458\n",
            "[LightGBM] [Info] Start training from score 0.500458\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174720, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118698 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4499\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622564 -> initscore=0.500447\n",
            "[LightGBM] [Info] Start training from score 0.500447\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113954 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4509\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.807523 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3533\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122358 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3589\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.121390 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4570\n",
            "[LightGBM] [Info] Number of data points in the train set: 366952, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644734 -> initscore=0.595971\n",
            "[LightGBM] [Info] Start training from score 0.595971\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126471 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4574\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124152 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4522\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128442 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3885\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 192232, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.251900 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3859\n",
            "[LightGBM] [Info] Number of data points in the train set: 366953, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595965\n",
            "[LightGBM] [Info] Start training from score 0.595965\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174720\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122321 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1413\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622567 -> initscore=0.500458\n",
            "[LightGBM] [Info] Start training from score 0.500458\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174720, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135635 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1414\n",
            "[LightGBM] [Info] Number of data points in the train set: 349441, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622564 -> initscore=0.500447\n",
            "[LightGBM] [Info] Start training from score 0.500447\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126229 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1413\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.118771 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1415\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 174721, number of negative: 174721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129314 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1418\n",
            "[LightGBM] [Info] Number of data points in the train set: 349442, number of used features: 52\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.622566 -> initscore=0.500452\n",
            "[LightGBM] [Info] Start training from score 0.500452\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"14\"></a>\n",
        "## 14. Final Model Training and Evaluation"
      ],
      "metadata": {
        "id": "Vk3H0znMRU41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the final model\n",
        "best_ensemble.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_ensemble.predict(X_test)\n",
        "y_pred_proba = best_ensemble.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_proba))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "\n",
        "# Show important features\n",
        "if hasattr(best_ensemble, 'feature_importances_'):\n",
        "    feature_importance = best_ensemble.feature_importances_\n",
        "    feature_names = X_train.columns\n",
        "    sorted_idx = np.argsort(feature_importance)\n",
        "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "    plt.yticks(pos, feature_names[sorted_idx])\n",
        "    plt.title('Feature Importance')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_kr-Z2K9RUQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f05e3d-6f60-48a6-85c6-0320de20f145"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Info] Number of positive: 240290, number of negative: 218401\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.722762 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4483\n",
            "[LightGBM] [Info] Number of data points in the train set: 458691, number of used features: 53\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.644733 -> initscore=0.595966\n",
            "[LightGBM] [Info] Start training from score 0.595966\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0\n",
            "[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.06      0.12     54585\n",
            "         1.0       0.39      0.99      0.56     33117\n",
            "\n",
            "    accuracy                           0.41     87702\n",
            "   macro avg       0.67      0.53      0.34     87702\n",
            "weighted avg       0.74      0.41      0.28     87702\n",
            "\n",
            "ROC AUC Score: 0.6035820405179824\n",
            "F1 Score: 0.5616655583405801\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V79rYEwt9-yU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}